{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cSPnqZisanby"
      },
      "outputs": [],
      "source": [
        "# import FrEIA framework\n",
        "import sys\n",
        "sys.path.append(\"/FrEIA-master\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a1eVVkYZu6Qu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.pyplot import figure\n",
        "from torch.utils.data import DataLoader\n",
        "import plain_inn_swap\n",
        "from tesladatainn import TeslaDatasetInn\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb\n",
        "import pprint\n",
        "import math\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpY1sHVuanbz"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYGpi3qGanb2",
        "outputId": "cc3125ca-0578-419a-e811-ab57ae19bec2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjeyhun\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ],
      "source": [
        "wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'Loss',\n",
        "    'goal': 'minimize'  \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'lambd_predict_back': {\n",
        "        # integers between 1 and 1024\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'lambd_latent': {\n",
        "        # integers between 1 and 1024\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'lambd_rev': {\n",
        "        # integers between 1 and 1024\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'epochs': {\n",
        "          'value': 1\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4KwIDXpanb5",
        "outputId": "4060c64e-6062-43a4-a6f1-e25aa1a3f479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'Loss'},\n",
            " 'parameters': {'epochs': {'value': 1},\n",
            "                'lambd_latent': {'distribution': 'q_log_uniform',\n",
            "                                 'max': 6.931471805599453,\n",
            "                                 'min': 0.0,\n",
            "                                 'q': 1},\n",
            "                'lambd_predict_back': {'distribution': 'q_log_uniform',\n",
            "                                       'max': 6.931471805599453,\n",
            "                                       'min': 0.0,\n",
            "                                       'q': 1},\n",
            "                'lambd_rev': {'distribution': 'q_log_uniform',\n",
            "                              'max': 6.931471805599453,\n",
            "                              'min': 0.0,\n",
            "                              'q': 1}}}\n",
            "Create sweep with ID: opxbmsu7\n",
            "Sweep URL: https://wandb.ai/jeyhun/INN%20optimization/sweeps/opxbmsu7\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(sweep_config)\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"INN optimization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXK_PVgZanb7"
      },
      "source": [
        "### Training\n",
        "The following cell basically trains an Invertible Neural Network as of (Ardizzone, 2018) without padding: `[y,z] <=> x` with `x` = parameters, `y` = temperature readings and `z` our latent variable (iid. Gaussian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-LMS92itanb8"
      },
      "outputs": [],
      "source": [
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        batch_size = 2048\n",
        "        lr = 1e-3\n",
        "        #device = \"cuda:0\"\n",
        "        # Use cuda if it is available, else use the cpu\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        num_features = 100\n",
        "        num_blocks = 5\n",
        "\n",
        "        #ds = TeslaDataset()\n",
        "        ds = TeslaDatasetInn(device = device, data = \"train\")\n",
        "        train_dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "        # get one sample of our dataset to infer its input and output dimension\n",
        "        x,y = ds.__getitem__(0)\n",
        "        dim_inp = x.shape[0]\n",
        "        dim_outp = 1\n",
        "         \n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        \n",
        "        #print('config.batch_size',config.batch_size)\n",
        "        my_inn = plain_inn_swap.INN(ndim_tot = dim_inp, ndim_y = dim_outp, ndim_x = dim_inp, ndim_z=dim_inp-dim_outp, \n",
        "            device = device,\n",
        "             lambd_predict_back = config.lambd_predict_back, lambd_latent = config.lambd_latent, lambd_rev = config.lambd_rev,\n",
        "             feature = num_features, num_blocks = num_blocks, batch_size = batch_size, lr = lr)\n",
        "\n",
        "        begin = time.time()\n",
        "        my_inn.train(config.epochs, train_loader=train_dataloader, val_loader=train_dataloader, log_writer = ['wb', wandb])\n",
        "        end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "palda30hanb9"
      },
      "outputs": [],
      "source": [
        "#print(\"training:\", end - begin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruD2gSAoanb_",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, train, count=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "1D_Heat_Equation_INN_WANDB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
