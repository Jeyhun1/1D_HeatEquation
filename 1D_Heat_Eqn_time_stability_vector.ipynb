{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqFaBeDXyHq",
        "outputId": "a3c337c2-5056-4adc-ecbd-af9c74ba11e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Was not able to import Horovod. Thus Horovod support is not enabled\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor, ones, stack, load\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.pyplot import figure\n",
        "import pandas as pd\n",
        "from torch.nn import Module\n",
        "from torch.utils.data import DataLoader\n",
        "from scipy import stats\n",
        "from tesladatadiff import TeslaDatasetDiff\n",
        "\n",
        "sys.path.append(\"NeuralSolvers\") \n",
        "import PINNFramework as pf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEqKEcG8YMpg",
        "outputId": "3d23d9d8-2acd-4ffa-bbb0-343ae128db3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Use cuda if it is available, else use the cpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQkJvE48IFHW"
      },
      "outputs": [],
      "source": [
        "normalize=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWB2kB0jYYb-"
      },
      "outputs": [],
      "source": [
        "# Create instance of the dataset\n",
        "ds = TeslaDatasetDiff(device = device, normalize = normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qto5MS9dlclL"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=ds, batch_size=1024, shuffle=False)\n",
        "#next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2RpWmEp6Zk2"
      },
      "outputs": [],
      "source": [
        "model = pf.models.MLP(input_size=5,\n",
        "                      output_size=1, \n",
        "                      hidden_size=100, \n",
        "                      num_hidden=4, \n",
        "                      lb=ds.lb, \n",
        "                      ub=ds.ub,\n",
        "                      activation = torch.relu\n",
        "                      )\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXZeiNIRoK2K"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p01JZkSBvB4",
        "outputId": "16c6f727-d21e-47f7-b2c8-f7e02061859c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 0\n",
            "Loss after mini-batch    50: 251.87665894\n",
            "Loss after mini-batch   100: 3.19053279\n",
            "Loss after mini-batch   150: 79.77052376\n",
            "Loss after mini-batch   200: 2.91633455\n",
            "Loss after mini-batch   250: 0.55253422\n",
            "Loss after mini-batch   300: 0.02041842\n",
            "Loss after mini-batch   350: 0.05362281\n",
            "Loss after mini-batch   400: 0.36541066\n",
            "Epoch  0 Total Loss  39.105487132760715\n",
            "Epoch  0 Loss 1  0.010007899469552474\n",
            "Epoch  0 Loss 2 39.09547931804112\n",
            "Starting epoch 1\n",
            "Loss after mini-batch    50: 5.78044002\n",
            "Loss after mini-batch   100: 6.52995488\n",
            "Loss after mini-batch   150: 60.45003828\n",
            "Loss after mini-batch   200: 2.79688961\n",
            "Loss after mini-batch   250: 2.05902440\n",
            "Loss after mini-batch   300: 1.22578814\n",
            "Loss after mini-batch   350: 0.50519130\n",
            "Loss after mini-batch   400: 0.57756090\n",
            "Epoch  1 Total Loss  10.162409849780442\n",
            "Epoch  1 Loss 1  0.01073356961500938\n",
            "Epoch  1 Loss 2 10.151676238577405\n",
            "Starting epoch 2\n",
            "Loss after mini-batch    50: 79.67921627\n",
            "Loss after mini-batch   100: 35.23607785\n",
            "Loss after mini-batch   150: 40.97951598\n",
            "Loss after mini-batch   200: 14.25221333\n",
            "Loss after mini-batch   250: 2.36252445\n",
            "Loss after mini-batch   300: 0.03605228\n",
            "Loss after mini-batch   350: 0.10724420\n",
            "Loss after mini-batch   400: 4.70187540\n",
            "Epoch  2 Total Loss  21.39223018394288\n",
            "Epoch  2 Loss 1  0.009781280905878086\n",
            "Epoch  2 Loss 2 21.382448954410354\n",
            "Starting epoch 3\n",
            "Loss after mini-batch    50: 51.50736215\n",
            "Loss after mini-batch   100: 9.81895573\n",
            "Loss after mini-batch   150: 39.65636316\n",
            "Loss after mini-batch   200: 4.26951575\n",
            "Loss after mini-batch   250: 0.92706185\n",
            "Loss after mini-batch   300: 0.19578907\n",
            "Loss after mini-batch   350: 0.17245333\n",
            "Loss after mini-batch   400: 0.43713158\n",
            "Epoch  3 Total Loss  12.373843758819035\n",
            "Epoch  3 Loss 1  0.011985821289943424\n",
            "Epoch  3 Loss 2 12.361858007841764\n",
            "Starting epoch 4\n",
            "Loss after mini-batch    50: 90.58127705\n",
            "Loss after mini-batch   100: 5.32978009\n",
            "Loss after mini-batch   150: 126.05896278\n",
            "Loss after mini-batch   200: 3.10969597\n",
            "Loss after mini-batch   250: 0.38003716\n",
            "Loss after mini-batch   300: 0.03069839\n",
            "Loss after mini-batch   350: 0.03225457\n",
            "Loss after mini-batch   400: 0.00849424\n",
            "Epoch  4 Total Loss  25.951859855299052\n",
            "Epoch  4 Loss 1  0.009916291021392848\n",
            "Epoch  4 Loss 2 25.941943419640694\n",
            "Starting epoch 5\n",
            "Loss after mini-batch    50: 25.24862261\n",
            "Loss after mini-batch   100: 1.51096480\n",
            "Loss after mini-batch   150: 3.78379629\n",
            "Loss after mini-batch   200: 0.32745681\n",
            "Loss after mini-batch   250: 0.27867755\n",
            "Loss after mini-batch   300: 0.04132166\n",
            "Loss after mini-batch   350: 0.03884754\n",
            "Loss after mini-batch   400: 0.26405302\n",
            "Epoch  5 Total Loss  3.6320154777401794\n",
            "Epoch  5 Loss 1  0.009407656044799944\n",
            "Epoch  5 Loss 2 3.6226078436111107\n",
            "Starting epoch 6\n",
            "Loss after mini-batch    50: 1.45129981\n",
            "Loss after mini-batch   100: 0.20133428\n",
            "Loss after mini-batch   150: 3.91067120\n",
            "Loss after mini-batch   200: 0.20055296\n",
            "Loss after mini-batch   250: 0.24571970\n",
            "Loss after mini-batch   300: 0.04598744\n",
            "Loss after mini-batch   350: 0.04968677\n",
            "Loss after mini-batch   400: 0.00935704\n",
            "Epoch  6 Total Loss  0.704903160459397\n",
            "Epoch  6 Loss 1  0.009004737768295802\n",
            "Epoch  6 Loss 2 0.6958984175694818\n",
            "Starting epoch 7\n",
            "Loss after mini-batch    50: 11.70826985\n",
            "Loss after mini-batch   100: 0.62809430\n",
            "Loss after mini-batch   150: 0.14533990\n",
            "Loss after mini-batch   200: 0.03284120\n",
            "Loss after mini-batch   250: 0.03400643\n",
            "Loss after mini-batch   300: 0.01846265\n",
            "Loss after mini-batch   350: 0.01694875\n",
            "Loss after mini-batch   400: 0.04108281\n",
            "Epoch  7 Total Loss  1.45836562201086\n",
            "Epoch  7 Loss 1  0.008997738665510397\n",
            "Epoch  7 Loss 2 1.4493678763363742\n",
            "Starting epoch 8\n",
            "Loss after mini-batch    50: 0.60203815\n",
            "Loss after mini-batch   100: 0.08224438\n",
            "Loss after mini-batch   150: 10.00758121\n",
            "Loss after mini-batch   200: 3.72550084\n",
            "Loss after mini-batch   250: 0.47152194\n",
            "Loss after mini-batch   300: 0.01104661\n",
            "Loss after mini-batch   350: 0.01174342\n",
            "Loss after mini-batch   400: 0.13427973\n",
            "Epoch  8 Total Loss  1.8085121198363292\n",
            "Epoch  8 Loss 1  0.008164533615524107\n",
            "Epoch  8 Loss 2 1.800347566845802\n",
            "Starting epoch 9\n",
            "Loss after mini-batch    50: 10.06547045\n",
            "Loss after mini-batch   100: 0.94732517\n",
            "Loss after mini-batch   150: 4.49592149\n",
            "Loss after mini-batch   200: 0.07514923\n",
            "Loss after mini-batch   250: 0.08933510\n",
            "Loss after mini-batch   300: 0.01449525\n",
            "Loss after mini-batch   350: 0.02727596\n",
            "Loss after mini-batch   400: 0.06103657\n",
            "Epoch  9 Total Loss  1.83720129326113\n",
            "Epoch  9 Loss 1  0.009094405431414475\n",
            "Epoch  9 Loss 2 1.8281068607020925\n",
            "Starting epoch 10\n",
            "Loss after mini-batch    50: 5.13684639\n",
            "Loss after mini-batch   100: 0.63394023\n",
            "Loss after mini-batch   150: 7.10186491\n",
            "Loss after mini-batch   200: 0.58390037\n",
            "Loss after mini-batch   250: 0.20333922\n",
            "Loss after mini-batch   300: 0.09353746\n",
            "Loss after mini-batch   350: 0.06101569\n",
            "Loss after mini-batch   400: 0.01037584\n",
            "Epoch  10 Total Loss  1.5944131604815053\n",
            "Epoch  10 Loss 1  0.008594853286997712\n",
            "Epoch  10 Loss 2 1.5858183045982328\n",
            "Starting epoch 11\n",
            "Loss after mini-batch    50: 2.81717604\n",
            "Loss after mini-batch   100: 0.48118165\n",
            "Loss after mini-batch   150: 0.11437942\n",
            "Loss after mini-batch   200: 0.11493203\n",
            "Loss after mini-batch   250: 0.07217515\n",
            "Loss after mini-batch   300: 0.02875892\n",
            "Loss after mini-batch   350: 0.02303817\n",
            "Loss after mini-batch   400: 0.00709052\n",
            "Epoch  11 Total Loss  0.4226806644627613\n",
            "Epoch  11 Loss 1  0.008070910266053097\n",
            "Epoch  11 Loss 2 0.41460976542252304\n",
            "Starting epoch 12\n",
            "Loss after mini-batch    50: 3.77903195\n",
            "Loss after mini-batch   100: 2.24930827\n",
            "Loss after mini-batch   150: 118.53263523\n",
            "Loss after mini-batch   200: 25.10571595\n",
            "Loss after mini-batch   250: 0.24042133\n",
            "Loss after mini-batch   300: 0.13172338\n",
            "Loss after mini-batch   350: 0.02044249\n",
            "Loss after mini-batch   400: 0.00967628\n",
            "Epoch  12 Total Loss  17.32029333681453\n",
            "Epoch  12 Loss 1  0.013444146227600701\n",
            "Epoch  12 Loss 2 17.306849186708398\n",
            "Starting epoch 13\n",
            "Loss after mini-batch    50: 81.89928134\n",
            "Loss after mini-batch   100: 10.22894067\n",
            "Loss after mini-batch   150: 26.15028200\n",
            "Loss after mini-batch   200: 0.27010342\n",
            "Loss after mini-batch   250: 0.78053719\n",
            "Loss after mini-batch   300: 0.05547176\n",
            "Loss after mini-batch   350: 0.01518522\n",
            "Loss after mini-batch   400: 0.18736272\n",
            "Epoch  13 Total Loss  13.839631485056774\n",
            "Epoch  13 Loss 1  0.009094636498090019\n",
            "Epoch  13 Loss 2 13.83053671112933\n",
            "Starting epoch 14\n",
            "Loss after mini-batch    50: 36.60453032\n",
            "Loss after mini-batch   100: 1.66403732\n",
            "Loss after mini-batch   150: 49.81453260\n",
            "Loss after mini-batch   200: 12.34596959\n",
            "Loss after mini-batch   250: 1.75275878\n",
            "Loss after mini-batch   300: 0.07555924\n",
            "Loss after mini-batch   350: 0.13508553\n",
            "Loss after mini-batch   400: 0.18325927\n",
            "Epoch  14 Total Loss  12.196143667513752\n",
            "Epoch  14 Loss 1  0.0081116141186811\n",
            "Epoch  14 Loss 2 12.188032150722508\n",
            "Starting epoch 15\n",
            "Loss after mini-batch    50: 159.25231167\n",
            "Loss after mini-batch   100: 1.86743299\n",
            "Loss after mini-batch   150: 9.37398477\n",
            "Loss after mini-batch   200: 1.86426035\n",
            "Loss after mini-batch   250: 1.01572472\n",
            "Loss after mini-batch   300: 0.02482302\n",
            "Loss after mini-batch   350: 0.04206923\n",
            "Loss after mini-batch   400: 0.04100745\n",
            "Epoch  15 Total Loss  20.00687289881981\n",
            "Epoch  15 Loss 1  0.008326985208485235\n",
            "Epoch  15 Loss 2 19.998546383827\n",
            "Starting epoch 16\n",
            "Loss after mini-batch    50: 30.94920563\n",
            "Loss after mini-batch   100: 7.15552813\n",
            "Loss after mini-batch   150: 115.52721575\n",
            "Loss after mini-batch   200: 0.24557792\n",
            "Loss after mini-batch   250: 1.08307741\n",
            "Loss after mini-batch   300: 0.98796924\n",
            "Loss after mini-batch   350: 0.18590091\n",
            "Loss after mini-batch   400: 4.23285150\n",
            "Epoch  16 Total Loss  21.341465367064576\n",
            "Epoch  16 Loss 1  0.013257727585013705\n",
            "Epoch  16 Loss 2 21.3282072175304\n",
            "Starting epoch 17\n",
            "Loss after mini-batch    50: 3.19982860\n",
            "Loss after mini-batch   100: 0.18460576\n",
            "Loss after mini-batch   150: 4.39663576\n",
            "Loss after mini-batch   200: 1.88817788\n",
            "Loss after mini-batch   250: 0.18230786\n",
            "Loss after mini-batch   300: 0.52928653\n",
            "Loss after mini-batch   350: 0.04103339\n",
            "Loss after mini-batch   400: 1.16695011\n",
            "Epoch  17 Total Loss  1.84368790964139\n",
            "Epoch  17 Loss 1  0.01040774032160949\n",
            "Epoch  17 Loss 2 1.8332801744763356\n",
            "Starting epoch 18\n",
            "Loss after mini-batch    50: 9.39025764\n",
            "Loss after mini-batch   100: 2.04345098\n",
            "Loss after mini-batch   150: 51.34430048\n",
            "Loss after mini-batch   200: 7.45268545\n",
            "Loss after mini-batch   250: 1.37618845\n",
            "Loss after mini-batch   300: 0.06765508\n",
            "Loss after mini-batch   350: 0.10224317\n",
            "Loss after mini-batch   400: 1.96393012\n",
            "Epoch  18 Total Loss  9.038245098003797\n",
            "Epoch  18 Loss 1  0.009283627133285252\n",
            "Epoch  18 Loss 2 9.028961610350157\n",
            "Starting epoch 19\n",
            "Loss after mini-batch    50: 17.87577899\n",
            "Loss after mini-batch   100: 6.92182233\n",
            "Loss after mini-batch   150: 0.29372440\n",
            "Loss after mini-batch   200: 0.03883127\n",
            "Loss after mini-batch   250: 0.08781497\n",
            "Loss after mini-batch   300: 0.02036922\n",
            "Loss after mini-batch   350: 0.01665666\n",
            "Loss after mini-batch   400: 0.00712191\n",
            "Epoch  19 Total Loss  2.9065190204272633\n",
            "Epoch  19 Loss 1  0.00955411045854388\n",
            "Epoch  19 Loss 2 2.8969648787537476\n",
            "Starting epoch 20\n",
            "Loss after mini-batch    50: 3.48036960\n",
            "Loss after mini-batch   100: 5.96005899\n",
            "Loss after mini-batch   150: 21.94046213\n",
            "Loss after mini-batch   200: 4.10321324\n",
            "Loss after mini-batch   250: 0.47758405\n",
            "Loss after mini-batch   300: 0.07209354\n",
            "Loss after mini-batch   350: 0.09768698\n",
            "Loss after mini-batch   400: 0.01293626\n",
            "Epoch  20 Total Loss  4.170188446974686\n",
            "Epoch  20 Loss 1  0.010978889460590113\n",
            "Epoch  20 Loss 2 4.159209582487887\n",
            "Starting epoch 21\n",
            "Loss after mini-batch    50: 4.67572066\n",
            "Loss after mini-batch   100: 0.77715496\n",
            "Loss after mini-batch   150: 64.68957488\n",
            "Loss after mini-batch   200: 6.71020176\n",
            "Loss after mini-batch   250: 0.07446057\n",
            "Loss after mini-batch   300: 0.08727336\n",
            "Loss after mini-batch   350: 0.23144838\n",
            "Loss after mini-batch   400: 0.02304776\n",
            "Epoch  21 Total Loss  8.95129596182104\n",
            "Epoch  21 Loss 1  0.00910597017982268\n",
            "Epoch  21 Loss 2 8.942189871079824\n",
            "Starting epoch 22\n",
            "Loss after mini-batch    50: 10.05500487\n",
            "Loss after mini-batch   100: 1.85529952\n",
            "Loss after mini-batch   150: 34.46931091\n",
            "Loss after mini-batch   200: 2.47529009\n",
            "Loss after mini-batch   250: 0.31661144\n",
            "Loss after mini-batch   300: 0.01034368\n",
            "Loss after mini-batch   350: 0.04345794\n",
            "Loss after mini-batch   400: 0.02448939\n",
            "Epoch  22 Total Loss  5.684889380851654\n",
            "Epoch  22 Loss 1  0.0079997808752356\n",
            "Epoch  22 Loss 2 5.676889586786664\n",
            "Starting epoch 23\n",
            "Loss after mini-batch    50: 2.81731977\n",
            "Loss after mini-batch   100: 1.29948456\n",
            "Loss after mini-batch   150: 59.59860250\n",
            "Loss after mini-batch   200: 6.03943225\n",
            "Loss after mini-batch   250: 0.93230599\n",
            "Loss after mini-batch   300: 0.31847388\n",
            "Loss after mini-batch   350: 0.52241728\n",
            "Loss after mini-batch   400: 0.14078749\n",
            "Epoch  23 Total Loss  8.343462650295853\n",
            "Epoch  23 Loss 1  0.010799651514615358\n",
            "Epoch  23 Loss 2 8.332662997206338\n",
            "Starting epoch 24\n",
            "Loss after mini-batch    50: 0.17869789\n",
            "Loss after mini-batch   100: 0.66677421\n",
            "Loss after mini-batch   150: 26.08342838\n",
            "Loss after mini-batch   200: 7.27380740\n",
            "Loss after mini-batch   250: 0.24888791\n",
            "Loss after mini-batch   300: 0.04608098\n",
            "Loss after mini-batch   350: 0.02804213\n",
            "Loss after mini-batch   400: 0.23650984\n",
            "Epoch  24 Total Loss  4.213243039769126\n",
            "Epoch  24 Loss 1  0.009220715503197844\n",
            "Epoch  24 Loss 2 4.204022304995782\n",
            "Starting epoch 25\n",
            "Loss after mini-batch    50: 39.00064318\n",
            "Loss after mini-batch   100: 18.39996938\n",
            "Loss after mini-batch   150: 51.05617963\n",
            "Loss after mini-batch   200: 0.38159949\n",
            "Loss after mini-batch   250: 0.24865198\n",
            "Loss after mini-batch   300: 0.07128302\n",
            "Loss after mini-batch   350: 0.16503025\n",
            "Loss after mini-batch   400: 0.02881301\n",
            "Epoch  25 Total Loss  12.599582529656008\n",
            "Epoch  25 Loss 1  0.010856328569680933\n",
            "Epoch  25 Loss 2 12.588726380402177\n",
            "Starting epoch 26\n",
            "Loss after mini-batch    50: 3.86855672\n",
            "Loss after mini-batch   100: 0.89002429\n",
            "Loss after mini-batch   150: 41.96957592\n",
            "Loss after mini-batch   200: 1.57380341\n",
            "Loss after mini-batch   250: 0.14878274\n",
            "Loss after mini-batch   300: 0.04756357\n",
            "Loss after mini-batch   350: 0.04238774\n",
            "Loss after mini-batch   400: 0.16504482\n",
            "Epoch  26 Total Loss  5.6460622693457525\n",
            "Epoch  26 Loss 1  0.008911283720701102\n",
            "Epoch  26 Loss 2 5.637151031553436\n",
            "Starting epoch 27\n",
            "Loss after mini-batch    50: 9.56401943\n",
            "Loss after mini-batch   100: 8.75256745\n",
            "Loss after mini-batch   150: 17.50114966\n",
            "Loss after mini-batch   200: 0.70786186\n",
            "Loss after mini-batch   250: 0.09581437\n",
            "Loss after mini-batch   300: 0.01632295\n",
            "Loss after mini-batch   350: 0.04933994\n",
            "Loss after mini-batch   400: 0.05779737\n",
            "Epoch  27 Total Loss  4.356281163944535\n",
            "Epoch  27 Loss 1  0.007495005245261288\n",
            "Epoch  27 Loss 2 4.348786166979768\n",
            "Starting epoch 28\n",
            "Loss after mini-batch    50: 16.45547023\n",
            "Loss after mini-batch   100: 5.41146021\n",
            "Loss after mini-batch   150: 35.21835122\n",
            "Loss after mini-batch   200: 3.26133887\n",
            "Loss after mini-batch   250: 0.19204235\n",
            "Loss after mini-batch   300: 0.01523749\n",
            "Loss after mini-batch   350: 0.04918193\n",
            "Loss after mini-batch   400: 0.01269852\n",
            "Epoch  28 Total Loss  7.021084487087941\n",
            "Epoch  28 Loss 1  0.009884708603552925\n",
            "Epoch  28 Loss 2 7.01119980869392\n",
            "Starting epoch 29\n",
            "Loss after mini-batch    50: 4.44821431\n",
            "Loss after mini-batch   100: 4.36579120\n",
            "Loss after mini-batch   150: 64.91146433\n",
            "Loss after mini-batch   200: 2.45096232\n",
            "Loss after mini-batch   250: 0.08873315\n",
            "Loss after mini-batch   300: 0.01593161\n",
            "Loss after mini-batch   350: 0.03043648\n",
            "Loss after mini-batch   400: 0.01492252\n",
            "Epoch  29 Total Loss  8.809679168604408\n",
            "Epoch  29 Loss 1  0.01242685747015405\n",
            "Epoch  29 Loss 2 8.797252240046573\n",
            "Starting epoch 30\n",
            "Loss after mini-batch    50: 19.69598366\n",
            "Loss after mini-batch   100: 6.87136652\n",
            "Loss after mini-batch   150: 29.45517841\n",
            "Loss after mini-batch   200: 3.14433310\n",
            "Loss after mini-batch   250: 0.55466242\n",
            "Loss after mini-batch   300: 0.01882813\n",
            "Loss after mini-batch   350: 0.01676725\n",
            "Loss after mini-batch   400: 0.00985764\n",
            "Epoch  30 Total Loss  6.876930794021668\n",
            "Epoch  30 Loss 1  0.00895708834433971\n",
            "Epoch  30 Loss 2 6.8679736989856455\n",
            "Starting epoch 31\n",
            "Loss after mini-batch    50: 14.85750316\n",
            "Loss after mini-batch   100: 1.65477998\n",
            "Loss after mini-batch   150: 4.61262272\n",
            "Loss after mini-batch   200: 2.17845678\n",
            "Loss after mini-batch   250: 0.33534780\n",
            "Loss after mini-batch   300: 0.01135660\n",
            "Loss after mini-batch   350: 0.02862592\n",
            "Loss after mini-batch   400: 0.04538268\n",
            "Epoch  31 Total Loss  2.753119977383807\n",
            "Epoch  31 Loss 1  0.007829138943676277\n",
            "Epoch  31 Loss 2 2.7452908802311016\n",
            "Starting epoch 32\n",
            "Loss after mini-batch    50: 29.53327250\n",
            "Loss after mini-batch   100: 2.12367616\n",
            "Loss after mini-batch   150: 4.43454076\n",
            "Loss after mini-batch   200: 0.66029719\n",
            "Loss after mini-batch   250: 0.04719530\n",
            "Loss after mini-batch   300: 0.02396332\n",
            "Loss after mini-batch   350: 0.02717006\n",
            "Loss after mini-batch   400: 0.00737611\n",
            "Epoch  32 Total Loss  4.237750071938955\n",
            "Epoch  32 Loss 1  0.007850388012685608\n",
            "Epoch  32 Loss 2 4.229899692983676\n",
            "Starting epoch 33\n",
            "Loss after mini-batch    50: 3.06260336\n",
            "Loss after mini-batch   100: 0.76493683\n",
            "Loss after mini-batch   150: 12.05705931\n",
            "Loss after mini-batch   200: 1.64619808\n",
            "Loss after mini-batch   250: 0.32751829\n",
            "Loss after mini-batch   300: 0.02872526\n",
            "Loss after mini-batch   350: 0.08494653\n",
            "Loss after mini-batch   400: 1.16042138\n",
            "Epoch  33 Total Loss  3.726782431701953\n",
            "Epoch  33 Loss 1  0.010265796277452938\n",
            "Epoch  33 Loss 2 3.7165166441605164\n",
            "Starting epoch 34\n",
            "Loss after mini-batch    50: 4.47826515\n",
            "Loss after mini-batch   100: 5.89658429\n",
            "Loss after mini-batch   150: 33.02192303\n",
            "Loss after mini-batch   200: 2.31818483\n",
            "Loss after mini-batch   250: 3.46636700\n",
            "Loss after mini-batch   300: 0.33524877\n",
            "Loss after mini-batch   350: 0.30107173\n",
            "Loss after mini-batch   400: 0.08213966\n",
            "Epoch  34 Total Loss  5.812622594204228\n",
            "Epoch  34 Loss 1  0.012586295231770643\n",
            "Epoch  34 Loss 2 5.800036238296307\n",
            "Starting epoch 35\n",
            "Loss after mini-batch    50: 16.66120882\n",
            "Loss after mini-batch   100: 5.20324091\n",
            "Loss after mini-batch   150: 8.53364903\n",
            "Loss after mini-batch   200: 1.25279622\n",
            "Loss after mini-batch   250: 0.20125106\n",
            "Loss after mini-batch   300: 0.02149351\n",
            "Loss after mini-batch   350: 0.02407912\n",
            "Loss after mini-batch   400: 0.03145853\n",
            "Epoch  35 Total Loss  3.6884622124834157\n",
            "Epoch  35 Loss 1  0.011727432850613236\n",
            "Epoch  35 Loss 2 3.6767347695914885\n",
            "Starting epoch 36\n",
            "Loss after mini-batch    50: 38.16031580\n",
            "Loss after mini-batch   100: 6.71808241\n",
            "Loss after mini-batch   150: 32.84797132\n",
            "Loss after mini-batch   200: 11.64314702\n",
            "Loss after mini-batch   250: 2.85947703\n",
            "Loss after mini-batch   300: 0.21531191\n",
            "Loss after mini-batch   350: 0.15358793\n",
            "Loss after mini-batch   400: 0.74620424\n",
            "Epoch  36 Total Loss  10.883114070044174\n",
            "Epoch  36 Loss 1  0.013598780307483004\n",
            "Epoch  36 Loss 2 10.869515398368966\n",
            "Starting epoch 37\n",
            "Loss after mini-batch    50: 1.79743845\n",
            "Loss after mini-batch   100: 0.17184888\n",
            "Loss after mini-batch   150: 5.65860441\n",
            "Loss after mini-batch   200: 1.13993823\n",
            "Loss after mini-batch   250: 0.29485529\n",
            "Loss after mini-batch   300: 0.01170033\n",
            "Loss after mini-batch   350: 0.01401972\n",
            "Loss after mini-batch   400: 0.01476894\n",
            "Epoch  37 Total Loss  1.0480760084722438\n",
            "Epoch  37 Loss 1  0.00887647001910754\n",
            "Epoch  37 Loss 2 1.0391995365978928\n",
            "Starting epoch 38\n",
            "Loss after mini-batch    50: 0.10542188\n",
            "Loss after mini-batch   100: 0.21860132\n",
            "Loss after mini-batch   150: 2.15648472\n",
            "Loss after mini-batch   200: 0.52568494\n",
            "Loss after mini-batch   250: 0.08163412\n",
            "Loss after mini-batch   300: 0.03796437\n",
            "Loss after mini-batch   350: 0.07852336\n",
            "Loss after mini-batch   400: 0.00695730\n",
            "Epoch  38 Total Loss  0.37254555936984424\n",
            "Epoch  38 Loss 1  0.009447152963356471\n",
            "Epoch  38 Loss 2 0.36309840631583346\n",
            "Starting epoch 39\n",
            "Loss after mini-batch    50: 3.52900041\n",
            "Loss after mini-batch   100: 0.45505947\n",
            "Loss after mini-batch   150: 6.18745471\n",
            "Loss after mini-batch   200: 0.65882366\n",
            "Loss after mini-batch   250: 0.04318213\n",
            "Loss after mini-batch   300: 0.06248495\n",
            "Loss after mini-batch   350: 0.01808389\n",
            "Loss after mini-batch   400: 0.01119700\n",
            "Epoch  39 Total Loss  1.2725166607743317\n",
            "Epoch  39 Loss 1  0.0095425117424841\n",
            "Epoch  39 Loss 2 1.262974177267584\n",
            "Starting epoch 40\n",
            "Loss after mini-batch    50: 1.24538454\n",
            "Loss after mini-batch   100: 2.32339114\n",
            "Loss after mini-batch   150: 27.82165848\n",
            "Loss after mini-batch   200: 1.60206360\n",
            "Loss after mini-batch   250: 0.25867665\n",
            "Loss after mini-batch   300: 0.08220845\n",
            "Loss after mini-batch   350: 0.15660102\n",
            "Loss after mini-batch   400: 0.05859613\n",
            "Epoch  40 Total Loss  3.873024759029904\n",
            "Epoch  40 Loss 1  0.00843512691433967\n",
            "Epoch  40 Loss 2 3.864589585286921\n",
            "Starting epoch 41\n",
            "Loss after mini-batch    50: 12.18001348\n",
            "Loss after mini-batch   100: 2.34427160\n",
            "Loss after mini-batch   150: 72.50441498\n",
            "Loss after mini-batch   200: 4.57429726\n",
            "Loss after mini-batch   250: 0.24986763\n",
            "Loss after mini-batch   300: 0.03958358\n",
            "Loss after mini-batch   350: 0.05057643\n",
            "Loss after mini-batch   400: 0.18543273\n",
            "Epoch  41 Total Loss  10.62067757168962\n",
            "Epoch  41 Loss 1  0.011223651868346061\n",
            "Epoch  41 Loss 2 10.609454108293152\n",
            "Starting epoch 42\n",
            "Loss after mini-batch    50: 2.22437397\n",
            "Loss after mini-batch   100: 0.41038697\n",
            "Loss after mini-batch   150: 9.75131691\n",
            "Loss after mini-batch   200: 0.31847164\n",
            "Loss after mini-batch   250: 0.05651629\n",
            "Loss after mini-batch   300: 0.01430961\n",
            "Loss after mini-batch   350: 0.01481441\n",
            "Loss after mini-batch   400: 0.06037890\n",
            "Epoch  42 Total Loss  1.499850053816983\n",
            "Epoch  42 Loss 1  0.008580374432549224\n",
            "Epoch  42 Loss 2 1.4912696794725575\n",
            "Starting epoch 43\n",
            "Loss after mini-batch    50: 6.50200355\n",
            "Loss after mini-batch   100: 1.00938733\n",
            "Loss after mini-batch   150: 12.42929627\n",
            "Loss after mini-batch   200: 1.84178540\n",
            "Loss after mini-batch   250: 0.04554344\n",
            "Loss after mini-batch   300: 0.01253989\n",
            "Loss after mini-batch   350: 0.01853818\n",
            "Loss after mini-batch   400: 0.03389761\n",
            "Epoch  43 Total Loss  2.5364957589823627\n",
            "Epoch  43 Loss 1  0.00980632164983558\n",
            "Epoch  43 Loss 2 2.5266894426844475\n",
            "Starting epoch 44\n",
            "Loss after mini-batch    50: 0.18626721\n",
            "Loss after mini-batch   100: 0.23821466\n",
            "Loss after mini-batch   150: 15.80121571\n",
            "Loss after mini-batch   200: 2.22604643\n",
            "Loss after mini-batch   250: 0.10114489\n",
            "Loss after mini-batch   300: 0.01743455\n",
            "Loss after mini-batch   350: 0.04314760\n",
            "Loss after mini-batch   400: 0.37253911\n",
            "Epoch  44 Total Loss  2.420344539964212\n",
            "Epoch  44 Loss 1  0.01075234006732052\n",
            "Epoch  44 Loss 2 2.4095922139741153\n",
            "Starting epoch 45\n",
            "Loss after mini-batch    50: 0.68065542\n",
            "Loss after mini-batch   100: 0.15184986\n",
            "Loss after mini-batch   150: 7.54358938\n",
            "Loss after mini-batch   200: 2.24334120\n",
            "Loss after mini-batch   250: 0.50550454\n",
            "Loss after mini-batch   300: 0.01592145\n",
            "Loss after mini-batch   350: 0.03289192\n",
            "Loss after mini-batch   400: 0.28042025\n",
            "Epoch  45 Total Loss  1.4238514033161591\n",
            "Epoch  45 Loss 1  0.010214989727390421\n",
            "Epoch  45 Loss 2 1.4136364081833628\n",
            "Starting epoch 46\n",
            "Loss after mini-batch    50: 7.03149716\n",
            "Loss after mini-batch   100: 0.67390195\n",
            "Loss after mini-batch   150: 0.12632555\n",
            "Loss after mini-batch   200: 0.10176094\n",
            "Loss after mini-batch   250: 0.01922072\n",
            "Loss after mini-batch   300: 0.01622519\n",
            "Loss after mini-batch   350: 0.01489870\n",
            "Loss after mini-batch   400: 0.01005111\n",
            "Epoch  46 Total Loss  0.9206833682568811\n",
            "Epoch  46 Loss 1  0.008943876973888569\n",
            "Epoch  46 Loss 2 0.9117394896281237\n",
            "Starting epoch 47\n",
            "Loss after mini-batch    50: 0.03458607\n",
            "Loss after mini-batch   100: 0.03720081\n",
            "Loss after mini-batch   150: 0.60113491\n",
            "Loss after mini-batch   200: 0.16884205\n",
            "Loss after mini-batch   250: 0.02226924\n",
            "Loss after mini-batch   300: 0.01707038\n",
            "Loss after mini-batch   350: 0.01749550\n",
            "Loss after mini-batch   400: 0.00910901\n",
            "Epoch  47 Total Loss  0.10658459385758133\n",
            "Epoch  47 Loss 1  0.008201957376409207\n",
            "Epoch  47 Loss 2 0.09838263608576597\n",
            "Starting epoch 48\n",
            "Loss after mini-batch    50: 0.06633976\n",
            "Loss after mini-batch   100: 0.09463829\n",
            "Loss after mini-batch   150: 2.94623263\n",
            "Loss after mini-batch   200: 0.35631847\n",
            "Loss after mini-batch   250: 0.48861913\n",
            "Loss after mini-batch   300: 0.09782517\n",
            "Loss after mini-batch   350: 0.20317096\n",
            "Loss after mini-batch   400: 0.02158555\n",
            "Epoch  48 Total Loss  0.4965234966560159\n",
            "Epoch  48 Loss 1  0.008937046752866102\n",
            "Epoch  48 Loss 2 0.4875864409807529\n",
            "Starting epoch 49\n",
            "Loss after mini-batch    50: 6.99196357\n",
            "Loss after mini-batch   100: 4.58945924\n",
            "Loss after mini-batch   150: 40.24023026\n",
            "Loss after mini-batch   200: 1.96276861\n",
            "Loss after mini-batch   250: 0.18926755\n",
            "Loss after mini-batch   300: 0.02277563\n",
            "Loss after mini-batch   350: 0.02814283\n",
            "Loss after mini-batch   400: 0.06646538\n",
            "Epoch  49 Total Loss  6.228081980870495\n",
            "Epoch  49 Loss 1  0.011560483279357157\n",
            "Epoch  49 Loss 2 6.2165213542547475\n",
            "Starting epoch 50\n",
            "Loss after mini-batch    50: 8.31025526\n",
            "Loss after mini-batch   100: 0.78460992\n",
            "Loss after mini-batch   150: 2.04191567\n",
            "Loss after mini-batch   200: 0.12561466\n",
            "Loss after mini-batch   250: 0.04279124\n",
            "Loss after mini-batch   300: 0.01284182\n",
            "Loss after mini-batch   350: 0.01623638\n",
            "Loss after mini-batch   400: 0.00853615\n",
            "Epoch  50 Total Loss  1.3069067583180112\n",
            "Epoch  50 Loss 1  0.009369520300261402\n",
            "Epoch  50 Loss 2 1.2975372359460082\n",
            "Starting epoch 51\n",
            "Loss after mini-batch    50: 0.54153064\n",
            "Loss after mini-batch   100: 0.11302583\n",
            "Loss after mini-batch   150: 16.00508622\n",
            "Loss after mini-batch   200: 3.95110449\n",
            "Loss after mini-batch   250: 0.06765029\n",
            "Loss after mini-batch   300: 0.01671088\n",
            "Loss after mini-batch   350: 0.03899740\n",
            "Loss after mini-batch   400: 0.03225628\n",
            "Epoch  51 Total Loss  2.390842447544454\n",
            "Epoch  51 Loss 1  0.008042169976765398\n",
            "Epoch  51 Loss 2 2.382800302864387\n",
            "Starting epoch 52\n",
            "Loss after mini-batch    50: 10.23586696\n",
            "Loss after mini-batch   100: 1.97385957\n",
            "Loss after mini-batch   150: 19.09571548\n",
            "Loss after mini-batch   200: 8.57162684\n",
            "Loss after mini-batch   250: 2.18128547\n",
            "Loss after mini-batch   300: 0.06684501\n",
            "Loss after mini-batch   350: 0.03022853\n",
            "Loss after mini-batch   400: 0.05670008\n",
            "Epoch  52 Total Loss  4.89028839582021\n",
            "Epoch  52 Loss 1  0.007793336177268032\n",
            "Epoch  52 Loss 2 4.88249506502311\n",
            "Starting epoch 53\n",
            "Loss after mini-batch    50: 8.24745977\n",
            "Loss after mini-batch   100: 0.11432641\n",
            "Loss after mini-batch   150: 0.03350359\n",
            "Loss after mini-batch   200: 0.04737942\n",
            "Loss after mini-batch   250: 0.04206167\n",
            "Loss after mini-batch   300: 0.01436750\n",
            "Loss after mini-batch   350: 0.01612228\n",
            "Loss after mini-batch   400: 0.00826675\n",
            "Epoch  53 Total Loss  0.981518162949432\n",
            "Epoch  53 Loss 1  0.008091245282504269\n",
            "Epoch  53 Loss 2 0.973426953524386\n",
            "Starting epoch 54\n",
            "Loss after mini-batch    50: 0.17096397\n",
            "Loss after mini-batch   100: 0.21153991\n",
            "Loss after mini-batch   150: 2.08050930\n",
            "Loss after mini-batch   200: 0.22948961\n",
            "Loss after mini-batch   250: 0.25370350\n",
            "Loss after mini-batch   300: 0.07854016\n",
            "Loss after mini-batch   350: 0.15423479\n",
            "Loss after mini-batch   400: 0.03543238\n",
            "Epoch  54 Total Loss  0.375262145677699\n",
            "Epoch  54 Loss 1  0.00889776417051842\n",
            "Epoch  54 Loss 2 0.3663643890333739\n",
            "Starting epoch 55\n",
            "Loss after mini-batch    50: 0.51566282\n",
            "Loss after mini-batch   100: 0.18770240\n",
            "Loss after mini-batch   150: 1.66576858\n",
            "Loss after mini-batch   200: 2.09585186\n",
            "Loss after mini-batch   250: 0.22169558\n",
            "Loss after mini-batch   300: 0.03756591\n",
            "Loss after mini-batch   350: 0.03625833\n",
            "Loss after mini-batch   400: 0.16450495\n",
            "Epoch  55 Total Loss  0.6295498614236258\n",
            "Epoch  55 Loss 1  0.008214109138765937\n",
            "Epoch  55 Loss 2 0.6213357454574014\n",
            "Starting epoch 56\n",
            "Loss after mini-batch    50: 3.50538251\n",
            "Loss after mini-batch   100: 0.35784236\n",
            "Loss after mini-batch   150: 12.38833494\n",
            "Loss after mini-batch   200: 0.32899247\n",
            "Loss after mini-batch   250: 0.12560336\n",
            "Loss after mini-batch   300: 0.08093229\n",
            "Loss after mini-batch   350: 0.09085533\n",
            "Loss after mini-batch   400: 0.10210963\n",
            "Epoch  56 Total Loss  2.044630618195053\n",
            "Epoch  56 Loss 1  0.00992499956309671\n",
            "Epoch  56 Loss 2 2.0347056223633713\n",
            "Starting epoch 57\n",
            "Loss after mini-batch    50: 0.26439843\n",
            "Loss after mini-batch   100: 0.04802308\n",
            "Loss after mini-batch   150: 14.83428326\n",
            "Loss after mini-batch   200: 0.77093663\n",
            "Loss after mini-batch   250: 2.05557429\n",
            "Loss after mini-batch   300: 0.13322133\n",
            "Loss after mini-batch   350: 0.17189104\n",
            "Loss after mini-batch   400: 0.18094151\n",
            "Epoch  57 Total Loss  2.1551808468029106\n",
            "Epoch  57 Loss 1  0.010424102263892438\n",
            "Epoch  57 Loss 2 2.1447567559816436\n",
            "Starting epoch 58\n",
            "Loss after mini-batch    50: 8.95894351\n",
            "Loss after mini-batch   100: 1.35857542\n",
            "Loss after mini-batch   150: 11.46462097\n",
            "Loss after mini-batch   200: 0.06571675\n",
            "Loss after mini-batch   250: 0.04103491\n",
            "Loss after mini-batch   300: 0.02278390\n",
            "Loss after mini-batch   350: 0.01420220\n",
            "Loss after mini-batch   400: 0.00843666\n",
            "Epoch  58 Total Loss  2.526317909192083\n",
            "Epoch  58 Loss 1  0.009878311268060306\n",
            "Epoch  58 Loss 2 2.5164396027617473\n",
            "Starting epoch 59\n",
            "Loss after mini-batch    50: 14.89398625\n",
            "Loss after mini-batch   100: 1.71350222\n",
            "Loss after mini-batch   150: 0.22114965\n",
            "Loss after mini-batch   200: 0.02137340\n",
            "Loss after mini-batch   250: 0.03006318\n",
            "Loss after mini-batch   300: 0.02306879\n",
            "Loss after mini-batch   350: 0.02486164\n",
            "Loss after mini-batch   400: 0.00943086\n",
            "Epoch  59 Total Loss  1.9512863250804735\n",
            "Epoch  59 Loss 1  0.008791347456431611\n",
            "Epoch  59 Loss 2 1.942494978667886\n",
            "Starting epoch 60\n",
            "Loss after mini-batch    50: 3.39421362\n",
            "Loss after mini-batch   100: 0.34240722\n",
            "Loss after mini-batch   150: 10.62819300\n",
            "Loss after mini-batch   200: 1.07980462\n",
            "Loss after mini-batch   250: 0.14982639\n",
            "Loss after mini-batch   300: 0.02797713\n",
            "Loss after mini-batch   350: 0.02713292\n",
            "Loss after mini-batch   400: 1.17499962\n",
            "Epoch  60 Total Loss  2.017017580490323\n",
            "Epoch  60 Loss 1  0.009616715331085497\n",
            "Epoch  60 Loss 2 2.0074008721690255\n",
            "Starting epoch 61\n",
            "Loss after mini-batch    50: 3.74852234\n",
            "Loss after mini-batch   100: 0.27003357\n",
            "Loss after mini-batch   150: 6.73134246\n",
            "Loss after mini-batch   200: 2.46793341\n",
            "Loss after mini-batch   250: 0.34462063\n",
            "Loss after mini-batch   300: 0.02461768\n",
            "Loss after mini-batch   350: 0.04541052\n",
            "Loss after mini-batch   400: 0.00774676\n",
            "Epoch  61 Total Loss  1.578268843167495\n",
            "Epoch  61 Loss 1  0.009873483453702647\n",
            "Epoch  61 Loss 2 1.5683953566822615\n",
            "Starting epoch 62\n",
            "Loss after mini-batch    50: 13.73813059\n",
            "Loss after mini-batch   100: 4.08816595\n",
            "Loss after mini-batch   150: 10.15235175\n",
            "Loss after mini-batch   200: 0.16735134\n",
            "Loss after mini-batch   250: 0.04471247\n",
            "Loss after mini-batch   300: 0.01738955\n",
            "Loss after mini-batch   350: 0.01556906\n",
            "Loss after mini-batch   400: 0.00947421\n",
            "Epoch  62 Total Loss  3.2468307038411517\n",
            "Epoch  62 Loss 1  0.009035631346483861\n",
            "Epoch  62 Loss 2 3.2377950749867512\n",
            "Starting epoch 63\n",
            "Loss after mini-batch    50: 4.07150982\n",
            "Loss after mini-batch   100: 0.91203658\n",
            "Loss after mini-batch   150: 1.17957422\n",
            "Loss after mini-batch   200: 0.19359618\n",
            "Loss after mini-batch   250: 0.04933362\n",
            "Loss after mini-batch   300: 0.01178423\n",
            "Loss after mini-batch   350: 0.01506975\n",
            "Loss after mini-batch   400: 0.02519387\n",
            "Epoch  63 Total Loss  0.7471671866788512\n",
            "Epoch  63 Loss 1  0.009147982147258246\n",
            "Epoch  63 Loss 2 0.7380192043852677\n",
            "Starting epoch 64\n",
            "Loss after mini-batch    50: 0.25845396\n",
            "Loss after mini-batch   100: 0.04358787\n",
            "Loss after mini-batch   150: 3.34785504\n",
            "Loss after mini-batch   200: 2.61891172\n",
            "Loss after mini-batch   250: 0.18861887\n",
            "Loss after mini-batch   300: 0.02846518\n",
            "Loss after mini-batch   350: 0.02579345\n",
            "Loss after mini-batch   400: 0.02963194\n",
            "Epoch  64 Total Loss  0.7610491134872962\n",
            "Epoch  64 Loss 1  0.008667034782795771\n",
            "Epoch  64 Loss 2 0.7523820864335874\n",
            "Starting epoch 65\n",
            "Loss after mini-batch    50: 2.29356764\n",
            "Loss after mini-batch   100: 3.38393357\n",
            "Loss after mini-batch   150: 35.30878086\n",
            "Loss after mini-batch   200: 2.81939844\n",
            "Loss after mini-batch   250: 0.09554541\n",
            "Loss after mini-batch   300: 0.03316281\n",
            "Loss after mini-batch   350: 0.05001820\n",
            "Loss after mini-batch   400: 0.07521383\n",
            "Epoch  65 Total Loss  5.129896060551843\n",
            "Epoch  65 Loss 1  0.010471975386882076\n",
            "Epoch  65 Loss 2 5.119424089299499\n",
            "Starting epoch 66\n",
            "Loss after mini-batch    50: 1.29623175\n",
            "Loss after mini-batch   100: 0.98986345\n",
            "Loss after mini-batch   150: 69.18754195\n",
            "Loss after mini-batch   200: 14.23219582\n",
            "Loss after mini-batch   250: 7.06141994\n",
            "Loss after mini-batch   300: 0.05071759\n",
            "Loss after mini-batch   350: 0.03479610\n",
            "Loss after mini-batch   400: 0.40027815\n",
            "Epoch  66 Total Loss  10.925459487388029\n",
            "Epoch  66 Loss 1  0.011817168815740707\n",
            "Epoch  66 Loss 2 10.913642416523599\n",
            "Starting epoch 67\n",
            "Loss after mini-batch    50: 2.94842171\n",
            "Loss after mini-batch   100: 0.51860394\n",
            "Loss after mini-batch   150: 0.33003748\n",
            "Loss after mini-batch   200: 0.12610631\n",
            "Loss after mini-batch   250: 0.10576836\n",
            "Loss after mini-batch   300: 0.02838078\n",
            "Loss after mini-batch   350: 0.01912107\n",
            "Loss after mini-batch   400: 0.02631354\n",
            "Epoch  67 Total Loss  0.5593342981117425\n",
            "Epoch  67 Loss 1  0.009548067213414136\n",
            "Epoch  67 Loss 2 0.5497862402795932\n",
            "Starting epoch 68\n",
            "Loss after mini-batch    50: 0.16472052\n",
            "Loss after mini-batch   100: 0.10270865\n",
            "Loss after mini-batch   150: 16.63688937\n",
            "Loss after mini-batch   200: 0.11907589\n",
            "Loss after mini-batch   250: 0.04816961\n",
            "Loss after mini-batch   300: 0.02578007\n",
            "Loss after mini-batch   350: 0.02115912\n",
            "Loss after mini-batch   400: 0.03003974\n",
            "Epoch  68 Total Loss  1.9820330979323517\n",
            "Epoch  68 Loss 1  0.009460518968939893\n",
            "Epoch  68 Loss 2 1.9725725771615397\n",
            "Starting epoch 69\n",
            "Loss after mini-batch    50: 1.62992944\n",
            "Loss after mini-batch   100: 1.03391325\n",
            "Loss after mini-batch   150: 16.05973711\n",
            "Loss after mini-batch   200: 4.19591435\n",
            "Loss after mini-batch   250: 0.98141494\n",
            "Loss after mini-batch   300: 0.04653604\n",
            "Loss after mini-batch   350: 0.02441869\n",
            "Loss after mini-batch   400: 0.25369416\n",
            "Epoch  69 Total Loss  2.972619650375043\n",
            "Epoch  69 Loss 1  0.01070480022913791\n",
            "Epoch  69 Loss 2 2.961914830412394\n",
            "Starting epoch 70\n",
            "Loss after mini-batch    50: 0.15311102\n",
            "Loss after mini-batch   100: 0.07215361\n",
            "Loss after mini-batch   150: 0.10287777\n",
            "Loss after mini-batch   200: 0.06784777\n",
            "Loss after mini-batch   250: 0.04490549\n",
            "Loss after mini-batch   300: 0.01287029\n",
            "Loss after mini-batch   350: 0.01369014\n",
            "Loss after mini-batch   400: 0.05740516\n",
            "Epoch  70 Total Loss  0.07005273265428838\n",
            "Epoch  70 Loss 1  0.008780980661552234\n",
            "Epoch  70 Loss 2 0.061271751351692584\n",
            "Starting epoch 71\n",
            "Loss after mini-batch    50: 0.20321371\n",
            "Loss after mini-batch   100: 0.19444482\n",
            "Loss after mini-batch   150: 1.17370964\n",
            "Loss after mini-batch   200: 0.04420937\n",
            "Loss after mini-batch   250: 0.04000416\n",
            "Loss after mini-batch   300: 0.01992163\n",
            "Loss after mini-batch   350: 0.02542581\n",
            "Loss after mini-batch   400: 0.03057978\n",
            "Epoch  71 Total Loss  0.22196342960184362\n",
            "Epoch  71 Loss 1  0.008503340857907\n",
            "Epoch  71 Loss 2 0.21346008715852502\n",
            "Starting epoch 72\n",
            "Loss after mini-batch    50: 11.43424460\n",
            "Loss after mini-batch   100: 1.42409642\n",
            "Loss after mini-batch   150: 6.95037914\n",
            "Loss after mini-batch   200: 3.73247352\n",
            "Loss after mini-batch   250: 3.63566921\n",
            "Loss after mini-batch   300: 0.06689844\n",
            "Loss after mini-batch   350: 0.15821691\n",
            "Loss after mini-batch   400: 0.21531486\n",
            "Epoch  72 Total Loss  3.1908128436397303\n",
            "Epoch  72 Loss 1  0.009943236387393306\n",
            "Epoch  72 Loss 2 3.180869598759349\n",
            "Starting epoch 73\n",
            "Loss after mini-batch    50: 2.94602091\n",
            "Loss after mini-batch   100: 0.24610236\n",
            "Loss after mini-batch   150: 1.02211321\n",
            "Loss after mini-batch   200: 0.26985373\n",
            "Loss after mini-batch   250: 0.04560364\n",
            "Loss after mini-batch   300: 0.01222970\n",
            "Loss after mini-batch   350: 0.01408502\n",
            "Loss after mini-batch   400: 0.01523686\n",
            "Epoch  73 Total Loss  0.5291936863498878\n",
            "Epoch  73 Loss 1  0.00887893570722146\n",
            "Epoch  73 Loss 2 0.5203147527940889\n",
            "Starting epoch 74\n",
            "Loss after mini-batch    50: 0.75257122\n",
            "Loss after mini-batch   100: 0.10463170\n",
            "Loss after mini-batch   150: 3.10930517\n",
            "Loss after mini-batch   200: 1.08165544\n",
            "Loss after mini-batch   250: 0.10850507\n",
            "Loss after mini-batch   300: 0.01286214\n",
            "Loss after mini-batch   350: 0.01654103\n",
            "Loss after mini-batch   400: 0.02500432\n",
            "Epoch  74 Total Loss  0.6141457100309436\n",
            "Epoch  74 Loss 1  0.009159361150146839\n",
            "Epoch  74 Loss 2 0.6049863507979285\n",
            "Starting epoch 75\n",
            "Loss after mini-batch    50: 2.74769384\n",
            "Loss after mini-batch   100: 1.01182643\n",
            "Loss after mini-batch   150: 20.01039914\n",
            "Loss after mini-batch   200: 10.06799169\n",
            "Loss after mini-batch   250: 8.02789452\n",
            "Loss after mini-batch   300: 0.23241588\n",
            "Loss after mini-batch   350: 3.50330386\n",
            "Loss after mini-batch   400: 7.58244420\n",
            "Epoch  75 Total Loss  6.195223736359821\n",
            "Epoch  75 Loss 1  0.013340460209350901\n",
            "Epoch  75 Loss 2 6.181883255981097\n",
            "Starting epoch 76\n",
            "Loss after mini-batch    50: 7.67829535\n",
            "Loss after mini-batch   100: 0.48000888\n",
            "Loss after mini-batch   150: 8.82219363\n",
            "Loss after mini-batch   200: 6.69416210\n",
            "Loss after mini-batch   250: 0.98385504\n",
            "Loss after mini-batch   300: 0.06816152\n",
            "Loss after mini-batch   350: 0.11420787\n",
            "Loss after mini-batch   400: 0.00919456\n",
            "Epoch  76 Total Loss  2.976616241271061\n",
            "Epoch  76 Loss 1  0.010617565301013775\n",
            "Epoch  76 Loss 2 2.965998667797008\n",
            "Starting epoch 77\n",
            "Loss after mini-batch    50: 17.30447349\n",
            "Loss after mini-batch   100: 0.37503571\n",
            "Loss after mini-batch   150: 19.48920270\n",
            "Loss after mini-batch   200: 0.28501592\n",
            "Loss after mini-batch   250: 0.11044629\n",
            "Loss after mini-batch   300: 0.06504105\n",
            "Loss after mini-batch   350: 0.14703565\n",
            "Loss after mini-batch   400: 0.05615945\n",
            "Epoch  77 Total Loss  4.410997141759423\n",
            "Epoch  77 Loss 1  0.00975644752822633\n",
            "Epoch  77 Loss 2 4.401240682735087\n",
            "Starting epoch 78\n",
            "Loss after mini-batch    50: 8.22619940\n",
            "Loss after mini-batch   100: 1.57244324\n",
            "Loss after mini-batch   150: 20.48757441\n",
            "Loss after mini-batch   200: 5.01474050\n",
            "Loss after mini-batch   250: 1.53025581\n",
            "Loss after mini-batch   300: 0.12282525\n",
            "Loss after mini-batch   350: 0.05517400\n",
            "Loss after mini-batch   400: 1.24412670\n",
            "Epoch  78 Total Loss  4.737731887735125\n",
            "Epoch  78 Loss 1  0.011845396378119185\n",
            "Epoch  78 Loss 2 4.725886493062211\n",
            "Starting epoch 79\n",
            "Loss after mini-batch    50: 26.98623499\n",
            "Loss after mini-batch   100: 9.61772558\n",
            "Loss after mini-batch   150: 2.81809978\n",
            "Loss after mini-batch   200: 0.99149248\n",
            "Loss after mini-batch   250: 0.10712124\n",
            "Loss after mini-batch   300: 0.01689338\n",
            "Loss after mini-batch   350: 0.02151487\n",
            "Loss after mini-batch   400: 0.01983962\n",
            "Epoch  79 Total Loss  4.685105523069161\n",
            "Epoch  79 Loss 1  0.01043882805639316\n",
            "Epoch  79 Loss 2 4.674666658736215\n",
            "Starting epoch 80\n",
            "Loss after mini-batch    50: 0.41513991\n",
            "Loss after mini-batch   100: 0.12838477\n",
            "Loss after mini-batch   150: 11.67554359\n",
            "Loss after mini-batch   200: 6.92970550\n",
            "Loss after mini-batch   250: 6.66582337\n",
            "Loss after mini-batch   300: 0.73879250\n",
            "Loss after mini-batch   350: 1.90687187\n",
            "Loss after mini-batch   400: 2.95351629\n",
            "Epoch  80 Total Loss  3.6839467113076383\n",
            "Epoch  80 Loss 1  0.0118528606259154\n",
            "Epoch  80 Loss 2 3.6720938441192796\n",
            "Starting epoch 81\n",
            "Loss after mini-batch    50: 8.08690263\n",
            "Loss after mini-batch   100: 1.13166630\n",
            "Loss after mini-batch   150: 3.54545047\n",
            "Loss after mini-batch   200: 0.80140056\n",
            "Loss after mini-batch   250: 0.15314075\n",
            "Loss after mini-batch   300: 0.01479526\n",
            "Loss after mini-batch   350: 0.01472753\n",
            "Loss after mini-batch   400: 0.00715630\n",
            "Epoch  81 Total Loss  1.584891371547573\n",
            "Epoch  81 Loss 1  0.008817333550207135\n",
            "Epoch  81 Loss 2 1.5760740382321792\n",
            "Starting epoch 82\n",
            "Loss after mini-batch    50: 0.94481859\n",
            "Loss after mini-batch   100: 0.10205657\n",
            "Loss after mini-batch   150: 7.60277577\n",
            "Loss after mini-batch   200: 3.08998346\n",
            "Loss after mini-batch   250: 0.33161412\n",
            "Loss after mini-batch   300: 0.02284531\n",
            "Loss after mini-batch   350: 0.03939806\n",
            "Loss after mini-batch   400: 0.10637376\n",
            "Epoch  82 Total Loss  1.4998267113534915\n",
            "Epoch  82 Loss 1  0.009343788460331591\n",
            "Epoch  82 Loss 2 1.4904829176411296\n",
            "Starting epoch 83\n",
            "Loss after mini-batch    50: 3.89528925\n",
            "Loss after mini-batch   100: 0.22571093\n",
            "Loss after mini-batch   150: 6.52402242\n",
            "Loss after mini-batch   200: 2.04069622\n",
            "Loss after mini-batch   250: 0.16539496\n",
            "Loss after mini-batch   300: 0.01615842\n",
            "Loss after mini-batch   350: 0.01117745\n",
            "Loss after mini-batch   400: 0.00795488\n",
            "Epoch  83 Total Loss  1.4854773759051099\n",
            "Epoch  83 Loss 1  0.009854575498897686\n",
            "Epoch  83 Loss 2 1.4756228057226608\n",
            "Starting epoch 84\n",
            "Loss after mini-batch    50: 0.04905727\n",
            "Loss after mini-batch   100: 0.02309146\n",
            "Loss after mini-batch   150: 2.57391714\n",
            "Loss after mini-batch   200: 0.16961677\n",
            "Loss after mini-batch   250: 1.42231713\n",
            "Loss after mini-batch   300: 0.01514168\n",
            "Loss after mini-batch   350: 0.01527157\n",
            "Loss after mini-batch   400: 0.15350339\n",
            "Epoch  84 Total Loss  0.5749692078316002\n",
            "Epoch  84 Loss 1  0.0085647810834939\n",
            "Epoch  84 Loss 2 0.5664044277999737\n",
            "Starting epoch 85\n",
            "Loss after mini-batch    50: 2.69750727\n",
            "Loss after mini-batch   100: 2.00783048\n",
            "Loss after mini-batch   150: 23.34399499\n",
            "Loss after mini-batch   200: 0.17978905\n",
            "Loss after mini-batch   250: 0.28067054\n",
            "Loss after mini-batch   300: 0.04642018\n",
            "Loss after mini-batch   350: 0.03187934\n",
            "Loss after mini-batch   400: 0.61191553\n",
            "Epoch  85 Total Loss  3.671752794628352\n",
            "Epoch  85 Loss 1  0.010260264015022554\n",
            "Epoch  85 Loss 2 3.661492500257133\n",
            "Starting epoch 86\n",
            "Loss after mini-batch    50: 4.65942001\n",
            "Loss after mini-batch   100: 1.07197875\n",
            "Loss after mini-batch   150: 18.85234144\n",
            "Loss after mini-batch   200: 2.10214079\n",
            "Loss after mini-batch   250: 0.88371350\n",
            "Loss after mini-batch   300: 0.07811301\n",
            "Loss after mini-batch   350: 0.03553030\n",
            "Loss after mini-batch   400: 0.10577797\n",
            "Epoch  86 Total Loss  3.281112660995813\n",
            "Epoch  86 Loss 1  0.008093981321219652\n",
            "Epoch  86 Loss 2 3.2730187031714277\n",
            "Starting epoch 87\n",
            "Loss after mini-batch    50: 26.77098245\n",
            "Loss after mini-batch   100: 10.51356598\n",
            "Loss after mini-batch   150: 29.48610378\n",
            "Loss after mini-batch   200: 3.40756455\n",
            "Loss after mini-batch   250: 0.15170719\n",
            "Loss after mini-batch   300: 0.01886693\n",
            "Loss after mini-batch   350: 0.02197165\n",
            "Loss after mini-batch   400: 0.17176736\n",
            "Epoch  87 Total Loss  8.214980137608437\n",
            "Epoch  87 Loss 1  0.0095764715830667\n",
            "Epoch  87 Loss 2 8.205403624270046\n",
            "Starting epoch 88\n",
            "Loss after mini-batch    50: 4.77115410\n",
            "Loss after mini-batch   100: 0.55797392\n",
            "Loss after mini-batch   150: 0.12568926\n",
            "Loss after mini-batch   200: 0.07862150\n",
            "Loss after mini-batch   250: 0.19663050\n",
            "Loss after mini-batch   300: 0.02516768\n",
            "Loss after mini-batch   350: 0.02737359\n",
            "Loss after mini-batch   400: 0.01038655\n",
            "Epoch  88 Total Loss  0.6704673637074001\n",
            "Epoch  88 Loss 1  0.008365061470700813\n",
            "Epoch  88 Loss 2 0.6621022995603211\n",
            "Starting epoch 89\n",
            "Loss after mini-batch    50: 1.25179255\n",
            "Loss after mini-batch   100: 1.13143826\n",
            "Loss after mini-batch   150: 18.81974829\n",
            "Loss after mini-batch   200: 10.51048839\n",
            "Loss after mini-batch   250: 0.79977391\n",
            "Loss after mini-batch   300: 0.03314470\n",
            "Loss after mini-batch   350: 0.04743081\n",
            "Loss after mini-batch   400: 0.02807093\n",
            "Epoch  89 Total Loss  3.829300940967833\n",
            "Epoch  89 Loss 1  0.00812619572326634\n",
            "Epoch  89 Loss 2 3.8211746971542344\n",
            "Starting epoch 90\n",
            "Loss after mini-batch    50: 15.02930586\n",
            "Loss after mini-batch   100: 0.60933175\n",
            "Loss after mini-batch   150: 6.05107443\n",
            "Loss after mini-batch   200: 1.54521107\n",
            "Loss after mini-batch   250: 0.23546453\n",
            "Loss after mini-batch   300: 0.01180866\n",
            "Loss after mini-batch   350: 0.05231969\n",
            "Loss after mini-batch   400: 0.15882419\n",
            "Epoch  90 Total Loss  2.7813054374535273\n",
            "Epoch  90 Loss 1  0.007444989426447388\n",
            "Epoch  90 Loss 2 2.7738604498324366\n",
            "Starting epoch 91\n",
            "Loss after mini-batch    50: 10.33091666\n",
            "Loss after mini-batch   100: 1.50368020\n",
            "Loss after mini-batch   150: 18.75076885\n",
            "Loss after mini-batch   200: 5.54979124\n",
            "Loss after mini-batch   250: 2.00821756\n",
            "Loss after mini-batch   300: 0.11297690\n",
            "Loss after mini-batch   350: 0.15438449\n",
            "Loss after mini-batch   400: 0.18719256\n",
            "Epoch  91 Total Loss  4.485301558057769\n",
            "Epoch  91 Loss 1  0.007601556534325351\n",
            "Epoch  91 Loss 2 4.477699972066884\n",
            "Starting epoch 92\n",
            "Loss after mini-batch    50: 21.21717485\n",
            "Loss after mini-batch   100: 0.64913969\n",
            "Loss after mini-batch   150: 13.28000130\n",
            "Loss after mini-batch   200: 2.11182004\n",
            "Loss after mini-batch   250: 0.84631975\n",
            "Loss after mini-batch   300: 0.03071732\n",
            "Loss after mini-batch   350: 0.04773199\n",
            "Loss after mini-batch   400: 0.03912142\n",
            "Epoch  92 Total Loss  4.486499699978346\n",
            "Epoch  92 Loss 1  0.007453258632694579\n",
            "Epoch  92 Loss 2 4.479046484175138\n",
            "Starting epoch 93\n",
            "Loss after mini-batch    50: 52.62840486\n",
            "Loss after mini-batch   100: 5.17877635\n",
            "Loss after mini-batch   150: 12.59647352\n",
            "Loss after mini-batch   200: 1.88077541\n",
            "Loss after mini-batch   250: 0.10769841\n",
            "Loss after mini-batch   300: 0.04759620\n",
            "Loss after mini-batch   350: 0.02684937\n",
            "Loss after mini-batch   400: 0.25242078\n",
            "Epoch  93 Total Loss  8.441006633374592\n",
            "Epoch  93 Loss 1  0.00988026823941819\n",
            "Epoch  93 Loss 2 8.431126383371844\n",
            "Starting epoch 94\n",
            "Loss after mini-batch    50: 4.46315478\n",
            "Loss after mini-batch   100: 1.01509970\n",
            "Loss after mini-batch   150: 1.36449796\n",
            "Loss after mini-batch   200: 0.10301016\n",
            "Loss after mini-batch   250: 0.19595129\n",
            "Loss after mini-batch   300: 0.01047198\n",
            "Loss after mini-batch   350: 0.02261757\n",
            "Loss after mini-batch   400: 0.02166846\n",
            "Epoch  94 Total Loss  0.8321162760762751\n",
            "Epoch  94 Loss 1  0.008346165934395768\n",
            "Epoch  94 Loss 2 0.8237701052559638\n",
            "Starting epoch 95\n",
            "Loss after mini-batch    50: 0.22662338\n",
            "Loss after mini-batch   100: 0.38628924\n",
            "Loss after mini-batch   150: 5.43422324\n",
            "Loss after mini-batch   200: 3.37040806\n",
            "Loss after mini-batch   250: 0.57518846\n",
            "Loss after mini-batch   300: 0.04979327\n",
            "Loss after mini-batch   350: 0.05334009\n",
            "Loss after mini-batch   400: 0.72914576\n",
            "Epoch  95 Total Loss  1.4024339873281149\n",
            "Epoch  95 Loss 1  0.008705399684558138\n",
            "Epoch  95 Loss 2 1.393728583119325\n",
            "Starting epoch 96\n",
            "Loss after mini-batch    50: 1.00420493\n",
            "Loss after mini-batch   100: 0.55961157\n",
            "Loss after mini-batch   150: 2.77725563\n",
            "Loss after mini-batch   200: 0.48292784\n",
            "Loss after mini-batch   250: 0.10806250\n",
            "Loss after mini-batch   300: 0.05128715\n",
            "Loss after mini-batch   350: 0.01904331\n",
            "Loss after mini-batch   400: 0.03578981\n",
            "Epoch  96 Total Loss  0.6016674430376847\n",
            "Epoch  96 Loss 1  0.008477512154602393\n",
            "Epoch  96 Loss 2 0.59318992926631\n",
            "Starting epoch 97\n",
            "Loss after mini-batch    50: 2.69980359\n",
            "Loss after mini-batch   100: 0.44413921\n",
            "Loss after mini-batch   150: 0.54476840\n",
            "Loss after mini-batch   200: 0.04682653\n",
            "Loss after mini-batch   250: 0.09785641\n",
            "Loss after mini-batch   300: 0.05733254\n",
            "Loss after mini-batch   350: 0.05902747\n",
            "Loss after mini-batch   400: 0.05391515\n",
            "Epoch  97 Total Loss  0.4740538946819522\n",
            "Epoch  97 Loss 1  0.008049527813314833\n",
            "Epoch  97 Loss 2 0.4660043701810392\n",
            "Starting epoch 98\n",
            "Loss after mini-batch    50: 1.72516131\n",
            "Loss after mini-batch   100: 0.51283631\n",
            "Loss after mini-batch   150: 0.65431861\n",
            "Loss after mini-batch   200: 0.06440709\n",
            "Loss after mini-batch   250: 0.10088534\n",
            "Loss after mini-batch   300: 0.02688908\n",
            "Loss after mini-batch   350: 0.02969028\n",
            "Loss after mini-batch   400: 0.00877463\n",
            "Epoch  98 Total Loss  0.37017550076630745\n",
            "Epoch  98 Loss 1  0.007872440639223259\n",
            "Epoch  98 Loss 2 0.3623030623981158\n",
            "Starting epoch 99\n",
            "Loss after mini-batch    50: 2.18276039\n",
            "Loss after mini-batch   100: 0.56875393\n",
            "Loss after mini-batch   150: 1.00317390\n",
            "Loss after mini-batch   200: 0.03040267\n",
            "Loss after mini-batch   250: 0.05499961\n",
            "Loss after mini-batch   300: 0.01663511\n",
            "Loss after mini-batch   350: 0.02174608\n",
            "Loss after mini-batch   400: 0.01174765\n",
            "Epoch  99 Total Loss  0.45067992931571904\n",
            "Epoch  99 Loss 1  0.007629720012332184\n",
            "Epoch  99 Loss 2 0.44305021561150815\n",
            "Starting epoch 100\n",
            "Loss after mini-batch    50: 0.02786626\n",
            "Loss after mini-batch   100: 0.02853249\n",
            "Loss after mini-batch   150: 2.23001669\n",
            "Loss after mini-batch   200: 0.25947279\n",
            "Loss after mini-batch   250: 0.14035128\n",
            "Loss after mini-batch   300: 0.02204802\n",
            "Loss after mini-batch   350: 0.02685950\n",
            "Loss after mini-batch   400: 0.10006917\n",
            "Epoch  100 Total Loss  0.3635753074338581\n",
            "Epoch  100 Loss 1  0.007594785171252509\n",
            "Epoch  100 Loss 2 0.3559805248799133\n",
            "Starting epoch 101\n",
            "Loss after mini-batch    50: 0.39706937\n",
            "Loss after mini-batch   100: 0.38265155\n",
            "Loss after mini-batch   150: 3.30805003\n",
            "Loss after mini-batch   200: 0.02809417\n",
            "Loss after mini-batch   250: 0.41660686\n",
            "Loss after mini-batch   300: 0.05308326\n",
            "Loss after mini-batch   350: 0.01350517\n",
            "Loss after mini-batch   400: 0.25760004\n",
            "Epoch  101 Total Loss  0.6361180660981068\n",
            "Epoch  101 Loss 1  0.008096708352240967\n",
            "Epoch  101 Loss 2 0.6280213565816517\n",
            "Starting epoch 102\n",
            "Loss after mini-batch    50: 6.39496794\n",
            "Loss after mini-batch   100: 1.67590896\n",
            "Loss after mini-batch   150: 17.99159124\n",
            "Loss after mini-batch   200: 1.98889703\n",
            "Loss after mini-batch   250: 1.79424738\n",
            "Loss after mini-batch   300: 0.32122804\n",
            "Loss after mini-batch   350: 0.72359930\n",
            "Loss after mini-batch   400: 1.60352603\n",
            "Epoch  102 Total Loss  3.783626660102481\n",
            "Epoch  102 Loss 1  0.009317550700155873\n",
            "Epoch  102 Loss 2 3.774309081757436\n",
            "Starting epoch 103\n",
            "Loss after mini-batch    50: 26.26102273\n",
            "Loss after mini-batch   100: 7.38443184\n",
            "Loss after mini-batch   150: 4.44223624\n",
            "Loss after mini-batch   200: 0.18888278\n",
            "Loss after mini-batch   250: 1.48663727\n",
            "Loss after mini-batch   300: 0.09139372\n",
            "Loss after mini-batch   350: 0.08899887\n",
            "Loss after mini-batch   400: 0.08506018\n",
            "Epoch  103 Total Loss  4.712215730570439\n",
            "Epoch  103 Loss 1  0.009380899726890895\n",
            "Epoch  103 Loss 2 4.702834969250649\n",
            "Starting epoch 104\n",
            "Loss after mini-batch    50: 6.12638811\n",
            "Loss after mini-batch   100: 1.50290204\n",
            "Loss after mini-batch   150: 406.17626434\n",
            "Loss after mini-batch   200: 0.70323773\n",
            "Loss after mini-batch   250: 0.76808255\n",
            "Loss after mini-batch   300: 0.02238792\n",
            "Loss after mini-batch   350: 0.14110274\n",
            "Loss after mini-batch   400: 0.27987730\n",
            "Epoch  104 Total Loss  47.97517462770783\n",
            "Epoch  104 Loss 1  0.009807071217734517\n",
            "Epoch  104 Loss 2 47.965368847801976\n",
            "Starting epoch 105\n",
            "Loss after mini-batch    50: 5.80984697\n",
            "Loss after mini-batch   100: 1.20706302\n",
            "Loss after mini-batch   150: 167.32290704\n",
            "Loss after mini-batch   200: 3.86130486\n",
            "Loss after mini-batch   250: 1.16425337\n",
            "Loss after mini-batch   300: 0.01889214\n",
            "Loss after mini-batch   350: 0.02279479\n",
            "Loss after mini-batch   400: 0.01521619\n",
            "Epoch  105 Total Loss  20.724018576880553\n",
            "Epoch  105 Loss 1  0.009931292112817354\n",
            "Epoch  105 Loss 2 20.714087443480167\n",
            "Starting epoch 106\n",
            "Loss after mini-batch    50: 39.09061530\n",
            "Loss after mini-batch   100: 5.32260439\n",
            "Loss after mini-batch   150: 0.57279506\n",
            "Loss after mini-batch   200: 0.06961506\n",
            "Loss after mini-batch   250: 0.04846537\n",
            "Loss after mini-batch   300: 0.01587449\n",
            "Loss after mini-batch   350: 0.01446760\n",
            "Loss after mini-batch   400: 0.02723829\n",
            "Epoch  106 Total Loss  5.204088634733899\n",
            "Epoch  106 Loss 1  0.010250977401242955\n",
            "Epoch  106 Loss 2 5.19383764000982\n",
            "Starting epoch 107\n",
            "Loss after mini-batch    50: 1.00883537\n",
            "Loss after mini-batch   100: 0.20401034\n",
            "Loss after mini-batch   150: 4.84417605\n",
            "Loss after mini-batch   200: 0.06662270\n",
            "Loss after mini-batch   250: 0.17535082\n",
            "Loss after mini-batch   300: 0.06324059\n",
            "Loss after mini-batch   350: 0.07525100\n",
            "Loss after mini-batch   400: 0.01689338\n",
            "Epoch  107 Total Loss  0.7479824766706372\n",
            "Epoch  107 Loss 1  0.008103481201285977\n",
            "Epoch  107 Loss 2 0.7398790120882323\n",
            "Starting epoch 108\n",
            "Loss after mini-batch    50: 8.83042023\n",
            "Loss after mini-batch   100: 6.34721395\n",
            "Loss after mini-batch   150: 21.67721062\n",
            "Loss after mini-batch   200: 1.76830811\n",
            "Loss after mini-batch   250: 0.77044352\n",
            "Loss after mini-batch   300: 0.00938840\n",
            "Loss after mini-batch   350: 0.03642454\n",
            "Loss after mini-batch   400: 0.09788912\n",
            "Epoch  108 Total Loss  4.571721973166713\n",
            "Epoch  108 Loss 1  0.007504639483505897\n",
            "Epoch  108 Loss 2 4.564217290967709\n",
            "Starting epoch 109\n",
            "Loss after mini-batch    50: 11.55185198\n",
            "Loss after mini-batch   100: 6.30141235\n",
            "Loss after mini-batch   150: 6.98755570\n",
            "Loss after mini-batch   200: 1.41745134\n",
            "Loss after mini-batch   250: 0.40481672\n",
            "Loss after mini-batch   300: 0.01429071\n",
            "Loss after mini-batch   350: 0.03163700\n",
            "Loss after mini-batch   400: 0.13272767\n",
            "Epoch  109 Total Loss  3.1897934369421015\n",
            "Epoch  109 Loss 1  0.0069516478134856105\n",
            "Epoch  109 Loss 2 3.1828418200498105\n",
            "Starting epoch 110\n",
            "Loss after mini-batch    50: 18.71741877\n",
            "Loss after mini-batch   100: 2.45789689\n",
            "Loss after mini-batch   150: 6.04473407\n",
            "Loss after mini-batch   200: 2.31375424\n",
            "Loss after mini-batch   250: 1.60196932\n",
            "Loss after mini-batch   300: 0.07302378\n",
            "Loss after mini-batch   350: 0.08254051\n",
            "Loss after mini-batch   400: 0.01281350\n",
            "Epoch  110 Total Loss  3.629392165329778\n",
            "Epoch  110 Loss 1  0.007355560997776833\n",
            "Epoch  110 Loss 2 3.622036647005175\n",
            "Starting epoch 111\n",
            "Loss after mini-batch    50: 15.16397153\n",
            "Loss after mini-batch   100: 3.14008397\n",
            "Loss after mini-batch   150: 156.39047917\n",
            "Loss after mini-batch   200: 9.89378092\n",
            "Loss after mini-batch   250: 0.24693715\n",
            "Loss after mini-batch   300: 0.02909610\n",
            "Loss after mini-batch   350: 0.03180571\n",
            "Loss after mini-batch   400: 0.18736575\n",
            "Epoch  111 Total Loss  21.29844401392971\n",
            "Epoch  111 Loss 1  0.01391985068609453\n",
            "Epoch  111 Loss 2 21.28452384959081\n",
            "Starting epoch 112\n",
            "Loss after mini-batch    50: 8.36214316\n",
            "Loss after mini-batch   100: 0.62110163\n",
            "Loss after mini-batch   150: 11.89339829\n",
            "Loss after mini-batch   200: 1.60995717\n",
            "Loss after mini-batch   250: 0.28044016\n",
            "Loss after mini-batch   300: 0.01667862\n",
            "Loss after mini-batch   350: 0.02385971\n",
            "Loss after mini-batch   400: 0.01603709\n",
            "Epoch  112 Total Loss  2.6362374960794113\n",
            "Epoch  112 Loss 1  0.009512741180548602\n",
            "Epoch  112 Loss 2 2.626724780065003\n",
            "Starting epoch 113\n",
            "Loss after mini-batch    50: 17.33768216\n",
            "Loss after mini-batch   100: 0.41536091\n",
            "Loss after mini-batch   150: 0.59197606\n",
            "Loss after mini-batch   200: 0.02906035\n",
            "Loss after mini-batch   250: 0.06262526\n",
            "Loss after mini-batch   300: 0.02086284\n",
            "Loss after mini-batch   350: 0.03613288\n",
            "Loss after mini-batch   400: 0.16183690\n",
            "Epoch  113 Total Loss  2.1574903960573475\n",
            "Epoch  113 Loss 1  0.008474996470262152\n",
            "Epoch  113 Loss 2 2.1490153756375165\n",
            "Starting epoch 114\n",
            "Loss after mini-batch    50: 1.17996948\n",
            "Loss after mini-batch   100: 0.12729307\n",
            "Loss after mini-batch   150: 1.84068775\n",
            "Loss after mini-batch   200: 0.89522920\n",
            "Loss after mini-batch   250: 0.51089188\n",
            "Loss after mini-batch   300: 0.02766007\n",
            "Loss after mini-batch   350: 0.01570673\n",
            "Loss after mini-batch   400: 0.01324636\n",
            "Epoch  114 Total Loss  0.5314741066948547\n",
            "Epoch  114 Loss 1  0.007836600737970713\n",
            "Epoch  114 Loss 2 0.5236375027252996\n",
            "Starting epoch 115\n",
            "Loss after mini-batch    50: 15.40794640\n",
            "Loss after mini-batch   100: 0.13075905\n",
            "Loss after mini-batch   150: 0.56015573\n",
            "Loss after mini-batch   200: 0.13366667\n",
            "Loss after mini-batch   250: 0.12734213\n",
            "Loss after mini-batch   300: 0.01305689\n",
            "Loss after mini-batch   350: 0.02345067\n",
            "Loss after mini-batch   400: 0.65768192\n",
            "Epoch  115 Total Loss  2.0278742709264845\n",
            "Epoch  115 Loss 1  0.007076601905182229\n",
            "Epoch  115 Loss 2 2.020797641002028\n",
            "Starting epoch 116\n",
            "Loss after mini-batch    50: 8.21490589\n",
            "Loss after mini-batch   100: 0.95141911\n",
            "Loss after mini-batch   150: 1.13561518\n",
            "Loss after mini-batch   200: 0.03927443\n",
            "Loss after mini-batch   250: 0.07155142\n",
            "Loss after mini-batch   300: 0.04163846\n",
            "Loss after mini-batch   350: 0.04005863\n",
            "Loss after mini-batch   400: 0.00717319\n",
            "Epoch  116 Total Loss  1.2125193052680379\n",
            "Epoch  116 Loss 1  0.007702111407807338\n",
            "Epoch  116 Loss 2 1.2048171707116304\n",
            "Starting epoch 117\n",
            "Loss after mini-batch    50: 0.17774827\n",
            "Loss after mini-batch   100: 0.15060582\n",
            "Loss after mini-batch   150: 0.14202938\n",
            "Loss after mini-batch   200: 0.09795422\n",
            "Loss after mini-batch   250: 0.01767350\n",
            "Loss after mini-batch   300: 0.01331437\n",
            "Loss after mini-batch   350: 0.01354606\n",
            "Loss after mini-batch   400: 0.01134088\n",
            "Epoch  117 Total Loss  0.07355959060929392\n",
            "Epoch  117 Loss 1  0.007337420269565579\n",
            "Epoch  117 Loss 2 0.06622217059885709\n",
            "Starting epoch 118\n",
            "Loss after mini-batch    50: 3.44293196\n",
            "Loss after mini-batch   100: 0.61212750\n",
            "Loss after mini-batch   150: 11.56122418\n",
            "Loss after mini-batch   200: 1.78468558\n",
            "Loss after mini-batch   250: 0.32813257\n",
            "Loss after mini-batch   300: 0.01572254\n",
            "Loss after mini-batch   350: 0.07290143\n",
            "Loss after mini-batch   400: 0.28803551\n",
            "Epoch  118 Total Loss  2.097303359038858\n",
            "Epoch  118 Loss 1  0.007221963623406141\n",
            "Epoch  118 Loss 2 2.0900814030917445\n",
            "Starting epoch 119\n",
            "Loss after mini-batch    50: 9.66303611\n",
            "Loss after mini-batch   100: 0.31661601\n",
            "Loss after mini-batch   150: 0.21525811\n",
            "Loss after mini-batch   200: 0.06758508\n",
            "Loss after mini-batch   250: 0.09276543\n",
            "Loss after mini-batch   300: 0.01109883\n",
            "Loss after mini-batch   350: 0.01385792\n",
            "Loss after mini-batch   400: 0.00590651\n",
            "Epoch  119 Total Loss  1.1986393164016789\n",
            "Epoch  119 Loss 1  0.006942421173700767\n",
            "Epoch  119 Loss 2 1.1916969052140138\n",
            "Starting epoch 120\n",
            "Loss after mini-batch    50: 3.19859471\n",
            "Loss after mini-batch   100: 0.81535113\n",
            "Loss after mini-batch   150: 1.10959486\n",
            "Loss after mini-batch   200: 0.35216281\n",
            "Loss after mini-batch   250: 0.15934483\n",
            "Loss after mini-batch   300: 0.07976451\n",
            "Loss after mini-batch   350: 0.16979460\n",
            "Loss after mini-batch   400: 0.00783463\n",
            "Epoch  120 Total Loss  0.6875429598621807\n",
            "Epoch  120 Loss 1  0.006746661383248852\n",
            "Epoch  120 Loss 2 0.6807962963836925\n",
            "Starting epoch 121\n",
            "Loss after mini-batch    50: 14.86729076\n",
            "Loss after mini-batch   100: 0.40037029\n",
            "Loss after mini-batch   150: 2.12947965\n",
            "Loss after mini-batch   200: 0.70136176\n",
            "Loss after mini-batch   250: 0.11114463\n",
            "Loss after mini-batch   300: 0.02196551\n",
            "Loss after mini-batch   350: 0.02391726\n",
            "Loss after mini-batch   400: 0.00970894\n",
            "Epoch  121 Total Loss  2.1093443301225254\n",
            "Epoch  121 Loss 1  0.007327330775664993\n",
            "Epoch  121 Loss 2 2.1020170731404706\n",
            "Starting epoch 122\n",
            "Loss after mini-batch    50: 1.67917868\n",
            "Loss after mini-batch   100: 0.44264438\n",
            "Loss after mini-batch   150: 2.58392390\n",
            "Loss after mini-batch   200: 0.97065184\n",
            "Loss after mini-batch   250: 0.05833409\n",
            "Loss after mini-batch   300: 0.01329545\n",
            "Loss after mini-batch   350: 0.01640029\n",
            "Loss after mini-batch   400: 0.00706857\n",
            "Epoch  122 Total Loss  0.6685117072056632\n",
            "Epoch  122 Loss 1  0.007014855727601539\n",
            "Epoch  122 Loss 2 0.6614968566473094\n",
            "Starting epoch 123\n",
            "Loss after mini-batch    50: 1.26001545\n",
            "Loss after mini-batch   100: 1.83475922\n",
            "Loss after mini-batch   150: 19.50419787\n",
            "Loss after mini-batch   200: 1.98741160\n",
            "Loss after mini-batch   250: 0.10027245\n",
            "Loss after mini-batch   300: 0.01364777\n",
            "Loss after mini-batch   350: 0.07177724\n",
            "Loss after mini-batch   400: 0.02035631\n",
            "Epoch  123 Total Loss  2.891052755151065\n",
            "Epoch  123 Loss 1  0.008244757349383763\n",
            "Epoch  123 Loss 2 2.882808004421379\n",
            "Starting epoch 124\n",
            "Loss after mini-batch    50: 7.75364781\n",
            "Loss after mini-batch   100: 0.73709828\n",
            "Loss after mini-batch   150: 3.25514088\n",
            "Loss after mini-batch   200: 0.49018523\n",
            "Loss after mini-batch   250: 0.14043331\n",
            "Loss after mini-batch   300: 0.08589469\n",
            "Loss after mini-batch   350: 0.10234870\n",
            "Loss after mini-batch   400: 0.28965508\n",
            "Epoch  124 Total Loss  1.622009378118088\n",
            "Epoch  124 Loss 1  0.009347532190306878\n",
            "Epoch  124 Loss 2 1.6126618420712413\n",
            "Starting epoch 125\n",
            "Loss after mini-batch    50: 7.05252317\n",
            "Loss after mini-batch   100: 5.15421820\n",
            "Loss after mini-batch   150: 19.34978838\n",
            "Loss after mini-batch   200: 15.19047285\n",
            "Loss after mini-batch   250: 1.64663221\n",
            "Loss after mini-batch   300: 0.39511385\n",
            "Loss after mini-batch   350: 0.42876014\n",
            "Loss after mini-batch   400: 0.95228721\n",
            "Epoch  125 Total Loss  6.015803371712227\n",
            "Epoch  125 Loss 1  0.009210034732903546\n",
            "Epoch  125 Loss 2 6.0065932993867595\n",
            "Starting epoch 126\n",
            "Loss after mini-batch    50: 13.25031478\n",
            "Loss after mini-batch   100: 4.00160984\n",
            "Loss after mini-batch   150: 34.55277897\n",
            "Loss after mini-batch   200: 16.22854377\n",
            "Loss after mini-batch   250: 1.18828150\n",
            "Loss after mini-batch   300: 0.11790882\n",
            "Loss after mini-batch   350: 0.11906348\n",
            "Loss after mini-batch   400: 0.64365772\n",
            "Epoch  126 Total Loss  8.294000844814335\n",
            "Epoch  126 Loss 1  0.008265840521842661\n",
            "Epoch  126 Loss 2 8.285735024343753\n",
            "Starting epoch 127\n",
            "Loss after mini-batch    50: 39.58448976\n",
            "Loss after mini-batch   100: 3.39660673\n",
            "Loss after mini-batch   150: 10.19859873\n",
            "Loss after mini-batch   200: 5.74632928\n",
            "Loss after mini-batch   250: 0.89621884\n",
            "Loss after mini-batch   300: 0.02642776\n",
            "Loss after mini-batch   350: 0.03421347\n",
            "Loss after mini-batch   400: 0.15342270\n",
            "Epoch  127 Total Loss  6.933866359283149\n",
            "Epoch  127 Loss 1  0.0077097851487900925\n",
            "Epoch  127 Loss 2 6.926156547104239\n",
            "Starting epoch 128\n",
            "Loss after mini-batch    50: 17.20381907\n",
            "Loss after mini-batch   100: 1.97713131\n",
            "Loss after mini-batch   150: 20.87658803\n",
            "Loss after mini-batch   200: 6.28153694\n",
            "Loss after mini-batch   250: 1.17063957\n",
            "Loss after mini-batch   300: 0.01418412\n",
            "Loss after mini-batch   350: 0.01758123\n",
            "Loss after mini-batch   400: 0.02358256\n",
            "Epoch  128 Total Loss  5.529806526663765\n",
            "Epoch  128 Loss 1  0.0072317768567020605\n",
            "Epoch  128 Loss 2 5.522574758602481\n",
            "Starting epoch 129\n",
            "Loss after mini-batch    50: 77.65328094\n",
            "Loss after mini-batch   100: 0.15159963\n",
            "Loss after mini-batch   150: 0.07890956\n",
            "Loss after mini-batch   200: 0.08776924\n",
            "Loss after mini-batch   250: 0.89129723\n",
            "Loss after mini-batch   300: 0.01576977\n",
            "Loss after mini-batch   350: 0.02406170\n",
            "Loss after mini-batch   400: 0.00693194\n",
            "Epoch  129 Total Loss  9.070681472295536\n",
            "Epoch  129 Loss 1  0.007552463911805267\n",
            "Epoch  129 Loss 2 9.063128838648392\n",
            "Starting epoch 130\n",
            "Loss after mini-batch    50: 0.92800213\n",
            "Loss after mini-batch   100: 0.12609410\n",
            "Loss after mini-batch   150: 0.95709757\n",
            "Loss after mini-batch   200: 0.17501601\n",
            "Loss after mini-batch   250: 0.82944948\n",
            "Loss after mini-batch   300: 0.11460065\n",
            "Loss after mini-batch   350: 0.23934335\n",
            "Loss after mini-batch   400: 0.18279917\n",
            "Epoch  130 Total Loss  0.4117123775361203\n",
            "Epoch  130 Loss 1  0.0078021284724447216\n",
            "Epoch  130 Loss 2 0.40391025130887026\n",
            "Starting epoch 131\n",
            "Loss after mini-batch    50: 4.35293312\n",
            "Loss after mini-batch   100: 0.45886541\n",
            "Loss after mini-batch   150: 1.99107957\n",
            "Loss after mini-batch   200: 0.40520558\n",
            "Loss after mini-batch   250: 0.26783284\n",
            "Loss after mini-batch   300: 0.10757959\n",
            "Loss after mini-batch   350: 0.17713751\n",
            "Loss after mini-batch   400: 0.02898726\n",
            "Epoch  131 Total Loss  0.9015514302505103\n",
            "Epoch  131 Loss 1  0.008769643718283758\n",
            "Epoch  131 Loss 2 0.8927817739214788\n",
            "Starting epoch 132\n",
            "Loss after mini-batch    50: 1.54698834\n",
            "Loss after mini-batch   100: 0.41351636\n",
            "Loss after mini-batch   150: 2.86471361\n",
            "Loss after mini-batch   200: 0.30011906\n",
            "Loss after mini-batch   250: 0.05355482\n",
            "Loss after mini-batch   300: 0.02976423\n",
            "Loss after mini-batch   350: 0.03546726\n",
            "Loss after mini-batch   400: 0.01154890\n",
            "Epoch  132 Total Loss  0.6225640466746933\n",
            "Epoch  132 Loss 1  0.007848502481680755\n",
            "Epoch  132 Loss 2 0.6147155448244053\n",
            "Starting epoch 133\n",
            "Loss after mini-batch    50: 9.60063019\n",
            "Loss after mini-batch   100: 1.25937211\n",
            "Loss after mini-batch   150: 3.22756267\n",
            "Loss after mini-batch   200: 1.07415762\n",
            "Loss after mini-batch   250: 0.18690189\n",
            "Loss after mini-batch   300: 0.08882619\n",
            "Loss after mini-batch   350: 0.21668535\n",
            "Loss after mini-batch   400: 0.53851264\n",
            "Epoch  133 Total Loss  1.9336366657053794\n",
            "Epoch  133 Loss 1  0.008784043595868388\n",
            "Epoch  133 Loss 2 1.924852628256087\n",
            "Starting epoch 134\n",
            "Loss after mini-batch    50: 1.78647369\n",
            "Loss after mini-batch   100: 0.43657235\n",
            "Loss after mini-batch   150: 3.55659588\n",
            "Loss after mini-batch   200: 0.74861987\n",
            "Loss after mini-batch   250: 0.17647291\n",
            "Loss after mini-batch   300: 0.01608148\n",
            "Loss after mini-batch   350: 0.01802353\n",
            "Loss after mini-batch   400: 0.24312261\n",
            "Epoch  134 Total Loss  0.8671788676591703\n",
            "Epoch  134 Loss 1  0.009556714725251117\n",
            "Epoch  134 Loss 2 0.8576221582147853\n",
            "Starting epoch 135\n",
            "Loss after mini-batch    50: 2.86930896\n",
            "Loss after mini-batch   100: 2.34142753\n",
            "Loss after mini-batch   150: 36.48102831\n",
            "Loss after mini-batch   200: 4.01886473\n",
            "Loss after mini-batch   250: 0.36045327\n",
            "Loss after mini-batch   300: 0.19304589\n",
            "Loss after mini-batch   350: 0.12274145\n",
            "Loss after mini-batch   400: 3.35735226\n",
            "Epoch  135 Total Loss  5.835104871414677\n",
            "Epoch  135 Loss 1  0.008605343985639582\n",
            "Epoch  135 Loss 2 5.826499562377223\n",
            "Starting epoch 136\n",
            "Loss after mini-batch    50: 18.08216842\n",
            "Loss after mini-batch   100: 0.33700735\n",
            "Loss after mini-batch   150: 16.42931348\n",
            "Loss after mini-batch   200: 1.26825529\n",
            "Loss after mini-batch   250: 3.32094406\n",
            "Loss after mini-batch   300: 0.04035414\n",
            "Loss after mini-batch   350: 0.80308684\n",
            "Loss after mini-batch   400: 0.66440650\n",
            "Epoch  136 Total Loss  4.812078849071434\n",
            "Epoch  136 Loss 1  0.01073785287339522\n",
            "Epoch  136 Loss 2 4.801340967937053\n",
            "Starting epoch 137\n",
            "Loss after mini-batch    50: 31.84978509\n",
            "Loss after mini-batch   100: 1.15974241\n",
            "Loss after mini-batch   150: 19.71624826\n",
            "Loss after mini-batch   200: 0.48537313\n",
            "Loss after mini-batch   250: 0.95661721\n",
            "Loss after mini-batch   300: 0.02285319\n",
            "Loss after mini-batch   350: 0.02636820\n",
            "Loss after mini-batch   400: 0.16307112\n",
            "Epoch  137 Total Loss  6.27276607313178\n",
            "Epoch  137 Loss 1  0.01358859484601129\n",
            "Epoch  137 Loss 2 6.259177384096098\n",
            "Starting epoch 138\n",
            "Loss after mini-batch    50: 2.37201040\n",
            "Loss after mini-batch   100: 0.29341336\n",
            "Loss after mini-batch   150: 0.25173682\n",
            "Loss after mini-batch   200: 0.16201876\n",
            "Loss after mini-batch   250: 0.08665410\n",
            "Loss after mini-batch   300: 0.01507849\n",
            "Loss after mini-batch   350: 0.01592737\n",
            "Loss after mini-batch   400: 0.03196218\n",
            "Epoch  138 Total Loss  0.38628557182196294\n",
            "Epoch  138 Loss 1  0.00814762735929947\n",
            "Epoch  138 Loss 2 0.3781379457674576\n",
            "Starting epoch 139\n",
            "Loss after mini-batch    50: 9.74335392\n",
            "Loss after mini-batch   100: 0.39361762\n",
            "Loss after mini-batch   150: 1.10946722\n",
            "Loss after mini-batch   200: 0.15280227\n",
            "Loss after mini-batch   250: 0.21205872\n",
            "Loss after mini-batch   300: 0.02014213\n",
            "Loss after mini-batch   350: 0.04146886\n",
            "Loss after mini-batch   400: 0.01118143\n",
            "Epoch  139 Total Loss  1.3614086465063766\n",
            "Epoch  139 Loss 1  0.008093173069260204\n",
            "Epoch  139 Loss 2 1.3533154802131362\n",
            "Starting epoch 140\n",
            "Loss after mini-batch    50: 4.56826377\n",
            "Loss after mini-batch   100: 0.37324238\n",
            "Loss after mini-batch   150: 2.15424220\n",
            "Loss after mini-batch   200: 0.52847635\n",
            "Loss after mini-batch   250: 0.29768618\n",
            "Loss after mini-batch   300: 0.03197284\n",
            "Loss after mini-batch   350: 0.03382459\n",
            "Loss after mini-batch   400: 0.28383919\n",
            "Epoch  140 Total Loss  1.0010805150716355\n",
            "Epoch  140 Loss 1  0.0079066607775175\n",
            "Epoch  140 Loss 2 0.9931738415669169\n",
            "Starting epoch 141\n",
            "Loss after mini-batch    50: 8.68033600\n",
            "Loss after mini-batch   100: 3.11924351\n",
            "Loss after mini-batch   150: 15.53540357\n",
            "Loss after mini-batch   200: 1.39581355\n",
            "Loss after mini-batch   250: 0.41291451\n",
            "Loss after mini-batch   300: 0.04161840\n",
            "Loss after mini-batch   350: 0.08130108\n",
            "Loss after mini-batch   400: 0.03465818\n",
            "Epoch  141 Total Loss  3.379265536405727\n",
            "Epoch  141 Loss 1  0.009908664565360575\n",
            "Epoch  141 Loss 2 3.3693569158042904\n",
            "Starting epoch 142\n",
            "Loss after mini-batch    50: 7.33018884\n",
            "Loss after mini-batch   100: 11.57905883\n",
            "Loss after mini-batch   150: 11.24141342\n",
            "Loss after mini-batch   200: 1.26558889\n",
            "Loss after mini-batch   250: 0.27709389\n",
            "Loss after mini-batch   300: 0.01187953\n",
            "Loss after mini-batch   350: 0.06146234\n",
            "Loss after mini-batch   400: 0.53450713\n",
            "Epoch  142 Total Loss  3.7467470397922007\n",
            "Epoch  142 Loss 1  0.008453404358342282\n",
            "Epoch  142 Loss 2 3.7382935984848147\n",
            "Starting epoch 143\n",
            "Loss after mini-batch    50: 9.63714000\n",
            "Loss after mini-batch   100: 1.80188494\n",
            "Loss after mini-batch   150: 14.21582426\n",
            "Loss after mini-batch   200: 4.40176782\n",
            "Loss after mini-batch   250: 1.72402125\n",
            "Loss after mini-batch   300: 0.01754033\n",
            "Loss after mini-batch   350: 0.04253692\n",
            "Loss after mini-batch   400: 1.86777433\n",
            "Epoch  143 Total Loss  3.9398244100237667\n",
            "Epoch  143 Loss 1  0.010751664262665897\n",
            "Epoch  143 Loss 2 3.929072711208501\n",
            "Starting epoch 144\n",
            "Loss after mini-batch    50: 62.60352468\n",
            "Loss after mini-batch   100: 1.78750091\n",
            "Loss after mini-batch   150: 12.30277738\n",
            "Loss after mini-batch   200: 0.95920047\n",
            "Loss after mini-batch   250: 0.36892337\n",
            "Loss after mini-batch   300: 0.01777129\n",
            "Loss after mini-batch   350: 0.05448105\n",
            "Loss after mini-batch   400: 0.10081756\n",
            "Epoch  144 Total Loss  8.998781899308735\n",
            "Epoch  144 Loss 1  0.010018373061899476\n",
            "Epoch  144 Loss 2 8.988763287982065\n",
            "Starting epoch 145\n",
            "Loss after mini-batch    50: 38.46647795\n",
            "Loss after mini-batch   100: 1.95730909\n",
            "Loss after mini-batch   150: 13.65139145\n",
            "Loss after mini-batch   200: 2.86282064\n",
            "Loss after mini-batch   250: 1.52124868\n",
            "Loss after mini-batch   300: 0.14541968\n",
            "Loss after mini-batch   350: 0.27565086\n",
            "Loss after mini-batch   400: 0.30767060\n",
            "Epoch  145 Total Loss  6.806045665978697\n",
            "Epoch  145 Loss 1  0.008265794358187289\n",
            "Epoch  145 Loss 2 6.797779775605926\n",
            "Starting epoch 146\n",
            "Loss after mini-batch    50: 0.17714988\n",
            "Loss after mini-batch   100: 0.02842384\n",
            "Loss after mini-batch   150: 2.62194957\n",
            "Loss after mini-batch   200: 1.73915300\n",
            "Loss after mini-batch   250: 0.27128737\n",
            "Loss after mini-batch   300: 0.00826840\n",
            "Loss after mini-batch   350: 0.01915996\n",
            "Loss after mini-batch   400: 0.07876904\n",
            "Epoch  146 Total Loss  0.6318888350870889\n",
            "Epoch  146 Loss 1  0.0074487039473762244\n",
            "Epoch  146 Loss 2 0.6244401295095504\n",
            "Starting epoch 147\n",
            "Loss after mini-batch    50: 1.24642247\n",
            "Loss after mini-batch   100: 0.28884634\n",
            "Loss after mini-batch   150: 15.43696569\n",
            "Loss after mini-batch   200: 3.12130638\n",
            "Loss after mini-batch   250: 1.04670103\n",
            "Loss after mini-batch   300: 0.02034719\n",
            "Loss after mini-batch   350: 0.02719090\n",
            "Loss after mini-batch   400: 0.12097361\n",
            "Epoch  147 Total Loss  2.4518868345044513\n",
            "Epoch  147 Loss 1  0.009797349000559055\n",
            "Epoch  147 Loss 2 2.442089488202446\n",
            "Starting epoch 148\n",
            "Loss after mini-batch    50: 1.35676686\n",
            "Loss after mini-batch   100: 0.26596949\n",
            "Loss after mini-batch   150: 0.31853742\n",
            "Loss after mini-batch   200: 0.29278697\n",
            "Loss after mini-batch   250: 0.18151764\n",
            "Loss after mini-batch   300: 0.01911617\n",
            "Loss after mini-batch   350: 0.01817604\n",
            "Loss after mini-batch   400: 0.02488693\n",
            "Epoch  148 Total Loss  0.285511988454494\n",
            "Epoch  148 Loss 1  0.008772230075790022\n",
            "Epoch  148 Loss 2 0.2767397597760639\n",
            "Starting epoch 149\n",
            "Loss after mini-batch    50: 0.09441807\n",
            "Loss after mini-batch   100: 0.13013682\n",
            "Loss after mini-batch   150: 0.31746597\n",
            "Loss after mini-batch   200: 0.06104109\n",
            "Loss after mini-batch   250: 0.11541098\n",
            "Loss after mini-batch   300: 0.01556728\n",
            "Loss after mini-batch   350: 0.01873262\n",
            "Loss after mini-batch   400: 0.01032246\n",
            "Epoch  149 Total Loss  0.08943074869865755\n",
            "Epoch  149 Loss 1  0.008285216596154844\n",
            "Epoch  149 Loss 2 0.08114553273917532\n",
            "Starting epoch 150\n",
            "Loss after mini-batch    50: 0.24594971\n",
            "Loss after mini-batch   100: 0.11866532\n",
            "Loss after mini-batch   150: 2.91469981\n",
            "Loss after mini-batch   200: 1.83623460\n",
            "Loss after mini-batch   250: 0.58768168\n",
            "Loss after mini-batch   300: 0.02108988\n",
            "Loss after mini-batch   350: 0.02386391\n",
            "Loss after mini-batch   400: 0.01664606\n",
            "Epoch  150 Total Loss  0.6702012697875787\n",
            "Epoch  150 Loss 1  0.007673999340050645\n",
            "Epoch  150 Loss 2 0.6625272697824327\n",
            "Starting epoch 151\n",
            "Loss after mini-batch    50: 0.30781040\n",
            "Loss after mini-batch   100: 0.15194017\n",
            "Loss after mini-batch   150: 3.90349249\n",
            "Loss after mini-batch   200: 1.50468277\n",
            "Loss after mini-batch   250: 0.85545463\n",
            "Loss after mini-batch   300: 0.01321343\n",
            "Loss after mini-batch   350: 0.01532976\n",
            "Loss after mini-batch   400: 0.03350346\n",
            "Epoch  151 Total Loss  0.7811083569963024\n",
            "Epoch  151 Loss 1  0.008785942024196733\n",
            "Epoch  151 Loss 2 0.7723224186094516\n",
            "Starting epoch 152\n",
            "Loss after mini-batch    50: 0.27010852\n",
            "Loss after mini-batch   100: 0.10744371\n",
            "Loss after mini-batch   150: 0.10306532\n",
            "Loss after mini-batch   200: 0.12062590\n",
            "Loss after mini-batch   250: 0.04589092\n",
            "Loss after mini-batch   300: 0.01216946\n",
            "Loss after mini-batch   350: 0.01362384\n",
            "Loss after mini-batch   400: 0.01348837\n",
            "Epoch  152 Total Loss  0.07991197513877722\n",
            "Epoch  152 Loss 1  0.0080923052087002\n",
            "Epoch  152 Loss 2 0.07181966943488531\n",
            "Starting epoch 153\n",
            "Loss after mini-batch    50: 0.06027026\n",
            "Loss after mini-batch   100: 0.09388678\n",
            "Loss after mini-batch   150: 1.63648791\n",
            "Loss after mini-batch   200: 0.55570781\n",
            "Loss after mini-batch   250: 0.24940484\n",
            "Loss after mini-batch   300: 0.01221078\n",
            "Loss after mini-batch   350: 0.01370916\n",
            "Loss after mini-batch   400: 0.03076286\n",
            "Epoch  153 Total Loss  0.3068207602054178\n",
            "Epoch  153 Loss 1  0.008415743447110945\n",
            "Epoch  153 Loss 2 0.2984050161562572\n",
            "Starting epoch 154\n",
            "Loss after mini-batch    50: 0.40966565\n",
            "Loss after mini-batch   100: 0.20240778\n",
            "Loss after mini-batch   150: 1.57142715\n",
            "Loss after mini-batch   200: 0.37996440\n",
            "Loss after mini-batch   250: 0.08753703\n",
            "Loss after mini-batch   300: 0.01422544\n",
            "Loss after mini-batch   350: 0.01757592\n",
            "Loss after mini-batch   400: 0.07425978\n",
            "Epoch  154 Total Loss  0.32072192395854715\n",
            "Epoch  154 Loss 1  0.008346284185203352\n",
            "Epoch  154 Loss 2 0.3123756391747861\n",
            "Starting epoch 155\n",
            "Loss after mini-batch    50: 0.47350985\n",
            "Loss after mini-batch   100: 0.27352368\n",
            "Loss after mini-batch   150: 0.93747501\n",
            "Loss after mini-batch   200: 0.11709796\n",
            "Loss after mini-batch   250: 0.05879277\n",
            "Loss after mini-batch   300: 0.01453327\n",
            "Loss after mini-batch   350: 0.01965285\n",
            "Loss after mini-batch   400: 0.03637071\n",
            "Epoch  155 Total Loss  0.22488651350331879\n",
            "Epoch  155 Loss 1  0.008132619551116509\n",
            "Epoch  155 Loss 2 0.21675389640797676\n",
            "Starting epoch 156\n",
            "Loss after mini-batch    50: 0.65389786\n",
            "Loss after mini-batch   100: 0.26868755\n",
            "Loss after mini-batch   150: 0.78363029\n",
            "Loss after mini-batch   200: 0.30892412\n",
            "Loss after mini-batch   250: 0.19242042\n",
            "Loss after mini-batch   300: 0.01139618\n",
            "Loss after mini-batch   350: 0.02040565\n",
            "Loss after mini-batch   400: 0.00808526\n",
            "Epoch  156 Total Loss  0.25929587655596203\n",
            "Epoch  156 Loss 1  0.007524740435950787\n",
            "Epoch  156 Loss 2 0.25177113617209634\n",
            "Starting epoch 157\n",
            "Loss after mini-batch    50: 0.24605196\n",
            "Loss after mini-batch   100: 0.27461625\n",
            "Loss after mini-batch   150: 2.04160377\n",
            "Loss after mini-batch   200: 0.71182131\n",
            "Loss after mini-batch   250: 0.45287946\n",
            "Loss after mini-batch   300: 0.01395882\n",
            "Loss after mini-batch   350: 0.01433575\n",
            "Loss after mini-batch   400: 0.05474688\n",
            "Epoch  157 Total Loss  0.45189516595563317\n",
            "Epoch  157 Loss 1  0.008037364581577586\n",
            "Epoch  157 Loss 2 0.44385780029398797\n",
            "Starting epoch 158\n",
            "Loss after mini-batch    50: 0.59094326\n",
            "Loss after mini-batch   100: 2.63555017\n",
            "Loss after mini-batch   150: 27.38855186\n",
            "Loss after mini-batch   200: 0.04349912\n",
            "Loss after mini-batch   250: 0.16583557\n",
            "Loss after mini-batch   300: 0.01629584\n",
            "Loss after mini-batch   350: 0.01417046\n",
            "Loss after mini-batch   400: 0.00905605\n",
            "Epoch  158 Total Loss  3.5514309845082983\n",
            "Epoch  158 Loss 1  0.0076003725864441435\n",
            "Epoch  158 Loss 2 3.543830672621753\n",
            "Starting epoch 159\n",
            "Loss after mini-batch    50: 14.36576815\n",
            "Loss after mini-batch   100: 10.12223909\n",
            "Loss after mini-batch   150: 18.88579746\n",
            "Loss after mini-batch   200: 0.05645294\n",
            "Loss after mini-batch   250: 0.38898736\n",
            "Loss after mini-batch   300: 0.01447781\n",
            "Loss after mini-batch   350: 0.01635598\n",
            "Loss after mini-batch   400: 0.03940453\n",
            "Epoch  159 Total Loss  5.068224183005061\n",
            "Epoch  159 Loss 1  0.008497803452379209\n",
            "Epoch  159 Loss 2 5.059726379378239\n",
            "Starting epoch 160\n",
            "Loss after mini-batch    50: 8.79358949\n",
            "Loss after mini-batch   100: 0.55480766\n",
            "Loss after mini-batch   150: 8.35283996\n",
            "Loss after mini-batch   200: 0.37345045\n",
            "Loss after mini-batch   250: 0.70521446\n",
            "Loss after mini-batch   300: 0.23949624\n",
            "Loss after mini-batch   350: 0.45125051\n",
            "Loss after mini-batch   400: 1.91787736\n",
            "Epoch  160 Total Loss  3.03834556471804\n",
            "Epoch  160 Loss 1  0.008580184731118637\n",
            "Epoch  160 Loss 2 3.02976538359417\n",
            "Starting epoch 161\n",
            "Loss after mini-batch    50: 25.07064616\n",
            "Loss after mini-batch   100: 0.08272253\n",
            "Loss after mini-batch   150: 6.14496052\n",
            "Loss after mini-batch   200: 4.20742520\n",
            "Loss after mini-batch   250: 3.21537819\n",
            "Loss after mini-batch   300: 0.08218102\n",
            "Loss after mini-batch   350: 0.10424828\n",
            "Loss after mini-batch   400: 0.01215139\n",
            "Epoch  161 Total Loss  4.507064232660537\n",
            "Epoch  161 Loss 1  0.007222789124841058\n",
            "Epoch  161 Loss 2 4.499841461836116\n",
            "Starting epoch 162\n",
            "Loss after mini-batch    50: 4.65612931\n",
            "Loss after mini-batch   100: 0.89345829\n",
            "Loss after mini-batch   150: 4.19663282\n",
            "Loss after mini-batch   200: 2.12338118\n",
            "Loss after mini-batch   250: 0.37493442\n",
            "Loss after mini-batch   300: 0.03338631\n",
            "Loss after mini-batch   350: 0.05671954\n",
            "Loss after mini-batch   400: 0.41395089\n",
            "Epoch  162 Total Loss  1.5129286589548137\n",
            "Epoch  162 Loss 1  0.007402920136548513\n",
            "Epoch  162 Loss 2 1.5055257530396249\n",
            "Starting epoch 163\n",
            "Loss after mini-batch    50: 9.78565363\n",
            "Loss after mini-batch   100: 0.74188589\n",
            "Loss after mini-batch   150: 11.07472855\n",
            "Loss after mini-batch   200: 3.44856734\n",
            "Loss after mini-batch   250: 0.55240613\n",
            "Loss after mini-batch   300: 0.02445172\n",
            "Loss after mini-batch   350: 0.03497244\n",
            "Loss after mini-batch   400: 0.18118957\n",
            "Epoch  163 Total Loss  3.0627823899992035\n",
            "Epoch  163 Loss 1  0.00774976052530344\n",
            "Epoch  163 Loss 2 3.055032552162308\n",
            "Starting epoch 164\n",
            "Loss after mini-batch    50: 13.20786943\n",
            "Loss after mini-batch   100: 2.93116925\n",
            "Loss after mini-batch   150: 7.03166016\n",
            "Loss after mini-batch   200: 3.20941037\n",
            "Loss after mini-batch   250: 0.71206430\n",
            "Loss after mini-batch   300: 0.02470590\n",
            "Loss after mini-batch   350: 0.03634923\n",
            "Loss after mini-batch   400: 0.43661351\n",
            "Epoch  164 Total Loss  3.3979887227843926\n",
            "Epoch  164 Loss 1  0.008424647647038439\n",
            "Epoch  164 Loss 2 3.3895640934669204\n",
            "Starting epoch 165\n",
            "Loss after mini-batch    50: 0.81118569\n",
            "Loss after mini-batch   100: 0.10788841\n",
            "Loss after mini-batch   150: 9.94063219\n",
            "Loss after mini-batch   200: 2.36400368\n",
            "Loss after mini-batch   250: 0.31406285\n",
            "Loss after mini-batch   300: 0.01436809\n",
            "Loss after mini-batch   350: 0.01666913\n",
            "Loss after mini-batch   400: 0.51444992\n",
            "Epoch  165 Total Loss  1.6567282599995472\n",
            "Epoch  165 Loss 1  0.0075647091749592565\n",
            "Epoch  165 Loss 2 1.6491635206160449\n",
            "Starting epoch 166\n",
            "Loss after mini-batch    50: 1.61445489\n",
            "Loss after mini-batch   100: 0.47512422\n",
            "Loss after mini-batch   150: 2.48713309\n",
            "Loss after mini-batch   200: 1.01629900\n",
            "Loss after mini-batch   250: 0.08526785\n",
            "Loss after mini-batch   300: 0.01355225\n",
            "Loss after mini-batch   350: 0.01830300\n",
            "Loss after mini-batch   400: 0.05186203\n",
            "Epoch  166 Total Loss  0.6823448050866036\n",
            "Epoch  166 Loss 1  0.007960868063891286\n",
            "Epoch  166 Loss 2 0.6743839429782728\n",
            "Starting epoch 167\n",
            "Loss after mini-batch    50: 7.78283523\n",
            "Loss after mini-batch   100: 0.26880799\n",
            "Loss after mini-batch   150: 0.20069257\n",
            "Loss after mini-batch   200: 0.11797966\n",
            "Loss after mini-batch   250: 0.30025528\n",
            "Loss after mini-batch   300: 0.02231596\n",
            "Loss after mini-batch   350: 0.03344692\n",
            "Loss after mini-batch   400: 0.03528047\n",
            "Epoch  167 Total Loss  1.0194580413349108\n",
            "Epoch  167 Loss 1  0.007587550401596631\n",
            "Epoch  167 Loss 2 1.0118704650012518\n",
            "Starting epoch 168\n",
            "Loss after mini-batch    50: 1.24485073\n",
            "Loss after mini-batch   100: 0.37394045\n",
            "Loss after mini-batch   150: 3.49614493\n",
            "Loss after mini-batch   200: 0.29769637\n",
            "Loss after mini-batch   250: 0.32712124\n",
            "Loss after mini-batch   300: 0.04395571\n",
            "Loss after mini-batch   350: 0.07985792\n",
            "Loss after mini-batch   400: 0.03676387\n",
            "Epoch  168 Total Loss  0.6898979431457529\n",
            "Epoch  168 Loss 1  0.007550622285450755\n",
            "Epoch  168 Loss 2 0.6823473240505015\n",
            "Starting epoch 169\n",
            "Loss after mini-batch    50: 0.74937357\n",
            "Loss after mini-batch   100: 0.22005457\n",
            "Loss after mini-batch   150: 1.57099967\n",
            "Loss after mini-batch   200: 0.27043610\n",
            "Loss after mini-batch   250: 0.07073412\n",
            "Loss after mini-batch   300: 0.01603780\n",
            "Loss after mini-batch   350: 0.02308838\n",
            "Loss after mini-batch   400: 0.00695457\n",
            "Epoch  169 Total Loss  0.345743847285192\n",
            "Epoch  169 Loss 1  0.007570597170510071\n",
            "Epoch  169 Loss 2 0.33817325034910395\n",
            "Starting epoch 170\n",
            "Loss after mini-batch    50: 0.43481166\n",
            "Loss after mini-batch   100: 0.20781793\n",
            "Loss after mini-batch   150: 6.44177539\n",
            "Loss after mini-batch   200: 2.36962145\n",
            "Loss after mini-batch   250: 1.53434733\n",
            "Loss after mini-batch   300: 0.01555610\n",
            "Loss after mini-batch   350: 0.02054464\n",
            "Loss after mini-batch   400: 0.12049703\n",
            "Epoch  170 Total Loss  1.3002104162420187\n",
            "Epoch  170 Loss 1  0.008725374650125507\n",
            "Epoch  170 Loss 2 1.2914850488464686\n",
            "Starting epoch 171\n",
            "Loss after mini-batch    50: 1.42415580\n",
            "Loss after mini-batch   100: 0.10988186\n",
            "Loss after mini-batch   150: 2.19389481\n",
            "Loss after mini-batch   200: 0.94422754\n",
            "Loss after mini-batch   250: 0.09139608\n",
            "Loss after mini-batch   300: 0.01793285\n",
            "Loss after mini-batch   350: 0.01812565\n",
            "Loss after mini-batch   400: 0.01672913\n",
            "Epoch  171 Total Loss  0.5569247048314568\n",
            "Epoch  171 Loss 1  0.007674558296158707\n",
            "Epoch  171 Loss 2 0.5492501478319117\n",
            "Starting epoch 172\n",
            "Loss after mini-batch    50: 0.13529173\n",
            "Loss after mini-batch   100: 0.07641132\n",
            "Loss after mini-batch   150: 0.44011549\n",
            "Loss after mini-batch   200: 0.07388329\n",
            "Loss after mini-batch   250: 0.15389787\n",
            "Loss after mini-batch   300: 0.01486240\n",
            "Loss after mini-batch   350: 0.01651425\n",
            "Loss after mini-batch   400: 0.00957091\n",
            "Epoch  172 Total Loss  0.10707999737281787\n",
            "Epoch  172 Loss 1  0.007801199281842771\n",
            "Epoch  172 Loss 2 0.09927879862197862\n",
            "Starting epoch 173\n",
            "Loss after mini-batch    50: 0.03332674\n",
            "Loss after mini-batch   100: 0.05077312\n",
            "Loss after mini-batch   150: 0.03840995\n",
            "Loss after mini-batch   200: 0.09370705\n",
            "Loss after mini-batch   250: 0.01621652\n",
            "Loss after mini-batch   300: 0.01387925\n",
            "Loss after mini-batch   350: 0.01498975\n",
            "Loss after mini-batch   400: 0.00657283\n",
            "Epoch  173 Total Loss  0.032093045199152764\n",
            "Epoch  173 Loss 1  0.007498506202515356\n",
            "Epoch  173 Loss 2 0.024594538816135054\n",
            "Starting epoch 174\n",
            "Loss after mini-batch    50: 0.03783522\n",
            "Loss after mini-batch   100: 0.06608007\n",
            "Loss after mini-batch   150: 1.40044398\n",
            "Loss after mini-batch   200: 0.36492564\n",
            "Loss after mini-batch   250: 0.23667865\n",
            "Loss after mini-batch   300: 0.01178262\n",
            "Loss after mini-batch   350: 0.01279400\n",
            "Loss after mini-batch   400: 0.00674349\n",
            "Epoch  174 Total Loss  0.24679524857834706\n",
            "Epoch  174 Loss 1  0.007444451073262888\n",
            "Epoch  174 Loss 2 0.23935079819281552\n",
            "Starting epoch 175\n",
            "Loss after mini-batch    50: 0.02281344\n",
            "Loss after mini-batch   100: 0.03603244\n",
            "Loss after mini-batch   150: 0.28390873\n",
            "Loss after mini-batch   200: 0.03391896\n",
            "Loss after mini-batch   250: 0.05464173\n",
            "Loss after mini-batch   300: 0.01384075\n",
            "Loss after mini-batch   350: 0.01432535\n",
            "Loss after mini-batch   400: 0.00552326\n",
            "Epoch  175 Total Loss  0.05464698116270954\n",
            "Epoch  175 Loss 1  0.006933887191561731\n",
            "Epoch  175 Loss 2 0.04771309420970587\n",
            "Starting epoch 176\n",
            "Loss after mini-batch    50: 0.03454940\n",
            "Loss after mini-batch   100: 0.03250581\n",
            "Loss after mini-batch   150: 0.23048680\n",
            "Loss after mini-batch   200: 0.02207480\n",
            "Loss after mini-batch   250: 0.03873038\n",
            "Loss after mini-batch   300: 0.01477037\n",
            "Loss after mini-batch   350: 0.01635959\n",
            "Loss after mini-batch   400: 0.00651720\n",
            "Epoch  176 Total Loss  0.046426749260943576\n",
            "Epoch  176 Loss 1  0.0071519802703659974\n",
            "Epoch  176 Loss 2 0.039274769345801555\n",
            "Starting epoch 177\n",
            "Loss after mini-batch    50: 0.03599500\n",
            "Loss after mini-batch   100: 0.04392840\n",
            "Loss after mini-batch   150: 1.22490097\n",
            "Loss after mini-batch   200: 0.13917950\n",
            "Loss after mini-batch   250: 0.06062106\n",
            "Loss after mini-batch   300: 0.01596665\n",
            "Loss after mini-batch   350: 0.01727542\n",
            "Loss after mini-batch   400: 0.00657732\n",
            "Epoch  177 Total Loss  0.17834303477446511\n",
            "Epoch  177 Loss 1  0.007064764362682278\n",
            "Epoch  177 Loss 2 0.1712782720981276\n",
            "Starting epoch 178\n",
            "Loss after mini-batch    50: 0.23710788\n",
            "Loss after mini-batch   100: 0.23825151\n",
            "Loss after mini-batch   150: 5.65146679\n",
            "Loss after mini-batch   200: 2.31914273\n",
            "Loss after mini-batch   250: 1.66893616\n",
            "Loss after mini-batch   300: 0.02036233\n",
            "Loss after mini-batch   350: 0.05301127\n",
            "Loss after mini-batch   400: 0.00829712\n",
            "Epoch  178 Total Loss  1.176307401195868\n",
            "Epoch  178 Loss 1  0.007727745146650871\n",
            "Epoch  178 Loss 2 1.168579654657271\n",
            "Starting epoch 179\n",
            "Loss after mini-batch    50: 2.02032920\n",
            "Loss after mini-batch   100: 2.66832670\n",
            "Loss after mini-batch   150: 1.45064722\n",
            "Loss after mini-batch   200: 1.65417248\n",
            "Loss after mini-batch   250: 0.76316591\n",
            "Loss after mini-batch   300: 0.01081823\n",
            "Loss after mini-batch   350: 0.01134101\n",
            "Loss after mini-batch   400: 0.04708417\n",
            "Epoch  179 Total Loss  0.9927148394554672\n",
            "Epoch  179 Loss 1  0.007744439481456507\n",
            "Epoch  179 Loss 2 0.9849704041589769\n",
            "Starting epoch 180\n",
            "Loss after mini-batch    50: 0.16028949\n",
            "Loss after mini-batch   100: 0.07552069\n",
            "Loss after mini-batch   150: 1.10646199\n",
            "Loss after mini-batch   200: 0.46780739\n",
            "Loss after mini-batch   250: 0.05147858\n",
            "Loss after mini-batch   300: 0.01305202\n",
            "Loss after mini-batch   350: 0.01363779\n",
            "Loss after mini-batch   400: 0.05022735\n",
            "Epoch  180 Total Loss  0.22705643147280494\n",
            "Epoch  180 Loss 1  0.006984310335079583\n",
            "Epoch  180 Loss 2 0.2200721247210447\n",
            "Starting epoch 181\n",
            "Loss after mini-batch    50: 0.09716644\n",
            "Loss after mini-batch   100: 0.03649893\n",
            "Loss after mini-batch   150: 1.27603351\n",
            "Loss after mini-batch   200: 0.17038691\n",
            "Loss after mini-batch   250: 0.35572306\n",
            "Loss after mini-batch   300: 0.01417930\n",
            "Loss after mini-batch   350: 0.01321770\n",
            "Loss after mini-batch   400: 0.00584764\n",
            "Epoch  181 Total Loss  0.23280125562125104\n",
            "Epoch  181 Loss 1  0.0073612243520920885\n",
            "Epoch  181 Loss 2 0.22544003284863648\n",
            "Starting epoch 182\n",
            "Loss after mini-batch    50: 0.06839965\n",
            "Loss after mini-batch   100: 0.07831906\n",
            "Loss after mini-batch   150: 3.63630477\n",
            "Loss after mini-batch   200: 0.96173208\n",
            "Loss after mini-batch   250: 0.47971474\n",
            "Loss after mini-batch   300: 0.01000310\n",
            "Loss after mini-batch   350: 0.01418907\n",
            "Loss after mini-batch   400: 0.01039579\n",
            "Epoch  182 Total Loss  0.605625439196288\n",
            "Epoch  182 Loss 1  0.008212048788423435\n",
            "Epoch  182 Loss 2 0.5974133951909333\n",
            "Starting epoch 183\n",
            "Loss after mini-batch    50: 0.14339689\n",
            "Loss after mini-batch   100: 0.04403599\n",
            "Loss after mini-batch   150: 1.95910403\n",
            "Loss after mini-batch   200: 0.13145909\n",
            "Loss after mini-batch   250: 0.02625978\n",
            "Loss after mini-batch   300: 0.01965729\n",
            "Loss after mini-batch   350: 0.01916124\n",
            "Loss after mini-batch   400: 0.03659698\n",
            "Epoch  183 Total Loss  0.2843319616612681\n",
            "Epoch  183 Loss 1  0.007399510646632996\n",
            "Epoch  183 Loss 2 0.2769324515771487\n",
            "Starting epoch 184\n",
            "Loss after mini-batch    50: 0.70187596\n",
            "Loss after mini-batch   100: 0.28856197\n",
            "Loss after mini-batch   150: 14.98280204\n",
            "Loss after mini-batch   200: 2.56917718\n",
            "Loss after mini-batch   250: 0.79423744\n",
            "Loss after mini-batch   300: 0.02179689\n",
            "Loss after mini-batch   350: 0.14665884\n",
            "Loss after mini-batch   400: 1.66518319\n",
            "Epoch  184 Total Loss  2.4821659702943317\n",
            "Epoch  184 Loss 1  0.008271158241388193\n",
            "Epoch  184 Loss 2 2.473894797738416\n",
            "Starting epoch 185\n",
            "Loss after mini-batch    50: 2.12331024\n",
            "Loss after mini-batch   100: 0.71076603\n",
            "Loss after mini-batch   150: 0.70256799\n",
            "Loss after mini-batch   200: 0.48568613\n",
            "Loss after mini-batch   250: 0.17483302\n",
            "Loss after mini-batch   300: 0.04200779\n",
            "Loss after mini-batch   350: 0.04348294\n",
            "Loss after mini-batch   400: 0.04907744\n",
            "Epoch  185 Total Loss  0.5157610822514993\n",
            "Epoch  185 Loss 1  0.008308320451953018\n",
            "Epoch  185 Loss 2 0.5074527629449562\n",
            "Starting epoch 186\n",
            "Loss after mini-batch    50: 0.80880968\n",
            "Loss after mini-batch   100: 0.27894017\n",
            "Loss after mini-batch   150: 1.57035289\n",
            "Loss after mini-batch   200: 0.06907344\n",
            "Loss after mini-batch   250: 0.21817461\n",
            "Loss after mini-batch   300: 0.01285429\n",
            "Loss after mini-batch   350: 0.01313909\n",
            "Loss after mini-batch   400: 0.00705514\n",
            "Epoch  186 Total Loss  0.34359416631981227\n",
            "Epoch  186 Loss 1  0.007977838308504253\n",
            "Epoch  186 Loss 2 0.3356163321909784\n",
            "Starting epoch 187\n",
            "Loss after mini-batch    50: 0.08052362\n",
            "Loss after mini-batch   100: 0.01697340\n",
            "Loss after mini-batch   150: 3.64025954\n",
            "Loss after mini-batch   200: 2.14646135\n",
            "Loss after mini-batch   250: 0.88898948\n",
            "Loss after mini-batch   300: 0.08500856\n",
            "Loss after mini-batch   350: 0.09257461\n",
            "Loss after mini-batch   400: 0.16602133\n",
            "Epoch  187 Total Loss  0.871426941990013\n",
            "Epoch  187 Loss 1  0.008337857031187139\n",
            "Epoch  187 Loss 2 0.8630890850699017\n",
            "Starting epoch 188\n",
            "Loss after mini-batch    50: 0.40617885\n",
            "Loss after mini-batch   100: 0.19824592\n",
            "Loss after mini-batch   150: 13.25361146\n",
            "Loss after mini-batch   200: 1.35956714\n",
            "Loss after mini-batch   250: 0.06154120\n",
            "Loss after mini-batch   300: 0.01967007\n",
            "Loss after mini-batch   350: 0.02034851\n",
            "Loss after mini-batch   400: 0.08927135\n",
            "Epoch  188 Total Loss  1.799201956190978\n",
            "Epoch  188 Loss 1  0.007251311055190216\n",
            "Epoch  188 Loss 2 1.7919506072765534\n",
            "Starting epoch 189\n",
            "Loss after mini-batch    50: 0.45368280\n",
            "Loss after mini-batch   100: 0.21905086\n",
            "Loss after mini-batch   150: 0.84601517\n",
            "Loss after mini-batch   200: 0.23818132\n",
            "Loss after mini-batch   250: 0.03602667\n",
            "Loss after mini-batch   300: 0.00892280\n",
            "Loss after mini-batch   350: 0.02897232\n",
            "Loss after mini-batch   400: 0.02749241\n",
            "Epoch  189 Total Loss  0.22727137301841013\n",
            "Epoch  189 Loss 1  0.007359807856156639\n",
            "Epoch  189 Loss 2 0.21991156772627443\n",
            "Starting epoch 190\n",
            "Loss after mini-batch    50: 0.46998248\n",
            "Loss after mini-batch   100: 0.84415858\n",
            "Loss after mini-batch   150: 9.65406769\n",
            "Loss after mini-batch   200: 1.05438599\n",
            "Loss after mini-batch   250: 0.92065444\n",
            "Loss after mini-batch   300: 0.04162655\n",
            "Loss after mini-batch   350: 0.05775777\n",
            "Loss after mini-batch   400: 0.86646564\n",
            "Epoch  190 Total Loss  1.9689545920486167\n",
            "Epoch  190 Loss 1  0.008660741188799583\n",
            "Epoch  190 Loss 2 1.9602938437794777\n",
            "Starting epoch 191\n",
            "Loss after mini-batch    50: 1.16126380\n",
            "Loss after mini-batch   100: 0.67292068\n",
            "Loss after mini-batch   150: 11.20726021\n",
            "Loss after mini-batch   200: 0.06053013\n",
            "Loss after mini-batch   250: 0.09499961\n",
            "Loss after mini-batch   300: 0.01343687\n",
            "Loss after mini-batch   350: 0.02272282\n",
            "Loss after mini-batch   400: 0.13724855\n",
            "Epoch  191 Total Loss  1.557090621460997\n",
            "Epoch  191 Loss 1  0.008004925790620532\n",
            "Epoch  191 Loss 2 1.549085687430467\n",
            "Starting epoch 192\n",
            "Loss after mini-batch    50: 22.52910170\n",
            "Loss after mini-batch   100: 0.74695168\n",
            "Loss after mini-batch   150: 16.36944591\n",
            "Loss after mini-batch   200: 0.10091753\n",
            "Loss after mini-batch   250: 0.09649500\n",
            "Loss after mini-batch   300: 0.01480670\n",
            "Loss after mini-batch   350: 0.01685707\n",
            "Loss after mini-batch   400: 0.06558266\n",
            "Epoch  192 Total Loss  4.64310870069802\n",
            "Epoch  192 Loss 1  0.00851303755809003\n",
            "Epoch  192 Loss 2 4.634595691201478\n",
            "Starting epoch 193\n",
            "Loss after mini-batch    50: 50.23771327\n",
            "Loss after mini-batch   100: 4.00001022\n",
            "Loss after mini-batch   150: 26.52164109\n",
            "Loss after mini-batch   200: 0.31348341\n",
            "Loss after mini-batch   250: 0.07953284\n",
            "Loss after mini-batch   300: 0.02795079\n",
            "Loss after mini-batch   350: 0.02067505\n",
            "Loss after mini-batch   400: 0.03182453\n",
            "Epoch  193 Total Loss  9.399877340164728\n",
            "Epoch  193 Loss 1  0.008242770978697456\n",
            "Epoch  193 Loss 2 9.39163445156554\n",
            "Starting epoch 194\n",
            "Loss after mini-batch    50: 3.65893610\n",
            "Loss after mini-batch   100: 0.28858739\n",
            "Loss after mini-batch   150: 2.88984655\n",
            "Loss after mini-batch   200: 0.77663012\n",
            "Loss after mini-batch   250: 0.16390910\n",
            "Loss after mini-batch   300: 0.03834394\n",
            "Loss after mini-batch   350: 0.05034357\n",
            "Loss after mini-batch   400: 0.06428391\n",
            "Epoch  194 Total Loss  0.9474333383045748\n",
            "Epoch  194 Loss 1  0.008295874945446716\n",
            "Epoch  194 Loss 2 0.9391374690427128\n",
            "Starting epoch 195\n",
            "Loss after mini-batch    50: 3.63767157\n",
            "Loss after mini-batch   100: 0.39357044\n",
            "Loss after mini-batch   150: 6.08430495\n",
            "Loss after mini-batch   200: 1.60833892\n",
            "Loss after mini-batch   250: 0.11788270\n",
            "Loss after mini-batch   300: 0.01293396\n",
            "Loss after mini-batch   350: 0.01869754\n",
            "Loss after mini-batch   400: 0.00912708\n",
            "Epoch  195 Total Loss  1.3767286962317955\n",
            "Epoch  195 Loss 1  0.007487078248508122\n",
            "Epoch  195 Loss 2 1.3692416320508256\n",
            "Starting epoch 196\n",
            "Loss after mini-batch    50: 0.16233707\n",
            "Loss after mini-batch   100: 0.04603083\n",
            "Loss after mini-batch   150: 0.02534821\n",
            "Loss after mini-batch   200: 0.04615189\n",
            "Loss after mini-batch   250: 0.16202014\n",
            "Loss after mini-batch   300: 0.01203065\n",
            "Loss after mini-batch   350: 0.01246832\n",
            "Loss after mini-batch   400: 0.01744406\n",
            "Epoch  196 Total Loss  0.05730749099696358\n",
            "Epoch  196 Loss 1  0.007433392702074636\n",
            "Epoch  196 Loss 2 0.049874098465420104\n",
            "Starting epoch 197\n",
            "Loss after mini-batch    50: 0.18084388\n",
            "Loss after mini-batch   100: 0.03494451\n",
            "Loss after mini-batch   150: 0.12658901\n",
            "Loss after mini-batch   200: 0.03724965\n",
            "Loss after mini-batch   250: 0.04896536\n",
            "Loss after mini-batch   300: 0.01021439\n",
            "Loss after mini-batch   350: 0.01743914\n",
            "Loss after mini-batch   400: 0.03490038\n",
            "Epoch  197 Total Loss  0.060372974527979684\n",
            "Epoch  197 Loss 1  0.007313115987968537\n",
            "Epoch  197 Loss 2 0.05305985832994516\n",
            "Starting epoch 198\n",
            "Loss after mini-batch    50: 0.11913757\n",
            "Loss after mini-batch   100: 0.03897928\n",
            "Loss after mini-batch   150: 0.68424476\n",
            "Loss after mini-batch   200: 0.30230132\n",
            "Loss after mini-batch   250: 0.01478310\n",
            "Loss after mini-batch   300: 0.01431917\n",
            "Loss after mini-batch   350: 0.01771765\n",
            "Loss after mini-batch   400: 0.02779428\n",
            "Epoch  198 Total Loss  0.14388038644236953\n",
            "Epoch  198 Loss 1  0.007141777532808777\n",
            "Epoch  198 Loss 2 0.1367386103712571\n",
            "Starting epoch 199\n",
            "Loss after mini-batch    50: 0.47655927\n",
            "Loss after mini-batch   100: 0.05728142\n",
            "Loss after mini-batch   150: 1.79389229\n",
            "Loss after mini-batch   200: 0.16856414\n",
            "Loss after mini-batch   250: 0.20802505\n",
            "Loss after mini-batch   300: 0.00892643\n",
            "Loss after mini-batch   350: 0.01341107\n",
            "Loss after mini-batch   400: 0.04263919\n",
            "Epoch  199 Total Loss  0.3281545060197647\n",
            "Epoch  199 Loss 1  0.0073543845124752795\n",
            "Epoch  199 Loss 2 0.32080012302689015\n",
            "Starting epoch 200\n",
            "Loss after mini-batch    50: 0.17310617\n",
            "Loss after mini-batch   100: 0.64858588\n",
            "Loss after mini-batch   150: 20.88939623\n",
            "Loss after mini-batch   200: 4.42610088\n",
            "Loss after mini-batch   250: 0.38632679\n",
            "Loss after mini-batch   300: 0.38920203\n",
            "Loss after mini-batch   350: 0.09266816\n",
            "Loss after mini-batch   400: 0.05865942\n",
            "Epoch  200 Total Loss  3.3144706823206915\n",
            "Epoch  200 Loss 1  0.009757988665710557\n",
            "Epoch  200 Loss 2 3.304712688110885\n",
            "Starting epoch 201\n",
            "Loss after mini-batch    50: 15.65382234\n",
            "Loss after mini-batch   100: 3.21785545\n",
            "Loss after mini-batch   150: 7.94726317\n",
            "Loss after mini-batch   200: 2.95159586\n",
            "Loss after mini-batch   250: 0.48802713\n",
            "Loss after mini-batch   300: 0.01825699\n",
            "Loss after mini-batch   350: 0.04184476\n",
            "Loss after mini-batch   400: 0.03016616\n",
            "Epoch  201 Total Loss  3.5117039398746175\n",
            "Epoch  201 Loss 1  0.008395352420250114\n",
            "Epoch  201 Loss 2 3.503308616758274\n",
            "Starting epoch 202\n",
            "Loss after mini-batch    50: 0.92645350\n",
            "Loss after mini-batch   100: 0.34495673\n",
            "Loss after mini-batch   150: 5.79843029\n",
            "Loss after mini-batch   200: 0.38299317\n",
            "Loss after mini-batch   250: 0.42700671\n",
            "Loss after mini-batch   300: 0.01907134\n",
            "Loss after mini-batch   350: 0.02667872\n",
            "Loss after mini-batch   400: 0.01427350\n",
            "Epoch  202 Total Loss  0.9561687219433183\n",
            "Epoch  202 Loss 1  0.00913952410978134\n",
            "Epoch  202 Loss 2 0.9470291931060274\n",
            "Starting epoch 203\n",
            "Loss after mini-batch    50: 3.12658071\n",
            "Loss after mini-batch   100: 2.10272322\n",
            "Loss after mini-batch   150: 12.58823861\n",
            "Loss after mini-batch   200: 0.11972085\n",
            "Loss after mini-batch   250: 0.40733958\n",
            "Loss after mini-batch   300: 0.03258212\n",
            "Loss after mini-batch   350: 0.09368990\n",
            "Loss after mini-batch   400: 0.01476572\n",
            "Epoch  203 Total Loss  2.31282353170512\n",
            "Epoch  203 Loss 1  0.009747910937811207\n",
            "Epoch  203 Loss 2 2.303075618297201\n",
            "Starting epoch 204\n",
            "Loss after mini-batch    50: 33.23335160\n",
            "Loss after mini-batch   100: 1.54680221\n",
            "Loss after mini-batch   150: 1.00881904\n",
            "Loss after mini-batch   200: 0.02659538\n",
            "Loss after mini-batch   250: 0.10249924\n",
            "Loss after mini-batch   300: 0.01384616\n",
            "Loss after mini-batch   350: 0.01596598\n",
            "Loss after mini-batch   400: 0.01198621\n",
            "Epoch  204 Total Loss  4.142537561434758\n",
            "Epoch  204 Loss 1  0.00863872606405389\n",
            "Epoch  204 Loss 2 4.133898864015094\n",
            "Starting epoch 205\n",
            "Loss after mini-batch    50: 1.28027316\n",
            "Loss after mini-batch   100: 0.42740384\n",
            "Loss after mini-batch   150: 13.56631215\n",
            "Loss after mini-batch   200: 2.32944147\n",
            "Loss after mini-batch   250: 0.41006875\n",
            "Loss after mini-batch   300: 0.14440451\n",
            "Loss after mini-batch   350: 0.16274484\n",
            "Loss after mini-batch   400: 0.02989155\n",
            "Epoch  205 Total Loss  2.188058566408767\n",
            "Epoch  205 Loss 1  0.009660896282496223\n",
            "Epoch  205 Loss 2 2.1783977005578685\n",
            "Starting epoch 206\n",
            "Loss after mini-batch    50: 9.23597683\n",
            "Loss after mini-batch   100: 2.10480503\n",
            "Loss after mini-batch   150: 29.25044811\n",
            "Loss after mini-batch   200: 1.23244317\n",
            "Loss after mini-batch   250: 0.13251718\n",
            "Loss after mini-batch   300: 0.01205644\n",
            "Loss after mini-batch   350: 0.06256215\n",
            "Loss after mini-batch   400: 0.65552808\n",
            "Epoch  206 Total Loss  5.225175086214042\n",
            "Epoch  206 Loss 1  0.008506597074276591\n",
            "Epoch  206 Loss 2 5.21666843412523\n",
            "Starting epoch 207\n",
            "Loss after mini-batch    50: 2.21928132\n",
            "Loss after mini-batch   100: 0.91060873\n",
            "Loss after mini-batch   150: 12.29859956\n",
            "Loss after mini-batch   200: 0.69493209\n",
            "Loss after mini-batch   250: 0.21468413\n",
            "Loss after mini-batch   300: 0.01885336\n",
            "Loss after mini-batch   350: 0.02104177\n",
            "Loss after mini-batch   400: 0.04338347\n",
            "Epoch  207 Total Loss  1.9159861539199565\n",
            "Epoch  207 Loss 1  0.009363998094554047\n",
            "Epoch  207 Loss 2 1.9066221924626532\n",
            "Starting epoch 208\n",
            "Loss after mini-batch    50: 10.26815695\n",
            "Loss after mini-batch   100: 0.73848589\n",
            "Loss after mini-batch   150: 37.84768848\n",
            "Loss after mini-batch   200: 3.09811059\n",
            "Loss after mini-batch   250: 0.24174689\n",
            "Loss after mini-batch   300: 0.01927596\n",
            "Loss after mini-batch   350: 0.02485943\n",
            "Loss after mini-batch   400: 0.91058601\n",
            "Epoch  208 Total Loss  6.219265898709791\n",
            "Epoch  208 Loss 1  0.009444830866472664\n",
            "Epoch  208 Loss 2 6.209820988721897\n",
            "Starting epoch 209\n",
            "Loss after mini-batch    50: 1.48070878\n",
            "Loss after mini-batch   100: 0.14118706\n",
            "Loss after mini-batch   150: 3.49985290\n",
            "Loss after mini-batch   200: 1.93957459\n",
            "Loss after mini-batch   250: 0.10834501\n",
            "Loss after mini-batch   300: 0.01223740\n",
            "Loss after mini-batch   350: 0.01487981\n",
            "Loss after mini-batch   400: 0.03529875\n",
            "Epoch  209 Total Loss  0.8325139703422594\n",
            "Epoch  209 Loss 1  0.008198046844411474\n",
            "Epoch  209 Loss 2 0.8243159286204418\n",
            "Starting epoch 210\n",
            "Loss after mini-batch    50: 0.09065210\n",
            "Loss after mini-batch   100: 0.08693991\n",
            "Loss after mini-batch   150: 3.99488435\n",
            "Loss after mini-batch   200: 0.74793628\n",
            "Loss after mini-batch   250: 0.05040128\n",
            "Loss after mini-batch   300: 0.01951893\n",
            "Loss after mini-batch   350: 0.01772661\n",
            "Loss after mini-batch   400: 0.12998894\n",
            "Epoch  210 Total Loss  0.6414431866697072\n",
            "Epoch  210 Loss 1  0.007756680101918119\n",
            "Epoch  210 Loss 2 0.63368649730332\n",
            "Starting epoch 211\n",
            "Loss after mini-batch    50: 6.76737491\n",
            "Loss after mini-batch   100: 1.47540796\n",
            "Loss after mini-batch   150: 13.49115240\n",
            "Loss after mini-batch   200: 0.11188686\n",
            "Loss after mini-batch   250: 0.37171101\n",
            "Loss after mini-batch   300: 0.02351008\n",
            "Loss after mini-batch   350: 0.02077994\n",
            "Loss after mini-batch   400: 1.54103941\n",
            "Epoch  211 Total Loss  3.000058427268332\n",
            "Epoch  211 Loss 1  0.00826316935161795\n",
            "Epoch  211 Loss 2 2.991795269495121\n",
            "Starting epoch 212\n",
            "Loss after mini-batch    50: 2.11249947\n",
            "Loss after mini-batch   100: 0.79538208\n",
            "Loss after mini-batch   150: 15.39213042\n",
            "Loss after mini-batch   200: 2.36069453\n",
            "Loss after mini-batch   250: 0.74115221\n",
            "Loss after mini-batch   300: 0.51146018\n",
            "Loss after mini-batch   350: 0.39618549\n",
            "Loss after mini-batch   400: 0.38252508\n",
            "Epoch  212 Total Loss  2.637009554994898\n",
            "Epoch  212 Loss 1  0.007908484532585469\n",
            "Epoch  212 Loss 2 2.629101043555613\n",
            "Starting epoch 213\n",
            "Loss after mini-batch    50: 11.48029415\n",
            "Loss after mini-batch   100: 6.89112057\n",
            "Loss after mini-batch   150: 99.34113563\n",
            "Loss after mini-batch   200: 0.15625341\n",
            "Loss after mini-batch   250: 0.06052520\n",
            "Loss after mini-batch   300: 0.03052039\n",
            "Loss after mini-batch   350: 0.04472815\n",
            "Loss after mini-batch   400: 0.00788465\n",
            "Epoch  213 Total Loss  13.57059360439419\n",
            "Epoch  213 Loss 1  0.008394684620512197\n",
            "Epoch  213 Loss 2 13.56219894625721\n",
            "Starting epoch 214\n",
            "Loss after mini-batch    50: 2.26323965\n",
            "Loss after mini-batch   100: 2.17401312\n",
            "Loss after mini-batch   150: 5.59381685\n",
            "Loss after mini-batch   200: 2.15074886\n",
            "Loss after mini-batch   250: 0.67306868\n",
            "Loss after mini-batch   300: 0.01963220\n",
            "Loss after mini-batch   350: 0.01580161\n",
            "Loss after mini-batch   400: 0.50855673\n",
            "Epoch  214 Total Loss  1.6747420886681843\n",
            "Epoch  214 Loss 1  0.008359393217512567\n",
            "Epoch  214 Loss 2 1.666382708576536\n",
            "Starting epoch 215\n",
            "Loss after mini-batch    50: 7.68797473\n",
            "Loss after mini-batch   100: 0.36260707\n",
            "Loss after mini-batch   150: 5.18848814\n",
            "Loss after mini-batch   200: 0.30653520\n",
            "Loss after mini-batch   250: 0.41744054\n",
            "Loss after mini-batch   300: 0.03727975\n",
            "Loss after mini-batch   350: 0.02065694\n",
            "Loss after mini-batch   400: 0.59964520\n",
            "Epoch  215 Total Loss  1.6840187456079956\n",
            "Epoch  215 Loss 1  0.008876740013887496\n",
            "Epoch  215 Loss 2 1.6751419893710235\n",
            "Starting epoch 216\n",
            "Loss after mini-batch    50: 1.48621034\n",
            "Loss after mini-batch   100: 0.38511606\n",
            "Loss after mini-batch   150: 17.44033556\n",
            "Loss after mini-batch   200: 1.73261720\n",
            "Loss after mini-batch   250: 0.57417151\n",
            "Loss after mini-batch   300: 0.08080911\n",
            "Loss after mini-batch   350: 0.10866572\n",
            "Loss after mini-batch   400: 0.01031161\n",
            "Epoch  216 Total Loss  2.5156319051661917\n",
            "Epoch  216 Loss 1  0.007901198646341699\n",
            "Epoch  216 Loss 2 2.507730715953416\n",
            "Starting epoch 217\n",
            "Loss after mini-batch    50: 1.75575041\n",
            "Loss after mini-batch   100: 0.34019419\n",
            "Loss after mini-batch   150: 15.89365983\n",
            "Loss after mini-batch   200: 0.36860525\n",
            "Loss after mini-batch   250: 5.65790160\n",
            "Loss after mini-batch   300: 0.06769849\n",
            "Loss after mini-batch   350: 0.14161269\n",
            "Loss after mini-batch   400: 0.34952317\n",
            "Epoch  217 Total Loss  2.978690481929428\n",
            "Epoch  217 Loss 1  0.008320381549078618\n",
            "Epoch  217 Loss 2 2.970370121315858\n",
            "Starting epoch 218\n",
            "Loss after mini-batch    50: 5.19976786\n",
            "Loss after mini-batch   100: 0.14439534\n",
            "Loss after mini-batch   150: 13.86682475\n",
            "Loss after mini-batch   200: 1.54506538\n",
            "Loss after mini-batch   250: 0.17533502\n",
            "Loss after mini-batch   300: 0.02056957\n",
            "Loss after mini-batch   350: 0.02160496\n",
            "Loss after mini-batch   400: 0.02560414\n",
            "Epoch  218 Total Loss  2.427228941839595\n",
            "Epoch  218 Loss 1  0.008344267117161968\n",
            "Epoch  218 Loss 2 2.4188846998960503\n",
            "Starting epoch 219\n",
            "Loss after mini-batch    50: 16.27943895\n",
            "Loss after mini-batch   100: 1.40188055\n",
            "Loss after mini-batch   150: 9.72498450\n",
            "Loss after mini-batch   200: 3.99328320\n",
            "Loss after mini-batch   250: 1.18512819\n",
            "Loss after mini-batch   300: 0.02544581\n",
            "Loss after mini-batch   350: 0.06589361\n",
            "Loss after mini-batch   400: 0.25046810\n",
            "Epoch  219 Total Loss  3.8928773995161046\n",
            "Epoch  219 Loss 1  0.010192780152392097\n",
            "Epoch  219 Loss 2 3.882684627155921\n",
            "Starting epoch 220\n",
            "Loss after mini-batch    50: 13.85459574\n",
            "Loss after mini-batch   100: 0.37762791\n",
            "Loss after mini-batch   150: 14.13715463\n",
            "Loss after mini-batch   200: 0.39093448\n",
            "Loss after mini-batch   250: 0.16024997\n",
            "Loss after mini-batch   300: 0.19079587\n",
            "Loss after mini-batch   350: 0.27880412\n",
            "Loss after mini-batch   400: 0.10274615\n",
            "Epoch  220 Total Loss  3.407790200059239\n",
            "Epoch  220 Loss 1  0.009900615522586111\n",
            "Epoch  220 Loss 2 3.397889524856357\n",
            "Starting epoch 221\n",
            "Loss after mini-batch    50: 13.60847904\n",
            "Loss after mini-batch   100: 0.40396672\n",
            "Loss after mini-batch   150: 5.77053814\n",
            "Loss after mini-batch   200: 0.63021810\n",
            "Loss after mini-batch   250: 0.19167302\n",
            "Loss after mini-batch   300: 0.04439012\n",
            "Loss after mini-batch   350: 0.04677370\n",
            "Loss after mini-batch   400: 0.01059888\n",
            "Epoch  221 Total Loss  2.3875311598407114\n",
            "Epoch  221 Loss 1  0.009191225041829695\n",
            "Epoch  221 Loss 2 2.378339888480519\n",
            "Starting epoch 222\n",
            "Loss after mini-batch    50: 1.61911305\n",
            "Loss after mini-batch   100: 0.16633150\n",
            "Loss after mini-batch   150: 1.97661362\n",
            "Loss after mini-batch   200: 0.25763021\n",
            "Loss after mini-batch   250: 0.16244740\n",
            "Loss after mini-batch   300: 0.01423669\n",
            "Loss after mini-batch   350: 0.01529672\n",
            "Loss after mini-batch   400: 0.04525953\n",
            "Epoch  222 Total Loss  0.49733250550548136\n",
            "Epoch  222 Loss 1  0.009222789244391271\n",
            "Epoch  222 Loss 2 0.4881097093147143\n",
            "Starting epoch 223\n",
            "Loss after mini-batch    50: 1.08004207\n",
            "Loss after mini-batch   100: 1.66547453\n",
            "Loss after mini-batch   150: 109.29743651\n",
            "Loss after mini-batch   200: 0.62969864\n",
            "Loss after mini-batch   250: 0.97806840\n",
            "Loss after mini-batch   300: 0.11309040\n",
            "Loss after mini-batch   350: 0.05716842\n",
            "Loss after mini-batch   400: 1.76541300\n",
            "Epoch  223 Total Loss  13.585214499844081\n",
            "Epoch  223 Loss 1  0.010225683399039554\n",
            "Epoch  223 Loss 2 13.574989172176153\n",
            "Starting epoch 224\n",
            "Loss after mini-batch    50: 4.05222313\n",
            "Loss after mini-batch   100: 1.71118607\n",
            "Loss after mini-batch   150: 10.51928616\n",
            "Loss after mini-batch   200: 5.20407150\n",
            "Loss after mini-batch   250: 2.44378273\n",
            "Loss after mini-batch   300: 0.03398408\n",
            "Loss after mini-batch   350: 0.03293467\n",
            "Loss after mini-batch   400: 0.40573959\n",
            "Epoch  224 Total Loss  2.832480993523345\n",
            "Epoch  224 Loss 1  0.009554907000108807\n",
            "Epoch  224 Loss 2 2.822926089487547\n",
            "Starting epoch 225\n",
            "Loss after mini-batch    50: 4.92332003\n",
            "Loss after mini-batch   100: 1.10390826\n",
            "Loss after mini-batch   150: 12.15886627\n",
            "Loss after mini-batch   200: 5.51643587\n",
            "Loss after mini-batch   250: 2.76980730\n",
            "Loss after mini-batch   300: 0.02267037\n",
            "Loss after mini-batch   350: 0.04457290\n",
            "Loss after mini-batch   400: 0.03480661\n",
            "Epoch  225 Total Loss  3.149634700339318\n",
            "Epoch  225 Loss 1  0.009081463567008018\n",
            "Epoch  225 Loss 2 3.140553207209908\n",
            "Starting epoch 226\n",
            "Loss after mini-batch    50: 5.26253509\n",
            "Loss after mini-batch   100: 1.84677557\n",
            "Loss after mini-batch   150: 12.63758423\n",
            "Loss after mini-batch   200: 5.45489588\n",
            "Loss after mini-batch   250: 0.54784255\n",
            "Loss after mini-batch   300: 0.03120040\n",
            "Loss after mini-batch   350: 0.02457485\n",
            "Loss after mini-batch   400: 0.13123033\n",
            "Epoch  226 Total Loss  3.1497906743702946\n",
            "Epoch  226 Loss 1  0.008722901525269946\n",
            "Epoch  226 Loss 2 3.14106776447127\n",
            "Starting epoch 227\n",
            "Loss after mini-batch    50: 4.49252828\n",
            "Loss after mini-batch   100: 2.22305302\n",
            "Loss after mini-batch   150: 4.83235763\n",
            "Loss after mini-batch   200: 1.36809599\n",
            "Loss after mini-batch   250: 0.70034830\n",
            "Loss after mini-batch   300: 0.01901539\n",
            "Loss after mini-batch   350: 0.22129357\n",
            "Loss after mini-batch   400: 1.39495511\n",
            "Epoch  227 Total Loss  1.9610709162113766\n",
            "Epoch  227 Loss 1  0.007237795849538799\n",
            "Epoch  227 Loss 2 1.9538331408907508\n",
            "Starting epoch 228\n",
            "Loss after mini-batch    50: 2.38649315\n",
            "Loss after mini-batch   100: 0.98745892\n",
            "Loss after mini-batch   150: 34.72793165\n",
            "Loss after mini-batch   200: 15.00560954\n",
            "Loss after mini-batch   250: 20.31627993\n",
            "Loss after mini-batch   300: 1.16375812\n",
            "Loss after mini-batch   350: 3.33057535\n",
            "Loss after mini-batch   400: 8.42326383\n",
            "Epoch  228 Total Loss  10.730882282176871\n",
            "Epoch  228 Loss 1  0.0113406353149076\n",
            "Epoch  228 Loss 2 10.719541679269442\n",
            "Starting epoch 229\n",
            "Loss after mini-batch    50: 43.69543923\n",
            "Loss after mini-batch   100: 2.12376662\n",
            "Loss after mini-batch   150: 153.90524558\n",
            "Loss after mini-batch   200: 19.99033377\n",
            "Loss after mini-batch   250: 3.94880681\n",
            "Loss after mini-batch   300: 0.25129571\n",
            "Loss after mini-batch   350: 0.13791235\n",
            "Loss after mini-batch   400: 0.07464824\n",
            "Epoch  229 Total Loss  25.804103240670855\n",
            "Epoch  229 Loss 1  0.011988086921153537\n",
            "Epoch  229 Loss 2 25.79211526610315\n",
            "Starting epoch 230\n",
            "Loss after mini-batch    50: 27.54458493\n",
            "Loss after mini-batch   100: 2.73101236\n",
            "Loss after mini-batch   150: 36.45338735\n",
            "Loss after mini-batch   200: 3.03454371\n",
            "Loss after mini-batch   250: 2.33999573\n",
            "Loss after mini-batch   300: 0.39498939\n",
            "Loss after mini-batch   350: 0.58511015\n",
            "Loss after mini-batch   400: 0.15896622\n",
            "Epoch  230 Total Loss  8.457664804448573\n",
            "Epoch  230 Loss 1  0.009124901821139675\n",
            "Epoch  230 Loss 2 8.448539826434434\n",
            "Starting epoch 231\n",
            "Loss after mini-batch    50: 44.33574440\n",
            "Loss after mini-batch   100: 1.65759062\n",
            "Loss after mini-batch   150: 23.77666752\n",
            "Loss after mini-batch   200: 4.03356529\n",
            "Loss after mini-batch   250: 6.22314165\n",
            "Loss after mini-batch   300: 1.01158417\n",
            "Loss after mini-batch   350: 2.78928838\n",
            "Loss after mini-batch   400: 2.67864753\n",
            "Epoch  231 Total Loss  10.099272681298801\n",
            "Epoch  231 Loss 1  0.010281373262064178\n",
            "Epoch  231 Loss 2 10.088991371033009\n",
            "Starting epoch 232\n",
            "Loss after mini-batch    50: 59.22807450\n",
            "Loss after mini-batch   100: 4.05755784\n",
            "Loss after mini-batch   150: 48.21124085\n",
            "Loss after mini-batch   200: 29.25174919\n",
            "Loss after mini-batch   250: 2.71062641\n",
            "Loss after mini-batch   300: 0.19053141\n",
            "Loss after mini-batch   350: 0.14916540\n",
            "Loss after mini-batch   400: 0.22271712\n",
            "Epoch  232 Total Loss  16.63736895790612\n",
            "Epoch  232 Loss 1  0.014041672613964839\n",
            "Epoch  232 Loss 2 16.623327260083748\n",
            "Starting epoch 233\n",
            "Loss after mini-batch    50: 13.60455095\n",
            "Loss after mini-batch   100: 1.75307246\n",
            "Loss after mini-batch   150: 38.61129513\n",
            "Loss after mini-batch   200: 0.64423874\n",
            "Loss after mini-batch   250: 0.30474095\n",
            "Loss after mini-batch   300: 0.02989770\n",
            "Loss after mini-batch   350: 0.02393508\n",
            "Loss after mini-batch   400: 0.19749555\n",
            "Epoch  233 Total Loss  6.368816073568492\n",
            "Epoch  233 Loss 1  0.010575867926547352\n",
            "Epoch  233 Loss 2 6.358240278136075\n",
            "Starting epoch 234\n",
            "Loss after mini-batch    50: 2.10645093\n",
            "Loss after mini-batch   100: 1.47192352\n",
            "Loss after mini-batch   150: 63.20746014\n",
            "Loss after mini-batch   200: 7.96512800\n",
            "Loss after mini-batch   250: 14.06088429\n",
            "Loss after mini-batch   300: 1.12463661\n",
            "Loss after mini-batch   350: 3.61980230\n",
            "Loss after mini-batch   400: 11.79614300\n",
            "Epoch  234 Total Loss  13.411199696570915\n",
            "Epoch  234 Loss 1  0.014162233985435946\n",
            "Epoch  234 Loss 2 13.397037700703944\n",
            "Starting epoch 235\n",
            "Loss after mini-batch    50: 32.65852335\n",
            "Loss after mini-batch   100: 0.90310082\n",
            "Loss after mini-batch   150: 4.11427205\n",
            "Loss after mini-batch   200: 0.32529334\n",
            "Loss after mini-batch   250: 0.97457704\n",
            "Loss after mini-batch   300: 0.05350960\n",
            "Loss after mini-batch   350: 0.05304524\n",
            "Loss after mini-batch   400: 0.11799380\n",
            "Epoch  235 Total Loss  4.538353008522704\n",
            "Epoch  235 Loss 1  0.010021731051913766\n",
            "Epoch  235 Loss 2 4.528331254006561\n",
            "Starting epoch 236\n",
            "Loss after mini-batch    50: 14.46985609\n",
            "Loss after mini-batch   100: 2.17912287\n",
            "Loss after mini-batch   150: 13.72846070\n",
            "Loss after mini-batch   200: 1.22909707\n",
            "Loss after mini-batch   250: 0.40542895\n",
            "Loss after mini-batch   300: 0.03088278\n",
            "Loss after mini-batch   350: 0.01505650\n",
            "Loss after mini-batch   400: 0.63407802\n",
            "Epoch  236 Total Loss  3.8580385854268373\n",
            "Epoch  236 Loss 1  0.008103063199488478\n",
            "Epoch  236 Loss 2 3.8499355859989475\n",
            "Starting epoch 237\n",
            "Loss after mini-batch    50: 19.23753035\n",
            "Loss after mini-batch   100: 1.54519679\n",
            "Loss after mini-batch   150: 31.91072520\n",
            "Loss after mini-batch   200: 3.89213765\n",
            "Loss after mini-batch   250: 0.39491071\n",
            "Loss after mini-batch   300: 0.01942215\n",
            "Loss after mini-batch   350: 0.04576059\n",
            "Loss after mini-batch   400: 0.98362352\n",
            "Epoch  237 Total Loss  6.763720299846368\n",
            "Epoch  237 Loss 1  0.007582752905493661\n",
            "Epoch  237 Loss 2 6.756137623876101\n",
            "Starting epoch 238\n",
            "Loss after mini-batch    50: 43.10886628\n",
            "Loss after mini-batch   100: 1.53651562\n",
            "Loss after mini-batch   150: 6.12109278\n",
            "Loss after mini-batch   200: 1.23994899\n",
            "Loss after mini-batch   250: 0.44821560\n",
            "Loss after mini-batch   300: 0.01241011\n",
            "Loss after mini-batch   350: 0.04408193\n",
            "Loss after mini-batch   400: 0.07251356\n",
            "Epoch  238 Total Loss  6.066831887229829\n",
            "Epoch  238 Loss 1  0.006948753740958302\n",
            "Epoch  238 Loss 2 6.059883020552414\n",
            "Starting epoch 239\n",
            "Loss after mini-batch    50: 9.49063795\n",
            "Loss after mini-batch   100: 1.23371550\n",
            "Loss after mini-batch   150: 23.51631493\n",
            "Loss after mini-batch   200: 1.29008570\n",
            "Loss after mini-batch   250: 1.51473603\n",
            "Loss after mini-batch   300: 0.02008751\n",
            "Loss after mini-batch   350: 0.09294105\n",
            "Loss after mini-batch   400: 0.36660449\n",
            "Epoch  239 Total Loss  4.361518845809318\n",
            "Epoch  239 Loss 1  0.009208490108253552\n",
            "Epoch  239 Loss 2 4.352310443912761\n",
            "Starting epoch 240\n",
            "Loss after mini-batch    50: 36.03774831\n",
            "Loss after mini-batch   100: 1.05621839\n",
            "Loss after mini-batch   150: 0.40656227\n",
            "Loss after mini-batch   200: 0.06209378\n",
            "Loss after mini-batch   250: 0.93122675\n",
            "Loss after mini-batch   300: 0.02123745\n",
            "Loss after mini-batch   350: 0.02612070\n",
            "Loss after mini-batch   400: 0.03233238\n",
            "Epoch  240 Total Loss  4.4501619701288835\n",
            "Epoch  240 Loss 1  0.00846553272904307\n",
            "Epoch  240 Loss 2 4.441696594262543\n",
            "Starting epoch 241\n",
            "Loss after mini-batch    50: 1.81969992\n",
            "Loss after mini-batch   100: 0.53579223\n",
            "Loss after mini-batch   150: 3.74380614\n",
            "Loss after mini-batch   200: 1.67729993\n",
            "Loss after mini-batch   250: 0.24057485\n",
            "Loss after mini-batch   300: 0.01387757\n",
            "Loss after mini-batch   350: 0.02131993\n",
            "Loss after mini-batch   400: 0.04738125\n",
            "Epoch  241 Total Loss  0.9475065364603209\n",
            "Epoch  241 Loss 1  0.0074750233239997054\n",
            "Epoch  241 Loss 2 0.9400315031542302\n",
            "Starting epoch 242\n",
            "Loss after mini-batch    50: 7.81688592\n",
            "Loss after mini-batch   100: 4.77309679\n",
            "Loss after mini-batch   150: 4.38558672\n",
            "Loss after mini-batch   200: 0.45222944\n",
            "Loss after mini-batch   250: 0.20070380\n",
            "Loss after mini-batch   300: 0.01278392\n",
            "Loss after mini-batch   350: 0.02846790\n",
            "Loss after mini-batch   400: 0.16726433\n",
            "Epoch  242 Total Loss  2.054570321540333\n",
            "Epoch  242 Loss 1  0.00779276791087806\n",
            "Epoch  242 Loss 2 2.0467775523395066\n",
            "Starting epoch 243\n",
            "Loss after mini-batch    50: 2.64403976\n",
            "Loss after mini-batch   100: 0.07144799\n",
            "Loss after mini-batch   150: 11.91057631\n",
            "Loss after mini-batch   200: 5.73602050\n",
            "Loss after mini-batch   250: 2.97394027\n",
            "Loss after mini-batch   300: 0.01305135\n",
            "Loss after mini-batch   350: 0.01638724\n",
            "Loss after mini-batch   400: 0.06214112\n",
            "Epoch  243 Total Loss  2.715513987608026\n",
            "Epoch  243 Loss 1  0.008147525038302043\n",
            "Epoch  243 Loss 2 2.7073664715244483\n",
            "Starting epoch 244\n",
            "Loss after mini-batch    50: 0.48038072\n",
            "Loss after mini-batch   100: 0.20895278\n",
            "Loss after mini-batch   150: 0.67982651\n",
            "Loss after mini-batch   200: 0.71447177\n",
            "Loss after mini-batch   250: 0.17421210\n",
            "Loss after mini-batch   300: 0.06409685\n",
            "Loss after mini-batch   350: 0.11905573\n",
            "Loss after mini-batch   400: 0.02093460\n",
            "Epoch  244 Total Loss  0.30404784487132697\n",
            "Epoch  244 Loss 1  0.007449052903326844\n",
            "Epoch  244 Loss 2 0.2965987917994051\n",
            "Starting epoch 245\n",
            "Loss after mini-batch    50: 0.70192029\n",
            "Loss after mini-batch   100: 0.10454783\n",
            "Loss after mini-batch   150: 1.16088225\n",
            "Loss after mini-batch   200: 0.28600575\n",
            "Loss after mini-batch   250: 0.24561416\n",
            "Loss after mini-batch   300: 0.01464499\n",
            "Loss after mini-batch   350: 0.02203214\n",
            "Loss after mini-batch   400: 0.06937071\n",
            "Epoch  245 Total Loss  0.3046418388669286\n",
            "Epoch  245 Loss 1  0.007559600659304375\n",
            "Epoch  245 Loss 2 0.29708224005180867\n",
            "Starting epoch 246\n",
            "Loss after mini-batch    50: 0.18135585\n",
            "Loss after mini-batch   100: 0.06780625\n",
            "Loss after mini-batch   150: 0.23401773\n",
            "Loss after mini-batch   200: 0.03279939\n",
            "Loss after mini-batch   250: 0.07674973\n",
            "Loss after mini-batch   300: 0.01357660\n",
            "Loss after mini-batch   350: 0.02806109\n",
            "Loss after mini-batch   400: 0.04485111\n",
            "Epoch  246 Total Loss  0.08143644860551988\n",
            "Epoch  246 Loss 1  0.007313905056067054\n",
            "Epoch  246 Loss 2 0.07412254334204131\n",
            "Starting epoch 247\n",
            "Loss after mini-batch    50: 0.40613465\n",
            "Loss after mini-batch   100: 0.32151808\n",
            "Loss after mini-batch   150: 0.20837772\n",
            "Loss after mini-batch   200: 0.02501450\n",
            "Loss after mini-batch   250: 0.06754422\n",
            "Loss after mini-batch   300: 0.01106805\n",
            "Loss after mini-batch   350: 0.01974855\n",
            "Loss after mini-batch   400: 0.01797824\n",
            "Epoch  247 Total Loss  0.12753802702306227\n",
            "Epoch  247 Loss 1  0.007274663140903623\n",
            "Epoch  247 Loss 2 0.12026336331471899\n",
            "Starting epoch 248\n",
            "Loss after mini-batch    50: 0.50853002\n",
            "Loss after mini-batch   100: 0.09680682\n",
            "Loss after mini-batch   150: 4.73712519\n",
            "Loss after mini-batch   200: 0.43196639\n",
            "Loss after mini-batch   250: 0.10003365\n",
            "Loss after mini-batch   300: 0.03612269\n",
            "Loss after mini-batch   350: 0.03542586\n",
            "Loss after mini-batch   400: 0.02072776\n",
            "Epoch  248 Total Loss  0.6889581057469022\n",
            "Epoch  248 Loss 1  0.006938686831705419\n",
            "Epoch  248 Loss 2 0.6820194138444989\n",
            "Starting epoch 249\n",
            "Loss after mini-batch    50: 0.86547267\n",
            "Loss after mini-batch   100: 3.00328597\n",
            "Loss after mini-batch   150: 12.48400217\n",
            "Loss after mini-batch   200: 2.43145384\n",
            "Loss after mini-batch   250: 3.28622122\n",
            "Loss after mini-batch   300: 0.19544648\n",
            "Loss after mini-batch   350: 0.64324828\n",
            "Loss after mini-batch   400: 2.03294356\n",
            "Epoch  249 Total Loss  3.0286843432609634\n",
            "Epoch  249 Loss 1  0.008190494611168189\n",
            "Epoch  249 Loss 2 3.020493846586688\n",
            "Starting epoch 250\n",
            "Loss after mini-batch    50: 3.46691557\n",
            "Loss after mini-batch   100: 0.09992399\n",
            "Loss after mini-batch   150: 2.02375187\n",
            "Loss after mini-batch   200: 1.87567496\n",
            "Loss after mini-batch   250: 0.53624348\n",
            "Loss after mini-batch   300: 0.02330094\n",
            "Loss after mini-batch   350: 0.05468614\n",
            "Loss after mini-batch   400: 0.65250386\n",
            "Epoch  250 Total Loss  1.069073940341386\n",
            "Epoch  250 Loss 1  0.008010271041917155\n",
            "Epoch  250 Loss 2 1.0610636775108466\n",
            "Starting epoch 251\n",
            "Loss after mini-batch    50: 1.35910141\n",
            "Loss after mini-batch   100: 0.56736688\n",
            "Loss after mini-batch   150: 19.70163875\n",
            "Loss after mini-batch   200: 0.06168606\n",
            "Loss after mini-batch   250: 0.09298102\n",
            "Loss after mini-batch   300: 0.01840481\n",
            "Loss after mini-batch   350: 0.02021771\n",
            "Loss after mini-batch   400: 0.01992192\n",
            "Epoch  251 Total Loss  2.5146877277708723\n",
            "Epoch  251 Loss 1  0.008169460890198463\n",
            "Epoch  251 Loss 2 2.5065182690856918\n",
            "Starting epoch 252\n",
            "Loss after mini-batch    50: 4.09068122\n",
            "Loss after mini-batch   100: 0.02162756\n",
            "Loss after mini-batch   150: 0.11599550\n",
            "Loss after mini-batch   200: 0.04146043\n",
            "Loss after mini-batch   250: 0.13912525\n",
            "Loss after mini-batch   300: 0.01224522\n",
            "Loss after mini-batch   350: 0.02477917\n",
            "Loss after mini-batch   400: 0.06313965\n",
            "Epoch  252 Total Loss  0.5216887725868908\n",
            "Epoch  252 Loss 1  0.0074047016986309895\n",
            "Epoch  252 Loss 2 0.5142840600748154\n",
            "Starting epoch 253\n",
            "Loss after mini-batch    50: 0.14060571\n",
            "Loss after mini-batch   100: 0.06832499\n",
            "Loss after mini-batch   150: 0.32873408\n",
            "Loss after mini-batch   200: 0.11847370\n",
            "Loss after mini-batch   250: 0.05463332\n",
            "Loss after mini-batch   300: 0.02355218\n",
            "Loss after mini-batch   350: 0.03568258\n",
            "Loss after mini-batch   400: 0.05832193\n",
            "Epoch  253 Total Loss  0.10401720903892787\n",
            "Epoch  253 Loss 1  0.006933519756438173\n",
            "Epoch  253 Loss 2 0.0970836895493248\n",
            "Starting epoch 254\n",
            "Loss after mini-batch    50: 0.22104161\n",
            "Loss after mini-batch   100: 0.03567417\n",
            "Loss after mini-batch   150: 0.23791261\n",
            "Loss after mini-batch   200: 0.04168600\n",
            "Loss after mini-batch   250: 0.14487007\n",
            "Loss after mini-batch   300: 0.01120830\n",
            "Loss after mini-batch   350: 0.02395278\n",
            "Loss after mini-batch   400: 0.06103719\n",
            "Epoch  254 Total Loss  0.09220796625421586\n",
            "Epoch  254 Loss 1  0.007093135878643096\n",
            "Epoch  254 Loss 2 0.08511482989998424\n",
            "Starting epoch 255\n",
            "Loss after mini-batch    50: 0.09576702\n",
            "Loss after mini-batch   100: 0.01835892\n",
            "Loss after mini-batch   150: 0.02838145\n",
            "Loss after mini-batch   200: 0.04286751\n",
            "Loss after mini-batch   250: 0.01596446\n",
            "Loss after mini-batch   300: 0.01403815\n",
            "Loss after mini-batch   350: 0.01563981\n",
            "Loss after mini-batch   400: 0.00979260\n",
            "Epoch  255 Total Loss  0.029850450720843438\n",
            "Epoch  255 Loss 1  0.006991297450156122\n",
            "Epoch  255 Loss 2 0.022859153453243228\n",
            "Starting epoch 256\n",
            "Loss after mini-batch    50: 0.04409069\n",
            "Loss after mini-batch   100: 0.01101292\n",
            "Loss after mini-batch   150: 0.03800013\n",
            "Loss after mini-batch   200: 0.01827546\n",
            "Loss after mini-batch   250: 0.03799943\n",
            "Loss after mini-batch   300: 0.01017913\n",
            "Loss after mini-batch   350: 0.01190434\n",
            "Loss after mini-batch   400: 0.00939497\n",
            "Epoch  256 Total Loss  0.021539375059833166\n",
            "Epoch  256 Loss 1  0.006733463887538729\n",
            "Epoch  256 Loss 2 0.014805911287529023\n",
            "Starting epoch 257\n",
            "Loss after mini-batch    50: 0.06871471\n",
            "Loss after mini-batch   100: 0.01367689\n",
            "Loss after mini-batch   150: 0.02135304\n",
            "Loss after mini-batch   200: 0.02763612\n",
            "Loss after mini-batch   250: 0.02041069\n",
            "Loss after mini-batch   300: 0.01216260\n",
            "Loss after mini-batch   350: 0.01250902\n",
            "Loss after mini-batch   400: 0.11526704\n",
            "Epoch  257 Total Loss  0.03445592214535365\n",
            "Epoch  257 Loss 1  0.007465908180985161\n",
            "Epoch  257 Loss 2 0.026990013782996747\n",
            "Starting epoch 258\n",
            "Loss after mini-batch    50: 0.02547693\n",
            "Loss after mini-batch   100: 0.01224869\n",
            "Loss after mini-batch   150: 0.02984498\n",
            "Loss after mini-batch   200: 0.02401970\n",
            "Loss after mini-batch   250: 0.02852981\n",
            "Loss after mini-batch   300: 0.01213239\n",
            "Loss after mini-batch   350: 0.01258942\n",
            "Loss after mini-batch   400: 0.00660755\n",
            "Epoch  258 Total Loss  0.0185108568080622\n",
            "Epoch  258 Loss 1  0.008151009635653229\n",
            "Epoch  258 Loss 2 0.010359847130659548\n",
            "Starting epoch 259\n",
            "Loss after mini-batch    50: 0.02429810\n",
            "Loss after mini-batch   100: 0.01240715\n",
            "Loss after mini-batch   150: 0.02332253\n",
            "Loss after mini-batch   200: 0.02556247\n",
            "Loss after mini-batch   250: 0.02548401\n",
            "Loss after mini-batch   300: 0.01181436\n",
            "Loss after mini-batch   350: 0.01275324\n",
            "Loss after mini-batch   400: 0.00577173\n",
            "Epoch  259 Total Loss  0.01741785886940003\n",
            "Epoch  259 Loss 1  0.0073616025659447035\n",
            "Epoch  259 Loss 2 0.010056256286945101\n",
            "Starting epoch 260\n",
            "Loss after mini-batch    50: 0.02516082\n",
            "Loss after mini-batch   100: 0.01264537\n",
            "Loss after mini-batch   150: 0.01825601\n",
            "Loss after mini-batch   200: 0.03104371\n",
            "Loss after mini-batch   250: 0.02062546\n",
            "Loss after mini-batch   300: 0.01256358\n",
            "Loss after mini-batch   350: 0.01355146\n",
            "Loss after mini-batch   400: 0.00606648\n",
            "Epoch  260 Total Loss  0.01724784541756367\n",
            "Epoch  260 Loss 1  0.007264810687139424\n",
            "Epoch  260 Loss 2 0.009983034850965584\n",
            "Starting epoch 261\n",
            "Loss after mini-batch    50: 0.02499896\n",
            "Loss after mini-batch   100: 0.01374941\n",
            "Loss after mini-batch   150: 0.01375789\n",
            "Loss after mini-batch   200: 0.04351572\n",
            "Loss after mini-batch   250: 0.01714855\n",
            "Loss after mini-batch   300: 0.01298966\n",
            "Loss after mini-batch   350: 0.01393050\n",
            "Loss after mini-batch   400: 0.00651787\n",
            "Epoch  261 Total Loss  0.018043988262789575\n",
            "Epoch  261 Loss 1  0.007054110259856713\n",
            "Epoch  261 Loss 2 0.0109898781701346\n",
            "Starting epoch 262\n",
            "Loss after mini-batch    50: 0.02310398\n",
            "Loss after mini-batch   100: 0.01578639\n",
            "Loss after mini-batch   150: 0.02298205\n",
            "Loss after mini-batch   200: 0.07681680\n",
            "Loss after mini-batch   250: 0.01819825\n",
            "Loss after mini-batch   300: 0.01397877\n",
            "Loss after mini-batch   350: 0.01448577\n",
            "Loss after mini-batch   400: 0.00652547\n",
            "Epoch  262 Total Loss  0.023143243546572236\n",
            "Epoch  262 Loss 1  0.006703367254973775\n",
            "Epoch  262 Loss 2 0.016439876157240286\n",
            "Starting epoch 263\n",
            "Loss after mini-batch    50: 0.02174711\n",
            "Loss after mini-batch   100: 0.01997587\n",
            "Loss after mini-batch   150: 0.02486346\n",
            "Loss after mini-batch   200: 0.07490650\n",
            "Loss after mini-batch   250: 0.01499854\n",
            "Loss after mini-batch   300: 0.01377517\n",
            "Loss after mini-batch   350: 0.01448620\n",
            "Loss after mini-batch   400: 0.00682833\n",
            "Epoch  263 Total Loss  0.023044777785704858\n",
            "Epoch  263 Loss 1  0.006790054915339055\n",
            "Epoch  263 Loss 2 0.016254722882960336\n",
            "Starting epoch 264\n",
            "Loss after mini-batch    50: 0.02004046\n",
            "Loss after mini-batch   100: 0.02348958\n",
            "Loss after mini-batch   150: 0.01303843\n",
            "Loss after mini-batch   200: 0.04970810\n",
            "Loss after mini-batch   250: 0.01834702\n",
            "Loss after mini-batch   300: 0.01319303\n",
            "Loss after mini-batch   350: 0.01414649\n",
            "Loss after mini-batch   400: 0.00600300\n",
            "Epoch  264 Total Loss  0.019085176202037705\n",
            "Epoch  264 Loss 1  0.006451293426703316\n",
            "Epoch  264 Loss 2 0.012633882693896698\n",
            "Starting epoch 265\n",
            "Loss after mini-batch    50: 0.01896379\n",
            "Loss after mini-batch   100: 0.03202451\n",
            "Loss after mini-batch   150: 0.29514170\n",
            "Loss after mini-batch   200: 0.04071229\n",
            "Loss after mini-batch   250: 0.05938414\n",
            "Loss after mini-batch   300: 0.01297631\n",
            "Loss after mini-batch   350: 0.01390084\n",
            "Loss after mini-batch   400: 0.00558481\n",
            "Epoch  265 Total Loss  0.05590685707848651\n",
            "Epoch  265 Loss 1  0.006386346928766947\n",
            "Epoch  265 Loss 2 0.049520510626909264\n",
            "Starting epoch 266\n",
            "Loss after mini-batch    50: 0.01779187\n",
            "Loss after mini-batch   100: 0.03741391\n",
            "Loss after mini-batch   150: 0.26800594\n",
            "Loss after mini-batch   200: 0.19354167\n",
            "Loss after mini-batch   250: 0.35579910\n",
            "Loss after mini-batch   300: 0.01666554\n",
            "Loss after mini-batch   350: 0.01559666\n",
            "Loss after mini-batch   400: 0.06529176\n",
            "Epoch  266 Total Loss  0.11529061044716034\n",
            "Epoch  266 Loss 1  0.006995715557849476\n",
            "Epoch  266 Loss 2 0.10829489385126402\n",
            "Starting epoch 267\n",
            "Loss after mini-batch    50: 0.04726217\n",
            "Loss after mini-batch   100: 0.03194813\n",
            "Loss after mini-batch   150: 0.31720324\n",
            "Loss after mini-batch   200: 0.04486660\n",
            "Loss after mini-batch   250: 0.06297648\n",
            "Loss after mini-batch   300: 0.01371356\n",
            "Loss after mini-batch   350: 0.01419257\n",
            "Loss after mini-batch   400: 0.00647313\n",
            "Epoch  267 Total Loss  0.06284883573826773\n",
            "Epoch  267 Loss 1  0.007138623959054848\n",
            "Epoch  267 Loss 2 0.05571021175394439\n",
            "Starting epoch 268\n",
            "Loss after mini-batch    50: 0.01950585\n",
            "Loss after mini-batch   100: 0.03583632\n",
            "Loss after mini-batch   150: 0.52153904\n",
            "Loss after mini-batch   200: 0.10063163\n",
            "Loss after mini-batch   250: 0.10629506\n",
            "Loss after mini-batch   300: 0.01232209\n",
            "Loss after mini-batch   350: 0.01331393\n",
            "Loss after mini-batch   400: 0.00552494\n",
            "Epoch  268 Total Loss  0.09464132876498203\n",
            "Epoch  268 Loss 1  0.006842312263375036\n",
            "Epoch  268 Loss 2 0.0877990168223961\n",
            "Starting epoch 269\n",
            "Loss after mini-batch    50: 0.01985615\n",
            "Loss after mini-batch   100: 0.03259386\n",
            "Loss after mini-batch   150: 0.23937055\n",
            "Loss after mini-batch   200: 0.03195381\n",
            "Loss after mini-batch   250: 0.05339182\n",
            "Loss after mini-batch   300: 0.01312062\n",
            "Loss after mini-batch   350: 0.01447385\n",
            "Loss after mini-batch   400: 0.00564747\n",
            "Epoch  269 Total Loss  0.04809073392918498\n",
            "Epoch  269 Loss 1  0.006744775276377043\n",
            "Epoch  269 Loss 2 0.041345959006579086\n",
            "Starting epoch 270\n",
            "Loss after mini-batch    50: 0.01869124\n",
            "Loss after mini-batch   100: 0.03590493\n",
            "Loss after mini-batch   150: 0.55438334\n",
            "Loss after mini-batch   200: 0.11185398\n",
            "Loss after mini-batch   250: 0.10997308\n",
            "Loss after mini-batch   300: 0.01179113\n",
            "Loss after mini-batch   350: 0.01296731\n",
            "Loss after mini-batch   400: 0.00545763\n",
            "Epoch  270 Total Loss  0.09991902083720665\n",
            "Epoch  270 Loss 1  0.006577893528815\n",
            "Epoch  270 Loss 2 0.09334112728999787\n",
            "Starting epoch 271\n",
            "Loss after mini-batch    50: 0.01902817\n",
            "Loss after mini-batch   100: 0.03167983\n",
            "Loss after mini-batch   150: 0.36291898\n",
            "Loss after mini-batch   200: 0.13596094\n",
            "Loss after mini-batch   250: 0.12337840\n",
            "Loss after mini-batch   300: 0.01247446\n",
            "Loss after mini-batch   350: 0.01401294\n",
            "Loss after mini-batch   400: 0.00601212\n",
            "Epoch  271 Total Loss  0.08207194610464473\n",
            "Epoch  271 Loss 1  0.006787697440224041\n",
            "Epoch  271 Loss 2 0.07528424771777259\n",
            "Starting epoch 272\n",
            "Loss after mini-batch    50: 0.15558421\n",
            "Loss after mini-batch   100: 0.01718219\n",
            "Loss after mini-batch   150: 0.31343910\n",
            "Loss after mini-batch   200: 0.31414866\n",
            "Loss after mini-batch   250: 0.54652151\n",
            "Loss after mini-batch   300: 0.02355303\n",
            "Loss after mini-batch   350: 0.02727064\n",
            "Loss after mini-batch   400: 0.01855529\n",
            "Epoch  272 Total Loss  0.16367362837874846\n",
            "Epoch  272 Loss 1  0.008531518290734291\n",
            "Epoch  272 Loss 2 0.1551421094384966\n",
            "Starting epoch 273\n",
            "Loss after mini-batch    50: 0.29157976\n",
            "Loss after mini-batch   100: 0.10333198\n",
            "Loss after mini-batch   150: 0.26800651\n",
            "Loss after mini-batch   200: 0.03968589\n",
            "Loss after mini-batch   250: 0.06096472\n",
            "Loss after mini-batch   300: 0.01402751\n",
            "Loss after mini-batch   350: 0.01380960\n",
            "Loss after mini-batch   400: 0.00576455\n",
            "Epoch  273 Total Loss  0.09257956881737792\n",
            "Epoch  273 Loss 1  0.008030660871125962\n",
            "Epoch  273 Loss 2 0.08454890866629164\n",
            "Starting epoch 274\n",
            "Loss after mini-batch    50: 0.02173160\n",
            "Loss after mini-batch   100: 0.03719835\n",
            "Loss after mini-batch   150: 0.43711538\n",
            "Loss after mini-batch   200: 0.07604925\n",
            "Loss after mini-batch   250: 0.08649945\n",
            "Loss after mini-batch   300: 0.01396980\n",
            "Loss after mini-batch   350: 0.01385667\n",
            "Loss after mini-batch   400: 0.00593882\n",
            "Epoch  274 Total Loss  0.0805845980416052\n",
            "Epoch  274 Loss 1  0.007525869540538339\n",
            "Epoch  274 Loss 2 0.07305872759421524\n",
            "Starting epoch 275\n",
            "Loss after mini-batch    50: 0.02162149\n",
            "Loss after mini-batch   100: 0.03421967\n",
            "Loss after mini-batch   150: 0.33654151\n",
            "Loss after mini-batch   200: 0.05011500\n",
            "Loss after mini-batch   250: 0.06643979\n",
            "Loss after mini-batch   300: 0.01299396\n",
            "Loss after mini-batch   350: 0.01396631\n",
            "Loss after mini-batch   400: 0.00627557\n",
            "Epoch  275 Total Loss  0.06324508925042638\n",
            "Epoch  275 Loss 1  0.007129128154618271\n",
            "Epoch  275 Loss 2 0.05611596203328055\n",
            "Starting epoch 276\n",
            "Loss after mini-batch    50: 0.02034366\n",
            "Loss after mini-batch   100: 0.03606671\n",
            "Loss after mini-batch   150: 0.47143124\n",
            "Loss after mini-batch   200: 0.08480390\n",
            "Loss after mini-batch   250: 0.09030433\n",
            "Loss after mini-batch   300: 0.01258460\n",
            "Loss after mini-batch   350: 0.01354646\n",
            "Loss after mini-batch   400: 0.00566022\n",
            "Epoch  276 Total Loss  0.08542033104308287\n",
            "Epoch  276 Loss 1  0.006789760132383451\n",
            "Epoch  276 Loss 2 0.07863057011455823\n",
            "Starting epoch 277\n",
            "Loss after mini-batch    50: 0.02067029\n",
            "Loss after mini-batch   100: 0.03386885\n",
            "Loss after mini-batch   150: 0.29795598\n",
            "Loss after mini-batch   200: 0.04156935\n",
            "Loss after mini-batch   250: 0.06187024\n",
            "Loss after mini-batch   300: 0.01333475\n",
            "Loss after mini-batch   350: 0.01399697\n",
            "Loss after mini-batch   400: 0.00643000\n",
            "Epoch  277 Total Loss  0.05724256164168513\n",
            "Epoch  277 Loss 1  0.0069715731084111264\n",
            "Epoch  277 Loss 2 0.05027098813116787\n",
            "Starting epoch 278\n",
            "Loss after mini-batch    50: 0.01997251\n",
            "Loss after mini-batch   100: 0.03578082\n",
            "Loss after mini-batch   150: 0.50819106\n",
            "Loss after mini-batch   200: 0.09622909\n",
            "Loss after mini-batch   250: 0.09827793\n",
            "Loss after mini-batch   300: 0.01248896\n",
            "Loss after mini-batch   350: 0.01278699\n",
            "Loss after mini-batch   400: 0.00577442\n",
            "Epoch  278 Total Loss  0.09169073785997589\n",
            "Epoch  278 Loss 1  0.006731954945991319\n",
            "Epoch  278 Loss 2 0.08495878183018984\n",
            "Starting epoch 279\n",
            "Loss after mini-batch    50: 0.01986172\n",
            "Loss after mini-batch   100: 0.03325905\n",
            "Loss after mini-batch   150: 0.25319714\n",
            "Loss after mini-batch   200: 0.03343863\n",
            "Loss after mini-batch   250: 0.05401156\n",
            "Loss after mini-batch   300: 0.01319244\n",
            "Loss after mini-batch   350: 0.01366829\n",
            "Loss after mini-batch   400: 0.00587634\n",
            "Epoch  279 Total Loss  0.04990869124400585\n",
            "Epoch  279 Loss 1  0.00644714065011853\n",
            "Epoch  279 Loss 2 0.0434615507964577\n",
            "Starting epoch 280\n",
            "Loss after mini-batch    50: 0.01868828\n",
            "Loss after mini-batch   100: 0.05226643\n",
            "Loss after mini-batch   150: 0.45095992\n",
            "Loss after mini-batch   200: 0.07652060\n",
            "Loss after mini-batch   250: 1.04923407\n",
            "Loss after mini-batch   300: 0.04714338\n",
            "Loss after mini-batch   350: 0.01391453\n",
            "Loss after mini-batch   400: 0.01299815\n",
            "Epoch  280 Total Loss  0.19924940626881615\n",
            "Epoch  280 Loss 1  0.009243547421797773\n",
            "Epoch  280 Loss 2 0.19000585550518595\n",
            "Starting epoch 281\n",
            "Loss after mini-batch    50: 0.02381790\n",
            "Loss after mini-batch   100: 0.03442999\n",
            "Loss after mini-batch   150: 0.31747521\n",
            "Loss after mini-batch   200: 0.04989530\n",
            "Loss after mini-batch   250: 0.06682582\n",
            "Loss after mini-batch   300: 0.01604230\n",
            "Loss after mini-batch   350: 0.01483319\n",
            "Loss after mini-batch   400: 0.00729524\n",
            "Epoch  281 Total Loss  0.06221205986783326\n",
            "Epoch  281 Loss 1  0.009397041117544983\n",
            "Epoch  281 Loss 2 0.052815019061831156\n",
            "Starting epoch 282\n",
            "Loss after mini-batch    50: 0.03502100\n",
            "Loss after mini-batch   100: 0.03551145\n",
            "Loss after mini-batch   150: 0.48311009\n",
            "Loss after mini-batch   200: 0.09174372\n",
            "Loss after mini-batch   250: 0.09414383\n",
            "Loss after mini-batch   300: 0.01432887\n",
            "Loss after mini-batch   350: 0.01423259\n",
            "Loss after mini-batch   400: 0.00727063\n",
            "Epoch  282 Total Loss  0.09028590894717356\n",
            "Epoch  282 Loss 1  0.009049593312257697\n",
            "Epoch  282 Loss 2 0.08123631630616013\n",
            "Starting epoch 283\n",
            "Loss after mini-batch    50: 0.02165000\n",
            "Loss after mini-batch   100: 0.03371453\n",
            "Loss after mini-batch   150: 0.29864840\n",
            "Loss after mini-batch   200: 0.04550418\n",
            "Loss after mini-batch   250: 0.06200459\n",
            "Loss after mini-batch   300: 0.01350460\n",
            "Loss after mini-batch   350: 0.01504041\n",
            "Loss after mini-batch   400: 0.00745466\n",
            "Epoch  283 Total Loss  0.05823448653983209\n",
            "Epoch  283 Loss 1  0.008169182776520297\n",
            "Epoch  283 Loss 2 0.05006530299480186\n",
            "Starting epoch 284\n",
            "Loss after mini-batch    50: 0.12349191\n",
            "Loss after mini-batch   100: 0.04352891\n",
            "Loss after mini-batch   150: 0.01892571\n",
            "Loss after mini-batch   200: 0.04227517\n",
            "Loss after mini-batch   250: 0.02656189\n",
            "Loss after mini-batch   300: 0.01692547\n",
            "Loss after mini-batch   350: 0.01572298\n",
            "Loss after mini-batch   400: 0.00709752\n",
            "Epoch  284 Total Loss  0.034930380671546024\n",
            "Epoch  284 Loss 1  0.00878062292325629\n",
            "Epoch  284 Loss 2 0.026149757910855644\n",
            "Starting epoch 285\n",
            "Loss after mini-batch    50: 0.02312446\n",
            "Loss after mini-batch   100: 0.04338066\n",
            "Loss after mini-batch   150: 1.02767402\n",
            "Loss after mini-batch   200: 0.37255086\n",
            "Loss after mini-batch   250: 0.36531744\n",
            "Loss after mini-batch   300: 0.01050692\n",
            "Loss after mini-batch   350: 0.01583198\n",
            "Loss after mini-batch   400: 0.02173996\n",
            "Epoch  285 Total Loss  0.21709307745145845\n",
            "Epoch  285 Loss 1  0.008599565114638377\n",
            "Epoch  285 Loss 2 0.20849351532568547\n",
            "Starting epoch 286\n",
            "Loss after mini-batch    50: 0.02368581\n",
            "Loss after mini-batch   100: 0.02184920\n",
            "Loss after mini-batch   150: 0.01679323\n",
            "Loss after mini-batch   200: 0.06093813\n",
            "Loss after mini-batch   250: 0.01626184\n",
            "Loss after mini-batch   300: 0.01463455\n",
            "Loss after mini-batch   350: 0.01486752\n",
            "Loss after mini-batch   400: 0.00649504\n",
            "Epoch  286 Total Loss  0.021278606975653834\n",
            "Epoch  286 Loss 1  0.007846644443567526\n",
            "Epoch  286 Loss 2 0.01343196247366798\n",
            "Starting epoch 287\n",
            "Loss after mini-batch    50: 0.05555737\n",
            "Loss after mini-batch   100: 0.01202749\n",
            "Loss after mini-batch   150: 0.15430503\n",
            "Loss after mini-batch   200: 0.02420853\n",
            "Loss after mini-batch   250: 0.05019264\n",
            "Loss after mini-batch   300: 0.01341392\n",
            "Loss after mini-batch   350: 0.01425341\n",
            "Loss after mini-batch   400: 0.00739111\n",
            "Epoch  287 Total Loss  0.03910632273876416\n",
            "Epoch  287 Loss 1  0.007760099779729846\n",
            "Epoch  287 Loss 2 0.031346222642844306\n",
            "Starting epoch 288\n",
            "Loss after mini-batch    50: 0.02174871\n",
            "Loss after mini-batch   100: 0.03290898\n",
            "Loss after mini-batch   150: 0.22228867\n",
            "Loss after mini-batch   200: 0.02962708\n",
            "Loss after mini-batch   250: 0.05159421\n",
            "Loss after mini-batch   300: 0.01383242\n",
            "Loss after mini-batch   350: 0.01479211\n",
            "Loss after mini-batch   400: 0.00710289\n",
            "Epoch  288 Total Loss  0.046242133781423285\n",
            "Epoch  288 Loss 1  0.007572096871779482\n",
            "Epoch  288 Loss 2 0.03867003686839056\n",
            "Starting epoch 289\n",
            "Loss after mini-batch    50: 0.02060475\n",
            "Loss after mini-batch   100: 0.03625604\n",
            "Loss after mini-batch   150: 0.56642741\n",
            "Loss after mini-batch   200: 0.11671222\n",
            "Loss after mini-batch   250: 0.11296276\n",
            "Loss after mini-batch   300: 0.01242734\n",
            "Loss after mini-batch   350: 0.01313924\n",
            "Loss after mini-batch   400: 0.00551159\n",
            "Epoch  289 Total Loss  0.10260326673608573\n",
            "Epoch  289 Loss 1  0.0071494847662287265\n",
            "Epoch  289 Loss 2 0.09545378164116676\n",
            "Starting epoch 290\n",
            "Loss after mini-batch    50: 0.22970354\n",
            "Loss after mini-batch   100: 0.08318316\n",
            "Loss after mini-batch   150: 0.27009902\n",
            "Loss after mini-batch   200: 0.04045669\n",
            "Loss after mini-batch   250: 0.06292591\n",
            "Loss after mini-batch   300: 0.01607178\n",
            "Loss after mini-batch   350: 0.01468085\n",
            "Loss after mini-batch   400: 0.00659505\n",
            "Epoch  290 Total Loss  0.08424112286850885\n",
            "Epoch  290 Loss 1  0.008344036817514531\n",
            "Epoch  290 Loss 2 0.07589708679217048\n",
            "Starting epoch 291\n",
            "Loss after mini-batch    50: 0.02182412\n",
            "Loss after mini-batch   100: 0.03478899\n",
            "Loss after mini-batch   150: 0.42302628\n",
            "Loss after mini-batch   200: 0.07141148\n",
            "Loss after mini-batch   250: 0.08096849\n",
            "Loss after mini-batch   300: 0.01316646\n",
            "Loss after mini-batch   350: 0.01389425\n",
            "Loss after mini-batch   400: 0.00605332\n",
            "Epoch  291 Total Loss  0.07732240074113796\n",
            "Epoch  291 Loss 1  0.007266828822622333\n",
            "Epoch  291 Loss 2 0.07005557255590943\n",
            "Starting epoch 292\n",
            "Loss after mini-batch    50: 0.02045894\n",
            "Loss after mini-batch   100: 0.03369196\n",
            "Loss after mini-batch   150: 0.32234771\n",
            "Loss after mini-batch   200: 0.11438391\n",
            "Loss after mini-batch   250: 0.68700197\n",
            "Loss after mini-batch   300: 0.02523945\n",
            "Loss after mini-batch   350: 0.05778082\n",
            "Loss after mini-batch   400: 0.10566027\n",
            "Epoch  292 Total Loss  0.158828197260371\n",
            "Epoch  292 Loss 1  0.009399881938350455\n",
            "Epoch  292 Loss 2 0.14942831371598747\n",
            "Starting epoch 293\n",
            "Loss after mini-batch    50: 0.02647072\n",
            "Loss after mini-batch   100: 0.03431516\n",
            "Loss after mini-batch   150: 0.23531596\n",
            "Loss after mini-batch   200: 0.03448318\n",
            "Loss after mini-batch   250: 0.05460104\n",
            "Loss after mini-batch   300: 0.01457288\n",
            "Loss after mini-batch   350: 0.01519259\n",
            "Loss after mini-batch   400: 0.00725756\n",
            "Epoch  293 Total Loss  0.04967956057316142\n",
            "Epoch  293 Loss 1  0.008670537771714648\n",
            "Epoch  293 Loss 2 0.04100902313021471\n",
            "Starting epoch 294\n",
            "Loss after mini-batch    50: 0.02033718\n",
            "Loss after mini-batch   100: 0.03630103\n",
            "Loss after mini-batch   150: 0.55501653\n",
            "Loss after mini-batch   200: 0.11565063\n",
            "Loss after mini-batch   250: 0.11036105\n",
            "Loss after mini-batch   300: 0.01319792\n",
            "Loss after mini-batch   350: 0.01362692\n",
            "Loss after mini-batch   400: 0.00668476\n",
            "Epoch  294 Total Loss  0.10121676170482266\n",
            "Epoch  294 Loss 1  0.008137229961144401\n",
            "Epoch  294 Loss 2 0.09307953120278818\n",
            "Starting epoch 295\n",
            "Loss after mini-batch    50: 0.02007125\n",
            "Loss after mini-batch   100: 0.03853374\n",
            "Loss after mini-batch   150: 0.15034118\n",
            "Loss after mini-batch   200: 0.02395205\n",
            "Loss after mini-batch   250: 0.04556217\n",
            "Loss after mini-batch   300: 0.01592488\n",
            "Loss after mini-batch   350: 0.01506727\n",
            "Loss after mini-batch   400: 0.00763722\n",
            "Epoch  295 Total Loss  0.03757842842220354\n",
            "Epoch  295 Loss 1  0.008683554215991304\n",
            "Epoch  295 Loss 2 0.028894874131776327\n",
            "Starting epoch 296\n",
            "Loss after mini-batch    50: 0.02176779\n",
            "Loss after mini-batch   100: 0.03773514\n",
            "Loss after mini-batch   150: 0.66161809\n",
            "Loss after mini-batch   200: 0.15681344\n",
            "Loss after mini-batch   250: 0.14234102\n",
            "Loss after mini-batch   300: 0.01217765\n",
            "Loss after mini-batch   350: 0.01318962\n",
            "Loss after mini-batch   400: 0.00759611\n",
            "Epoch  296 Total Loss  0.12222911214060635\n",
            "Epoch  296 Loss 1  0.008481299885948076\n",
            "Epoch  296 Loss 2 0.1137478127180371\n",
            "Starting epoch 297\n",
            "Loss after mini-batch    50: 6.07493983\n",
            "Loss after mini-batch   100: 1.56163552\n",
            "Loss after mini-batch   150: 2.18998183\n",
            "Loss after mini-batch   200: 1.04291950\n",
            "Loss after mini-batch   250: 1.59649252\n",
            "Loss after mini-batch   300: 0.07748480\n",
            "Loss after mini-batch   350: 0.25194158\n",
            "Loss after mini-batch   400: 0.75126335\n",
            "Epoch  297 Total Loss  1.594954513370721\n",
            "Epoch  297 Loss 1  0.008913523203637464\n",
            "Epoch  297 Loss 2 1.5860409936953095\n",
            "Starting epoch 298\n",
            "Loss after mini-batch    50: 0.68804453\n",
            "Loss after mini-batch   100: 0.01462975\n",
            "Loss after mini-batch   150: 0.05291257\n",
            "Loss after mini-batch   200: 0.01969172\n",
            "Loss after mini-batch   250: 0.04872975\n",
            "Loss after mini-batch   300: 0.01080645\n",
            "Loss after mini-batch   350: 0.01252999\n",
            "Loss after mini-batch   400: 0.01077636\n",
            "Epoch  298 Total Loss  0.09946385360841074\n",
            "Epoch  298 Loss 1  0.0077334861235456255\n",
            "Epoch  298 Loss 2 0.0917303696462834\n",
            "Starting epoch 299\n",
            "Loss after mini-batch    50: 0.02219557\n",
            "Loss after mini-batch   100: 0.01352201\n",
            "Loss after mini-batch   150: 0.03116668\n",
            "Loss after mini-batch   200: 0.02132734\n",
            "Loss after mini-batch   250: 0.02935667\n",
            "Loss after mini-batch   300: 0.01115108\n",
            "Loss after mini-batch   350: 0.01225427\n",
            "Loss after mini-batch   400: 0.00651845\n",
            "Epoch  299 Total Loss  0.01792454348472964\n",
            "Epoch  299 Loss 1  0.0071141350262694\n",
            "Epoch  299 Loss 2 0.010810408504177409\n",
            "Starting epoch 300\n",
            "Loss after mini-batch    50: 0.02396567\n",
            "Loss after mini-batch   100: 0.01336178\n",
            "Loss after mini-batch   150: 0.02665212\n",
            "Loss after mini-batch   200: 0.02338346\n",
            "Loss after mini-batch   250: 0.02633360\n",
            "Loss after mini-batch   300: 0.01177712\n",
            "Loss after mini-batch   350: 0.01244597\n",
            "Loss after mini-batch   400: 0.00599599\n",
            "Epoch  300 Total Loss  0.017592232567445514\n",
            "Epoch  300 Loss 1  0.00701785483404234\n",
            "Epoch  300 Loss 2 0.010574377761941835\n",
            "Starting epoch 301\n",
            "Loss after mini-batch    50: 0.02375463\n",
            "Loss after mini-batch   100: 0.01452525\n",
            "Loss after mini-batch   150: 0.01844534\n",
            "Loss after mini-batch   200: 0.02992986\n",
            "Loss after mini-batch   250: 0.01953876\n",
            "Loss after mini-batch   300: 0.01215964\n",
            "Loss after mini-batch   350: 0.01299302\n",
            "Loss after mini-batch   400: 0.00613756\n",
            "Epoch  301 Total Loss  0.01687559946920206\n",
            "Epoch  301 Loss 1  0.006717657532252575\n",
            "Epoch  301 Loss 2 0.010157942036223144\n",
            "Starting epoch 302\n",
            "Loss after mini-batch    50: 0.02323898\n",
            "Loss after mini-batch   100: 0.01670902\n",
            "Loss after mini-batch   150: 0.01288196\n",
            "Loss after mini-batch   200: 0.04727091\n",
            "Loss after mini-batch   250: 0.01491533\n",
            "Loss after mini-batch   300: 0.01336772\n",
            "Loss after mini-batch   350: 0.01373341\n",
            "Loss after mini-batch   400: 0.00977082\n",
            "Epoch  302 Total Loss  0.17052868954131806\n",
            "Epoch  302 Loss 1  0.006754702061244779\n",
            "Epoch  302 Loss 2 0.16377398990601985\n",
            "Starting epoch 303\n",
            "Loss after mini-batch    50: 0.14975612\n",
            "Loss after mini-batch   100: 0.02630567\n",
            "Loss after mini-batch   150: 0.04106602\n",
            "Loss after mini-batch   200: 0.10307642\n",
            "Loss after mini-batch   250: 0.01896277\n",
            "Loss after mini-batch   300: 0.01679569\n",
            "Loss after mini-batch   350: 0.01598685\n",
            "Loss after mini-batch   400: 0.00926274\n",
            "Epoch  303 Total Loss  0.04517814585255444\n",
            "Epoch  303 Loss 1  0.009510106053176582\n",
            "Epoch  303 Loss 2 0.03566803939706964\n",
            "Starting epoch 304\n",
            "Loss after mini-batch    50: 0.02541783\n",
            "Loss after mini-batch   100: 0.02413024\n",
            "Loss after mini-batch   150: 0.01607266\n",
            "Loss after mini-batch   200: 0.05606372\n",
            "Loss after mini-batch   250: 0.01921797\n",
            "Loss after mini-batch   300: 0.01560196\n",
            "Loss after mini-batch   350: 0.01483770\n",
            "Loss after mini-batch   400: 0.00786081\n",
            "Epoch  304 Total Loss  0.021840587293313705\n",
            "Epoch  304 Loss 1  0.009027440818355334\n",
            "Epoch  304 Loss 2 0.012813146639092447\n",
            "Starting epoch 305\n",
            "Loss after mini-batch    50: 0.02189300\n",
            "Loss after mini-batch   100: 0.03038467\n",
            "Loss after mini-batch   150: 0.08161289\n",
            "Loss after mini-batch   200: 0.02226256\n",
            "Loss after mini-batch   250: 0.03670753\n",
            "Loss after mini-batch   300: 0.01644863\n",
            "Loss after mini-batch   350: 0.01539510\n",
            "Loss after mini-batch   400: 0.00774983\n",
            "Epoch  305 Total Loss  0.027796005245298815\n",
            "Epoch  305 Loss 1  0.008892236901838574\n",
            "Epoch  305 Loss 2 0.01890376834921648\n",
            "Starting epoch 306\n",
            "Loss after mini-batch    50: 3.74597882\n",
            "Loss after mini-batch   100: 0.08577160\n",
            "Loss after mini-batch   150: 0.17277105\n",
            "Loss after mini-batch   200: 0.25540204\n",
            "Loss after mini-batch   250: 0.07157560\n",
            "Loss after mini-batch   300: 0.02163380\n",
            "Loss after mini-batch   350: 0.02466105\n",
            "Loss after mini-batch   400: 0.02297217\n",
            "Epoch  306 Total Loss  0.5078049461440426\n",
            "Epoch  306 Loss 1  0.008900344301411218\n",
            "Epoch  306 Loss 2 0.49890459815899907\n",
            "Starting epoch 307\n",
            "Loss after mini-batch    50: 0.11725926\n",
            "Loss after mini-batch   100: 0.01693384\n",
            "Loss after mini-batch   150: 0.02585902\n",
            "Loss after mini-batch   200: 0.03027518\n",
            "Loss after mini-batch   250: 0.02701496\n",
            "Loss after mini-batch   300: 0.01687014\n",
            "Loss after mini-batch   350: 0.01392660\n",
            "Loss after mini-batch   400: 0.00697562\n",
            "Epoch  307 Total Loss  0.030599950550471287\n",
            "Epoch  307 Loss 1  0.00924042626255628\n",
            "Epoch  307 Loss 2 0.021359524129635175\n",
            "Starting epoch 308\n",
            "Loss after mini-batch    50: 0.02511005\n",
            "Loss after mini-batch   100: 0.02156618\n",
            "Loss after mini-batch   150: 0.01695472\n",
            "Loss after mini-batch   200: 0.06194572\n",
            "Loss after mini-batch   250: 0.01741784\n",
            "Loss after mini-batch   300: 0.01410366\n",
            "Loss after mini-batch   350: 0.01486536\n",
            "Loss after mini-batch   400: 0.00721843\n",
            "Epoch  308 Total Loss  0.021690299811163494\n",
            "Epoch  308 Loss 1  0.008180464791259782\n",
            "Epoch  308 Loss 2 0.013509835196326028\n",
            "Starting epoch 309\n",
            "Loss after mini-batch    50: 0.02292844\n",
            "Loss after mini-batch   100: 0.02716427\n",
            "Loss after mini-batch   150: 0.02468895\n",
            "Loss after mini-batch   200: 0.03102246\n",
            "Loss after mini-batch   250: 0.02536892\n",
            "Loss after mini-batch   300: 0.01386269\n",
            "Loss after mini-batch   350: 0.01470755\n",
            "Loss after mini-batch   400: 0.00661625\n",
            "Epoch  309 Total Loss  0.02012107792563319\n",
            "Epoch  309 Loss 1  0.007713207735759661\n",
            "Epoch  309 Loss 2 0.012407870249212206\n",
            "Starting epoch 310\n",
            "Loss after mini-batch    50: 0.02023668\n",
            "Loss after mini-batch   100: 0.03532063\n",
            "Loss after mini-batch   150: 0.33498850\n",
            "Loss after mini-batch   200: 0.05072272\n",
            "Loss after mini-batch   250: 0.06649191\n",
            "Loss after mini-batch   300: 0.01374615\n",
            "Loss after mini-batch   350: 0.01495258\n",
            "Loss after mini-batch   400: 0.00702051\n",
            "Epoch  310 Total Loss  0.06349893142025143\n",
            "Epoch  310 Loss 1  0.007717150391745863\n",
            "Epoch  310 Loss 2 0.05578178050457577\n",
            "Starting epoch 311\n",
            "Loss after mini-batch    50: 0.02066068\n",
            "Loss after mini-batch   100: 0.03549456\n",
            "Loss after mini-batch   150: 0.49110864\n",
            "Loss after mini-batch   200: 0.09170385\n",
            "Loss after mini-batch   250: 0.09466154\n",
            "Loss after mini-batch   300: 0.01257083\n",
            "Loss after mini-batch   350: 0.01389499\n",
            "Loss after mini-batch   400: 0.00622248\n",
            "Epoch  311 Total Loss  0.08907331722099722\n",
            "Epoch  311 Loss 1  0.007329358223980579\n",
            "Epoch  311 Loss 2 0.08174395958126288\n",
            "Starting epoch 312\n",
            "Loss after mini-batch    50: 0.02031005\n",
            "Loss after mini-batch   100: 0.03333761\n",
            "Loss after mini-batch   150: 0.27819169\n",
            "Loss after mini-batch   200: 0.03985793\n",
            "Loss after mini-batch   250: 0.05838645\n",
            "Loss after mini-batch   300: 0.01318144\n",
            "Loss after mini-batch   350: 0.01473110\n",
            "Loss after mini-batch   400: 0.00642423\n",
            "Epoch  312 Total Loss  0.054327343673904925\n",
            "Epoch  312 Loss 1  0.007226468951457405\n",
            "Epoch  312 Loss 2 0.04710087465577816\n",
            "Starting epoch 313\n",
            "Loss after mini-batch    50: 0.01933920\n",
            "Loss after mini-batch   100: 0.05775821\n",
            "Loss after mini-batch   150: 0.41305944\n",
            "Loss after mini-batch   200: 0.06720657\n",
            "Loss after mini-batch   250: 0.07607821\n",
            "Loss after mini-batch   300: 0.01332551\n",
            "Loss after mini-batch   350: 0.01496792\n",
            "Loss after mini-batch   400: 0.00683676\n",
            "Epoch  313 Total Loss  0.0778881956122671\n",
            "Epoch  313 Loss 1  0.00790700500400472\n",
            "Epoch  313 Loss 2 0.06998119095699919\n",
            "Starting epoch 314\n",
            "Loss after mini-batch    50: 0.02119762\n",
            "Loss after mini-batch   100: 0.03532113\n",
            "Loss after mini-batch   150: 0.46765349\n",
            "Loss after mini-batch   200: 0.08428663\n",
            "Loss after mini-batch   250: 0.08973062\n",
            "Loss after mini-batch   300: 0.01252117\n",
            "Loss after mini-batch   350: 0.01396318\n",
            "Loss after mini-batch   400: 0.00600003\n",
            "Epoch  314 Total Loss  0.08498175231300478\n",
            "Epoch  314 Loss 1  0.007349103207726047\n",
            "Epoch  314 Loss 2 0.07763264889172089\n",
            "Starting epoch 315\n",
            "Loss after mini-batch    50: 0.02072010\n",
            "Loss after mini-batch   100: 0.03356168\n",
            "Loss after mini-batch   150: 0.30846603\n",
            "Loss after mini-batch   200: 0.04415414\n",
            "Loss after mini-batch   250: 0.06292259\n",
            "Loss after mini-batch   300: 0.01304670\n",
            "Loss after mini-batch   350: 0.01421217\n",
            "Loss after mini-batch   400: 0.00616923\n",
            "Epoch  315 Total Loss  0.05878123007336733\n",
            "Epoch  315 Loss 1  0.007002638461705212\n",
            "Epoch  315 Loss 2 0.05177859181898139\n",
            "Starting epoch 316\n",
            "Loss after mini-batch    50: 0.02006505\n",
            "Loss after mini-batch   100: 0.03526604\n",
            "Loss after mini-batch   150: 0.49601574\n",
            "Loss after mini-batch   200: 0.09252669\n",
            "Loss after mini-batch   250: 0.09622084\n",
            "Loss after mini-batch   300: 0.01290736\n",
            "Loss after mini-batch   350: 0.01314573\n",
            "Loss after mini-batch   400: 0.00607077\n",
            "Epoch  316 Total Loss  0.0896979580536664\n",
            "Epoch  316 Loss 1  0.006939004004722857\n",
            "Epoch  316 Loss 2 0.08275895386062551\n",
            "Starting epoch 317\n",
            "Loss after mini-batch    50: 0.05366322\n",
            "Loss after mini-batch   100: 0.01247892\n",
            "Loss after mini-batch   150: 0.15812717\n",
            "Loss after mini-batch   200: 0.02281466\n",
            "Loss after mini-batch   250: 0.04168868\n",
            "Loss after mini-batch   300: 0.01686208\n",
            "Loss after mini-batch   350: 0.01515184\n",
            "Loss after mini-batch   400: 0.00643551\n",
            "Epoch  317 Total Loss  0.03853486384229665\n",
            "Epoch  317 Loss 1  0.007861663737493545\n",
            "Epoch  317 Loss 2 0.03067320004755699\n",
            "Starting epoch 318\n",
            "Loss after mini-batch    50: 0.02021732\n",
            "Loss after mini-batch   100: 0.03861944\n",
            "Loss after mini-batch   150: 0.78128556\n",
            "Loss after mini-batch   200: 0.21233419\n",
            "Loss after mini-batch   250: 0.19277900\n",
            "Loss after mini-batch   300: 0.01370125\n",
            "Loss after mini-batch   350: 0.01256120\n",
            "Loss after mini-batch   400: 0.00756669\n",
            "Epoch  318 Total Loss  0.14808109349757834\n",
            "Epoch  318 Loss 1  0.007713147419961115\n",
            "Epoch  318 Loss 2 0.1403679455181799\n",
            "Starting epoch 319\n",
            "Loss after mini-batch    50: 0.02118128\n",
            "Loss after mini-batch   100: 0.02864069\n",
            "Loss after mini-batch   150: 0.02158340\n",
            "Loss after mini-batch   200: 0.03392813\n",
            "Loss after mini-batch   250: 0.02266339\n",
            "Loss after mini-batch   300: 0.01326300\n",
            "Loss after mini-batch   350: 0.01425562\n",
            "Loss after mini-batch   400: 0.00600718\n",
            "Epoch  319 Total Loss  0.019508720839753392\n",
            "Epoch  319 Loss 1  0.007207565381520845\n",
            "Epoch  319 Loss 2 0.012301155563694093\n",
            "Starting epoch 320\n",
            "Loss after mini-batch    50: 0.01970987\n",
            "Loss after mini-batch   100: 0.03433259\n",
            "Loss after mini-batch   150: 0.37975094\n",
            "Loss after mini-batch   200: 0.05989899\n",
            "Loss after mini-batch   250: 0.07280295\n",
            "Loss after mini-batch   300: 0.01289623\n",
            "Loss after mini-batch   350: 0.01401899\n",
            "Loss after mini-batch   400: 0.00628659\n",
            "Epoch  320 Total Loss  0.06988369568803712\n",
            "Epoch  320 Loss 1  0.006800215584179119\n",
            "Epoch  320 Loss 2 0.06308347977342692\n",
            "Starting epoch 321\n",
            "Loss after mini-batch    50: 0.01947572\n",
            "Loss after mini-batch   100: 0.03447542\n",
            "Loss after mini-batch   150: 0.41839213\n",
            "Loss after mini-batch   200: 0.06971530\n",
            "Loss after mini-batch   250: 2.96852267\n",
            "Loss after mini-batch   300: 0.02540849\n",
            "Loss after mini-batch   350: 0.03107644\n",
            "Loss after mini-batch   400: 0.05481963\n",
            "Epoch  321 Total Loss  0.4177971454098387\n",
            "Epoch  321 Loss 1  0.009504665714560141\n",
            "Epoch  321 Loss 2 0.408292493986894\n",
            "Starting epoch 322\n",
            "Loss after mini-batch    50: 0.03567403\n",
            "Loss after mini-batch   100: 8.91276884\n",
            "Loss after mini-batch   150: 44.93607132\n",
            "Loss after mini-batch   200: 0.41016467\n",
            "Loss after mini-batch   250: 0.39285932\n",
            "Loss after mini-batch   300: 0.07695581\n",
            "Loss after mini-batch   350: 0.15307529\n",
            "Loss after mini-batch   400: 0.40075536\n",
            "Epoch  322 Total Loss  6.413224989060588\n",
            "Epoch  322 Loss 1  0.010938597090624945\n",
            "Epoch  322 Loss 2 6.402286593323006\n",
            "Starting epoch 323\n",
            "Loss after mini-batch    50: 2.09267912\n",
            "Loss after mini-batch   100: 1.01700403\n",
            "Loss after mini-batch   150: 10.02787064\n",
            "Loss after mini-batch   200: 0.03339808\n",
            "Loss after mini-batch   250: 0.51576659\n",
            "Loss after mini-batch   300: 2.58281542\n",
            "Loss after mini-batch   350: 0.11084131\n",
            "Loss after mini-batch   400: 0.21824130\n",
            "Epoch  323 Total Loss  1.925952100155115\n",
            "Epoch  323 Loss 1  0.010771547115734716\n",
            "Epoch  323 Loss 2 1.915180537801108\n",
            "Starting epoch 324\n",
            "Loss after mini-batch    50: 0.80153982\n",
            "Loss after mini-batch   100: 0.40561330\n",
            "Loss after mini-batch   150: 3.52991740\n",
            "Loss after mini-batch   200: 0.11732156\n",
            "Loss after mini-batch   250: 0.06197369\n",
            "Loss after mini-batch   300: 0.02742239\n",
            "Loss after mini-batch   350: 0.04038578\n",
            "Loss after mini-batch   400: 0.07230755\n",
            "Epoch  324 Total Loss  0.5933806039366855\n",
            "Epoch  324 Loss 1  0.00789435315762122\n",
            "Epoch  324 Loss 2 0.585486237760822\n",
            "Starting epoch 325\n",
            "Loss after mini-batch    50: 0.41122970\n",
            "Loss after mini-batch   100: 0.17577838\n",
            "Loss after mini-batch   150: 1.65163862\n",
            "Loss after mini-batch   200: 0.04567981\n",
            "Loss after mini-batch   250: 0.17078762\n",
            "Loss after mini-batch   300: 0.01451152\n",
            "Loss after mini-batch   350: 0.03224377\n",
            "Loss after mini-batch   400: 0.09128335\n",
            "Epoch  325 Total Loss  0.3041479827638283\n",
            "Epoch  325 Loss 1  0.008095056906522482\n",
            "Epoch  325 Loss 2 0.29605293363540147\n",
            "Starting epoch 326\n",
            "Loss after mini-batch    50: 0.26997890\n",
            "Loss after mini-batch   100: 0.11590710\n",
            "Loss after mini-batch   150: 0.79090794\n",
            "Loss after mini-batch   200: 0.09200078\n",
            "Loss after mini-batch   250: 0.04045651\n",
            "Loss after mini-batch   300: 0.02211644\n",
            "Loss after mini-batch   350: 0.03073174\n",
            "Loss after mini-batch   400: 0.04565097\n",
            "Epoch  326 Total Loss  0.16989280085496528\n",
            "Epoch  326 Loss 1  0.00786070113611239\n",
            "Epoch  326 Loss 2 0.16203210166960602\n",
            "Starting epoch 327\n",
            "Loss after mini-batch    50: 0.24261065\n",
            "Loss after mini-batch   100: 0.07671242\n",
            "Loss after mini-batch   150: 0.66816301\n",
            "Loss after mini-batch   200: 0.04803470\n",
            "Loss after mini-batch   250: 0.16691746\n",
            "Loss after mini-batch   300: 0.01368405\n",
            "Loss after mini-batch   350: 0.03058971\n",
            "Loss after mini-batch   400: 0.08340652\n",
            "Epoch  327 Total Loss  0.1580067617028561\n",
            "Epoch  327 Loss 1  0.007679446375107222\n",
            "Epoch  327 Loss 2 0.15032731436901867\n",
            "Starting epoch 328\n",
            "Loss after mini-batch    50: 0.20704272\n",
            "Loss after mini-batch   100: 0.13651852\n",
            "Loss after mini-batch   150: 0.35267941\n",
            "Loss after mini-batch   200: 0.10224062\n",
            "Loss after mini-batch   250: 0.04682215\n",
            "Loss after mini-batch   300: 0.02730761\n",
            "Loss after mini-batch   350: 0.03170948\n",
            "Loss after mini-batch   400: 0.04795421\n",
            "Epoch  328 Total Loss  0.11731638961753289\n",
            "Epoch  328 Loss 1  0.009274822844064596\n",
            "Epoch  328 Loss 2 0.10804156556749903\n",
            "Starting epoch 329\n",
            "Loss after mini-batch    50: 0.24523570\n",
            "Loss after mini-batch   100: 0.03881841\n",
            "Loss after mini-batch   150: 0.28752221\n",
            "Loss after mini-batch   200: 0.04379697\n",
            "Loss after mini-batch   250: 0.14572579\n",
            "Loss after mini-batch   300: 0.01561474\n",
            "Loss after mini-batch   350: 0.02513733\n",
            "Loss after mini-batch   400: 0.06196139\n",
            "Epoch  329 Total Loss  0.1024931775372383\n",
            "Epoch  329 Loss 1  0.009290832876603804\n",
            "Epoch  329 Loss 2 0.09320234581184131\n",
            "Starting epoch 330\n",
            "Loss after mini-batch    50: 0.11777429\n",
            "Loss after mini-batch   100: 0.02702193\n",
            "Loss after mini-batch   150: 0.06105190\n",
            "Loss after mini-batch   200: 0.05854862\n",
            "Loss after mini-batch   250: 0.01887264\n",
            "Loss after mini-batch   300: 0.01667853\n",
            "Loss after mini-batch   350: 0.01921732\n",
            "Loss after mini-batch   400: 0.01630358\n",
            "Epoch  330 Total Loss  0.04188526209472911\n",
            "Epoch  330 Loss 1  0.007736975806929176\n",
            "Epoch  330 Loss 2 0.034148286294209684\n",
            "Starting epoch 331\n",
            "Loss after mini-batch    50: 0.07267249\n",
            "Loss after mini-batch   100: 0.02960745\n",
            "Loss after mini-batch   150: 0.06668795\n",
            "Loss after mini-batch   200: 0.02268733\n",
            "Loss after mini-batch   250: 0.06391288\n",
            "Loss after mini-batch   300: 0.01796664\n",
            "Loss after mini-batch   350: 0.01369532\n",
            "Loss after mini-batch   400: 0.01630390\n",
            "Epoch  331 Total Loss  0.035635224482661446\n",
            "Epoch  331 Loss 1  0.009494035165146764\n",
            "Epoch  331 Loss 2 0.026141189332077243\n",
            "Starting epoch 332\n",
            "Loss after mini-batch    50: 0.02978774\n",
            "Loss after mini-batch   100: 0.01245369\n",
            "Loss after mini-batch   150: 0.02759755\n",
            "Loss after mini-batch   200: 0.02261992\n",
            "Loss after mini-batch   250: 0.02941349\n",
            "Loss after mini-batch   300: 0.01236042\n",
            "Loss after mini-batch   350: 0.01243919\n",
            "Loss after mini-batch   400: 0.00653589\n",
            "Epoch  332 Total Loss  0.018498320124565686\n",
            "Epoch  332 Loss 1  0.00808572341833831\n",
            "Epoch  332 Loss 2 0.01041259674468426\n",
            "Starting epoch 333\n",
            "Loss after mini-batch    50: 0.02378442\n",
            "Loss after mini-batch   100: 0.01216390\n",
            "Loss after mini-batch   150: 0.03305375\n",
            "Loss after mini-batch   200: 0.02054730\n",
            "Loss after mini-batch   250: 0.03337815\n",
            "Loss after mini-batch   300: 0.01181703\n",
            "Loss after mini-batch   350: 0.01241310\n",
            "Loss after mini-batch   400: 0.00721456\n",
            "Epoch  333 Total Loss  0.018562671745417775\n",
            "Epoch  333 Loss 1  0.007374003778403122\n",
            "Epoch  333 Loss 2 0.011188668097786854\n",
            "Starting epoch 334\n",
            "Loss after mini-batch    50: 0.02248032\n",
            "Loss after mini-batch   100: 0.01242364\n",
            "Loss after mini-batch   150: 0.03258477\n",
            "Loss after mini-batch   200: 0.02076601\n",
            "Loss after mini-batch   250: 0.03182571\n",
            "Loss after mini-batch   300: 0.01190124\n",
            "Loss after mini-batch   350: 0.01235956\n",
            "Loss after mini-batch   400: 0.00676450\n",
            "Epoch  334 Total Loss  0.018258733281865048\n",
            "Epoch  334 Loss 1  0.00715733511045899\n",
            "Epoch  334 Loss 2 0.011101398114723871\n",
            "Starting epoch 335\n",
            "Loss after mini-batch    50: 0.02318828\n",
            "Loss after mini-batch   100: 0.04617898\n",
            "Loss after mini-batch   150: 0.01944005\n",
            "Loss after mini-batch   200: 0.03631631\n",
            "Loss after mini-batch   250: 0.02266223\n",
            "Loss after mini-batch   300: 0.02085407\n",
            "Loss after mini-batch   350: 0.01392664\n",
            "Loss after mini-batch   400: 0.00753065\n",
            "Epoch  335 Total Loss  0.023176867016345255\n",
            "Epoch  335 Loss 1  0.009510078655307291\n",
            "Epoch  335 Loss 2 0.013666788289739737\n",
            "Starting epoch 336\n",
            "Loss after mini-batch    50: 0.02831758\n",
            "Loss after mini-batch   100: 0.01361112\n",
            "Loss after mini-batch   150: 0.02435725\n",
            "Loss after mini-batch   200: 0.02525696\n",
            "Loss after mini-batch   250: 0.02432358\n",
            "Loss after mini-batch   300: 0.01284829\n",
            "Loss after mini-batch   350: 0.01278967\n",
            "Loss after mini-batch   400: 0.00557403\n",
            "Epoch  336 Total Loss  0.017956038256277514\n",
            "Epoch  336 Loss 1  0.007361169783338294\n",
            "Epoch  336 Loss 2 0.01059486850120816\n",
            "Starting epoch 337\n",
            "Loss after mini-batch    50: 0.02411248\n",
            "Loss after mini-batch   100: 0.01508129\n",
            "Loss after mini-batch   150: 0.01548318\n",
            "Loss after mini-batch   200: 0.03597328\n",
            "Loss after mini-batch   250: 0.01904961\n",
            "Loss after mini-batch   300: 0.01338379\n",
            "Loss after mini-batch   350: 0.01352837\n",
            "Loss after mini-batch   400: 0.00588783\n",
            "Epoch  337 Total Loss  0.0174617620377705\n",
            "Epoch  337 Loss 1  0.0070746288124683325\n",
            "Epoch  337 Loss 2 0.010387133295481457\n",
            "Starting epoch 338\n",
            "Loss after mini-batch    50: 0.02293258\n",
            "Loss after mini-batch   100: 0.01784840\n",
            "Loss after mini-batch   150: 0.01336273\n",
            "Loss after mini-batch   200: 0.05442499\n",
            "Loss after mini-batch   250: 0.07590018\n",
            "Loss after mini-batch   300: 0.01694543\n",
            "Loss after mini-batch   350: 0.01418407\n",
            "Loss after mini-batch   400: 0.00754542\n",
            "Epoch  338 Total Loss  0.026836118274087342\n",
            "Epoch  338 Loss 1  0.008003743569351246\n",
            "Epoch  338 Loss 2 0.01883237469057478\n",
            "Starting epoch 339\n",
            "Loss after mini-batch    50: 0.02384668\n",
            "Loss after mini-batch   100: 0.02284040\n",
            "Loss after mini-batch   150: 0.01608414\n",
            "Loss after mini-batch   200: 0.05990728\n",
            "Loss after mini-batch   250: 0.01600571\n",
            "Loss after mini-batch   300: 0.01440630\n",
            "Loss after mini-batch   350: 0.01483395\n",
            "Loss after mini-batch   400: 0.00698101\n",
            "Epoch  339 Total Loss  0.021170559210716828\n",
            "Epoch  339 Loss 1  0.00793896747114747\n",
            "Epoch  339 Loss 2 0.013231591637828296\n",
            "Starting epoch 340\n",
            "Loss after mini-batch    50: 0.02163483\n",
            "Loss after mini-batch   100: 0.02861405\n",
            "Loss after mini-batch   150: 0.04621118\n",
            "Loss after mini-batch   200: 0.02387838\n",
            "Loss after mini-batch   250: 0.03031642\n",
            "Loss after mini-batch   300: 0.01417493\n",
            "Loss after mini-batch   350: 0.01484490\n",
            "Loss after mini-batch   400: 0.00672914\n",
            "Epoch  340 Total Loss  0.0224372069481506\n",
            "Epoch  340 Loss 1  0.007766172158412753\n",
            "Epoch  340 Loss 2 0.01467103479063237\n",
            "Starting epoch 341\n",
            "Loss after mini-batch    50: 0.01942905\n",
            "Loss after mini-batch   100: 0.04238727\n",
            "Loss after mini-batch   150: 0.41402468\n",
            "Loss after mini-batch   200: 0.07024227\n",
            "Loss after mini-batch   250: 0.07988328\n",
            "Loss after mini-batch   300: 0.01558561\n",
            "Loss after mini-batch   350: 0.01457345\n",
            "Loss after mini-batch   400: 0.00665355\n",
            "Epoch  341 Total Loss  0.07721876437332877\n",
            "Epoch  341 Loss 1  0.008505743879178572\n",
            "Epoch  341 Loss 2 0.06871302022411338\n",
            "Starting epoch 342\n",
            "Loss after mini-batch    50: 0.02187223\n",
            "Loss after mini-batch   100: 0.03487850\n",
            "Loss after mini-batch   150: 0.42979712\n",
            "Loss after mini-batch   200: 0.07551723\n",
            "Loss after mini-batch   250: 0.08348532\n",
            "Loss after mini-batch   300: 0.01349221\n",
            "Loss after mini-batch   350: 0.01420262\n",
            "Loss after mini-batch   400: 0.00608742\n",
            "Epoch  342 Total Loss  0.07908462131745182\n",
            "Epoch  342 Loss 1  0.007871451952873365\n",
            "Epoch  342 Loss 2 0.0712131694601931\n",
            "Starting epoch 343\n",
            "Loss after mini-batch    50: 0.02036875\n",
            "Loss after mini-batch   100: 0.03385507\n",
            "Loss after mini-batch   150: 0.35650946\n",
            "Loss after mini-batch   200: 0.05659170\n",
            "Loss after mini-batch   250: 0.07125485\n",
            "Loss after mini-batch   300: 0.01382141\n",
            "Loss after mini-batch   350: 0.01427494\n",
            "Loss after mini-batch   400: 0.00577217\n",
            "Epoch  343 Total Loss  0.0667318978099669\n",
            "Epoch  343 Loss 1  0.007382594912122914\n",
            "Epoch  343 Loss 2 0.059349302810557024\n",
            "Starting epoch 344\n",
            "Loss after mini-batch    50: 0.14113835\n",
            "Loss after mini-batch   100: 0.05303340\n",
            "Loss after mini-batch   150: 0.02707633\n",
            "Loss after mini-batch   200: 0.03529081\n",
            "Loss after mini-batch   250: 0.03141672\n",
            "Loss after mini-batch   300: 0.02363638\n",
            "Loss after mini-batch   350: 0.01574607\n",
            "Loss after mini-batch   400: 0.00770292\n",
            "Epoch  344 Total Loss  0.039661532173073055\n",
            "Epoch  344 Loss 1  0.009906730410173247\n",
            "Epoch  344 Loss 2 0.029754801683500896\n",
            "Starting epoch 345\n",
            "Loss after mini-batch    50: 0.03114929\n",
            "Loss after mini-batch   100: 0.04262596\n",
            "Loss after mini-batch   150: 0.98595203\n",
            "Loss after mini-batch   200: 0.34312144\n",
            "Loss after mini-batch   250: 0.33112188\n",
            "Loss after mini-batch   300: 0.01760472\n",
            "Loss after mini-batch   350: 0.01442874\n",
            "Loss after mini-batch   400: 0.01781651\n",
            "Epoch  345 Total Loss  0.20611025547893694\n",
            "Epoch  345 Loss 1  0.011500620893047618\n",
            "Epoch  345 Loss 2 0.19460963420642596\n",
            "Starting epoch 346\n",
            "Loss after mini-batch    50: 0.02449830\n",
            "Loss after mini-batch   100: 0.02240433\n",
            "Loss after mini-batch   150: 0.01525470\n",
            "Loss after mini-batch   200: 0.89510376\n",
            "Loss after mini-batch   250: 0.12027313\n",
            "Loss after mini-batch   300: 0.02280310\n",
            "Loss after mini-batch   350: 0.01296627\n",
            "Loss after mini-batch   400: 0.00775704\n",
            "Epoch  346 Total Loss  0.13012957588858814\n",
            "Epoch  346 Loss 1  0.010685872431809683\n",
            "Epoch  346 Loss 2 0.11944370296552051\n",
            "Starting epoch 347\n",
            "Loss after mini-batch    50: 34.41598218\n",
            "Loss after mini-batch   100: 5.00294950\n",
            "Loss after mini-batch   150: 4.00856901\n",
            "Loss after mini-batch   200: 1.05728766\n",
            "Loss after mini-batch   250: 1.09755549\n",
            "Loss after mini-batch   300: 0.13777389\n",
            "Loss after mini-batch   350: 0.31616734\n",
            "Loss after mini-batch   400: 0.85220129\n",
            "Epoch  347 Total Loss  5.478584622701618\n",
            "Epoch  347 Loss 1  0.010202873623799453\n",
            "Epoch  347 Loss 2 5.468381729224907\n",
            "Starting epoch 348\n",
            "Loss after mini-batch    50: 2.43180001\n",
            "Loss after mini-batch   100: 0.29724842\n",
            "Loss after mini-batch   150: 1.77399842\n",
            "Loss after mini-batch   200: 0.30482763\n",
            "Loss after mini-batch   250: 0.68569531\n",
            "Loss after mini-batch   300: 0.04661479\n",
            "Loss after mini-batch   350: 0.12107199\n",
            "Loss after mini-batch   400: 0.38524869\n",
            "Epoch  348 Total Loss  0.7224557199146785\n",
            "Epoch  348 Loss 1  0.012086096040374463\n",
            "Epoch  348 Loss 2 0.7103696406062174\n",
            "Starting epoch 349\n",
            "Loss after mini-batch    50: 0.85374312\n",
            "Loss after mini-batch   100: 0.11908202\n",
            "Loss after mini-batch   150: 0.47016074\n",
            "Loss after mini-batch   200: 0.21666121\n",
            "Loss after mini-batch   250: 0.13775446\n",
            "Loss after mini-batch   300: 0.04253394\n",
            "Loss after mini-batch   350: 0.05981230\n",
            "Loss after mini-batch   400: 0.12009791\n",
            "Epoch  349 Total Loss  0.24739666673605365\n",
            "Epoch  349 Loss 1  0.011392938898835832\n",
            "Epoch  349 Loss 2 0.23600372817838164\n",
            "Starting epoch 350\n",
            "Loss after mini-batch    50: 0.36905880\n",
            "Loss after mini-batch   100: 0.03571324\n",
            "Loss after mini-batch   150: 0.22841576\n",
            "Loss after mini-batch   200: 0.05213066\n",
            "Loss after mini-batch   250: 0.16377518\n",
            "Loss after mini-batch   300: 0.02119730\n",
            "Loss after mini-batch   350: 0.02541913\n",
            "Loss after mini-batch   400: 0.06288173\n",
            "Epoch  350 Total Loss  0.11318257796642003\n",
            "Epoch  350 Loss 1  0.011748725818483501\n",
            "Epoch  350 Loss 2 0.1014338525153479\n",
            "Starting epoch 351\n",
            "Loss after mini-batch    50: 0.09623975\n",
            "Loss after mini-batch   100: 0.01574636\n",
            "Loss after mini-batch   150: 0.02190433\n",
            "Loss after mini-batch   200: 0.03357799\n",
            "Loss after mini-batch   250: 0.02407313\n",
            "Loss after mini-batch   300: 0.02160307\n",
            "Loss after mini-batch   350: 0.01367521\n",
            "Loss after mini-batch   400: 0.00755081\n",
            "Epoch  351 Total Loss  0.02852069711312317\n",
            "Epoch  351 Loss 1  0.011590102138987946\n",
            "Epoch  351 Loss 2 0.016930594942389344\n",
            "Starting epoch 352\n",
            "Loss after mini-batch    50: 0.04148126\n",
            "Loss after mini-batch   100: 0.01273492\n",
            "Loss after mini-batch   150: 0.03697046\n",
            "Loss after mini-batch   200: 0.02336512\n",
            "Loss after mini-batch   250: 0.04060927\n",
            "Loss after mini-batch   300: 0.02025579\n",
            "Loss after mini-batch   350: 0.01262653\n",
            "Loss after mini-batch   400: 0.00911997\n",
            "Epoch  352 Total Loss  0.023749528786243774\n",
            "Epoch  352 Loss 1  0.011599697218237755\n",
            "Epoch  352 Loss 2 0.012149831686444207\n",
            "Starting epoch 353\n",
            "Loss after mini-batch    50: 0.03483161\n",
            "Loss after mini-batch   100: 0.01311305\n",
            "Loss after mini-batch   150: 0.03598440\n",
            "Loss after mini-batch   200: 0.02374887\n",
            "Loss after mini-batch   250: 0.03896591\n",
            "Loss after mini-batch   300: 0.02045212\n",
            "Loss after mini-batch   350: 0.01266184\n",
            "Loss after mini-batch   400: 0.00839992\n",
            "Epoch  353 Total Loss  0.022782894112146325\n",
            "Epoch  353 Loss 1  0.011603134541170826\n",
            "Epoch  353 Loss 2 0.011179759573819285\n",
            "Starting epoch 354\n",
            "Loss after mini-batch    50: 0.03548734\n",
            "Loss after mini-batch   100: 0.01354588\n",
            "Loss after mini-batch   150: 0.03394638\n",
            "Loss after mini-batch   200: 0.02460889\n",
            "Loss after mini-batch   250: 0.03637843\n",
            "Loss after mini-batch   300: 0.02074791\n",
            "Loss after mini-batch   350: 0.01281210\n",
            "Loss after mini-batch   400: 0.00776657\n",
            "Epoch  354 Total Loss  0.02253742681377321\n",
            "Epoch  354 Loss 1  0.011588432024358157\n",
            "Epoch  354 Loss 2 0.010948994765763184\n",
            "Starting epoch 355\n",
            "Loss after mini-batch    50: 0.03621416\n",
            "Loss after mini-batch   100: 0.01424964\n",
            "Loss after mini-batch   150: 0.02839440\n",
            "Loss after mini-batch   200: 0.02746218\n",
            "Loss after mini-batch   250: 0.03151541\n",
            "Loss after mini-batch   300: 0.02125987\n",
            "Loss after mini-batch   350: 0.01323542\n",
            "Loss after mini-batch   400: 0.00736630\n",
            "Epoch  355 Total Loss  0.021991166359916912\n",
            "Epoch  355 Loss 1  0.011564280769196286\n",
            "Epoch  355 Loss 2 0.010426885512083393\n",
            "Starting epoch 356\n",
            "Loss after mini-batch    50: 0.03681361\n",
            "Loss after mini-batch   100: 0.01550975\n",
            "Loss after mini-batch   150: 0.02006105\n",
            "Loss after mini-batch   200: 0.03563978\n",
            "Loss after mini-batch   250: 0.02568143\n",
            "Loss after mini-batch   300: 0.02199017\n",
            "Loss after mini-batch   350: 0.01403124\n",
            "Loss after mini-batch   400: 0.00754423\n",
            "Epoch  356 Total Loss  0.021774333532837396\n",
            "Epoch  356 Loss 1  0.011530088083972437\n",
            "Epoch  356 Loss 2 0.010244245442268799\n",
            "Starting epoch 357\n",
            "Loss after mini-batch    50: 0.03672459\n",
            "Loss after mini-batch   100: 0.01794837\n",
            "Loss after mini-batch   150: 0.01591971\n",
            "Loss after mini-batch   200: 0.05304988\n",
            "Loss after mini-batch   250: 0.02192183\n",
            "Loss after mini-batch   300: 0.02269402\n",
            "Loss after mini-batch   350: 0.01488475\n",
            "Loss after mini-batch   400: 0.00800118\n",
            "Epoch  357 Total Loss  0.0233475235236632\n",
            "Epoch  357 Loss 1  0.011493477022664048\n",
            "Epoch  357 Loss 2 0.01185404660598264\n",
            "Starting epoch 358\n",
            "Loss after mini-batch    50: 0.03570231\n",
            "Loss after mini-batch   100: 0.02220938\n",
            "Loss after mini-batch   150: 0.01792917\n",
            "Loss after mini-batch   200: 0.06346036\n",
            "Loss after mini-batch   250: 0.02176149\n",
            "Loss after mini-batch   300: 0.02287949\n",
            "Loss after mini-batch   350: 0.01503994\n",
            "Loss after mini-batch   400: 0.00789790\n",
            "Epoch  358 Total Loss  0.02507661859103112\n",
            "Epoch  358 Loss 1  0.01148384704271963\n",
            "Epoch  358 Loss 2 0.013592771423822293\n",
            "Starting epoch 359\n",
            "Loss after mini-batch    50: 0.03425616\n",
            "Loss after mini-batch   100: 0.02802953\n",
            "Loss after mini-batch   150: 0.02468317\n",
            "Loss after mini-batch   200: 0.03392584\n",
            "Loss after mini-batch   250: 0.03012698\n",
            "Loss after mini-batch   300: 0.02288205\n",
            "Loss after mini-batch   350: 0.01493885\n",
            "Loss after mini-batch   400: 0.00762335\n",
            "Epoch  359 Total Loss  0.023810560914290395\n",
            "Epoch  359 Loss 1  0.011540978098985332\n",
            "Epoch  359 Loss 2 0.012269582764573883\n",
            "Starting epoch 360\n",
            "Loss after mini-batch    50: 0.03292686\n",
            "Loss after mini-batch   100: 0.03470690\n",
            "Loss after mini-batch   150: 0.34650131\n",
            "Loss after mini-batch   200: 0.05621707\n",
            "Loss after mini-batch   250: 0.07426449\n",
            "Loss after mini-batch   300: 0.02276915\n",
            "Loss after mini-batch   350: 0.01479945\n",
            "Loss after mini-batch   400: 0.00753728\n",
            "Epoch  360 Total Loss  0.06900558333059315\n",
            "Epoch  360 Loss 1  0.01171529188737288\n",
            "Epoch  360 Loss 2 0.05729029160568839\n",
            "Starting epoch 361\n",
            "Loss after mini-batch    50: 0.03274252\n",
            "Loss after mini-batch   100: 0.03589924\n",
            "Loss after mini-batch   150: 0.46316393\n",
            "Loss after mini-batch   200: 0.08631864\n",
            "Loss after mini-batch   250: 0.09489014\n",
            "Loss after mini-batch   300: 0.02234380\n",
            "Loss after mini-batch   350: 0.01430758\n",
            "Loss after mini-batch   400: 0.00741085\n",
            "Epoch  361 Total Loss  0.0882627097094569\n",
            "Epoch  361 Loss 1  0.011762600948111804\n",
            "Epoch  361 Loss 2 0.07650010894931816\n",
            "Starting epoch 362\n",
            "Loss after mini-batch    50: 0.03304514\n",
            "Loss after mini-batch   100: 0.03445057\n",
            "Loss after mini-batch   150: 0.31998762\n",
            "Loss after mini-batch   200: 0.05051975\n",
            "Loss after mini-batch   250: 0.07032806\n",
            "Loss after mini-batch   300: 0.02287672\n",
            "Loss after mini-batch   350: 0.01488495\n",
            "Loss after mini-batch   400: 0.00756241\n",
            "Epoch  362 Total Loss  0.06485588982664169\n",
            "Epoch  362 Loss 1  0.011708495078706076\n",
            "Epoch  362 Loss 2 0.05314739451458878\n",
            "Starting epoch 363\n",
            "Loss after mini-batch    50: 0.03269063\n",
            "Loss after mini-batch   100: 0.03617211\n",
            "Loss after mini-batch   150: 0.49102360\n",
            "Loss after mini-batch   200: 0.09474152\n",
            "Loss after mini-batch   250: 0.10077787\n",
            "Loss after mini-batch   300: 0.02221799\n",
            "Loss after mini-batch   350: 0.01416579\n",
            "Loss after mini-batch   400: 0.00738435\n",
            "Epoch  363 Total Loss  0.09310687012122756\n",
            "Epoch  363 Loss 1  0.011774250874884597\n",
            "Epoch  363 Loss 2 0.0813326187520674\n",
            "Starting epoch 364\n",
            "Loss after mini-batch    50: 0.03313380\n",
            "Loss after mini-batch   100: 0.03405108\n",
            "Loss after mini-batch   150: 0.28375713\n"
          ]
        }
      ],
      "source": [
        "x_data_plot=[]\n",
        "y_data_all_plot=[]\n",
        "y_data_1_plot=[]\n",
        "y_data_2_plot=[]\n",
        "\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "Epochs = 500\n",
        "for epoch in range(Epochs):\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch}')\n",
        "    \n",
        "    # Set current and total loss value\n",
        "    current_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "    total_loss1 = 0.0\n",
        "    total_loss2 = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader,0):\n",
        "\n",
        "        x_batch, y_batch, delta_t = data\n",
        "\n",
        "        # Ground-truth temperature\n",
        "        true_temp = x_batch[:,4]\n",
        "\n",
        "        # Predicted temperature using model prediction and forward euler method\n",
        "        pred_temp = true_temp.detach().clone().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(x_batch.to(device)) #GPU\n",
        "        deltaTemp = prediction.reshape(-1)*delta_t.reshape(-1)/normalize\n",
        "        temp0 = pred_temp + deltaTemp\n",
        "        pred_temp[1:] = temp0[:-1]\n",
        " \n",
        "        loss1 = criterion(prediction,y_batch.to(device))\n",
        "        loss2 = criterion(pred_temp.to(device),true_temp.to(device))\n",
        "        loss = loss1+loss2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        current_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        total_loss1 += loss1.item()\n",
        "        total_loss2 += loss2.item()\n",
        "\n",
        "        if i % 50 == 49:\n",
        "            print('Loss after mini-batch %5d: %.8f' %\n",
        "                  (i + 1, current_loss / 50))\n",
        "            current_loss = 0.0\n",
        "\n",
        "    print(\"Epoch \", epoch, \"Total Loss \", total_loss/(i+1))\n",
        "    print(\"Epoch \", epoch, \"Loss 1 \", total_loss1/(i+1))\n",
        "    print(\"Epoch \", epoch, \"Loss 2\", total_loss2/(i+1))\n",
        "\n",
        "    x_data_plot.append(epoch)\n",
        "    y_data_all_plot.append(total_loss/(i+1))\n",
        "    y_data_1_plot.append(total_loss1/(i+1))\n",
        "    y_data_2_plot.append(total_loss2/(i+1))\n",
        "\n",
        "# Make the plot of Total Loss vs epochs\n",
        "plt.plot(x_data_plot,y_data_all_plot)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Total Loss')\n",
        "plt.show()\n",
        "\n",
        "# Make the plot of the supervised loss\n",
        "plt.plot(x_data_plot,y_data_1_plot)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss1')\n",
        "plt.show()\n",
        "\n",
        "# Make the plot of time stability loss\n",
        "plt.plot(x_data_plot,y_data_2_plot)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "loVO9lty_1mH",
        "outputId": "f6d3670b-7753-4cc9-8133-972cbce4f2b3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a6bb1b93a3ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot of last 100 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_data_all_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot of last 100 epochs\n",
        "plt.plot(x_data_plot[-200:],y_data_all_plot[-200:])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot of last 100 epochs\n",
        "plt.plot(x_data_plot[-200:],y_data_1_plot[-200:])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss 1')\n",
        "plt.show()\n",
        "\n",
        "# Plot of last 100 epochs\n",
        "plt.plot(x_data_plot[-200:],y_data_2_plot[-200:])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2CKaap0Aauy"
      },
      "outputs": [],
      "source": [
        "# Make a prediction\n",
        "pred = model(ds.x.float().to(device)) #GPU\n",
        "pred = pred.detach().cpu().numpy()/normalize\n",
        "\n",
        "# ground-truth\n",
        "df_y_tensor_np = ds.y.numpy()/normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP7kZ5jnjTTy"
      },
      "outputs": [],
      "source": [
        "# Some statistics on the model performance on all of dataset\n",
        "mae = np.sum(np.abs(pred- df_y_tensor_np).mean(axis=None))\n",
        "print('MAE:', mae)\n",
        "\n",
        "mse = ((df_y_tensor_np - pred)**2).mean(axis=None)\n",
        "print('MSE:', mse)\n",
        "\n",
        "rel_error = np.linalg.norm(pred - df_y_tensor_np) / np.linalg.norm(df_y_tensor_np)\n",
        "print('Relative error (%):', rel_error*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtDt8BXiDYrZ"
      },
      "outputs": [],
      "source": [
        "figure(figsize=(10, 8), dpi= 360)\n",
        "\n",
        "plt.plot(pred, '--')\n",
        "plt.plot(df_y_tensor_np, '-')\n",
        "plt.legend(['Prediction', 'ground-truth'])\n",
        "plt.xlabel('t-idx')\n",
        "plt.ylabel('Delta Temperature/delta time')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3ZQU5JyDrEq"
      },
      "outputs": [],
      "source": [
        "figure(figsize=(10, 8), dpi= 360)\n",
        "\n",
        "#time\n",
        "t=ds.t\n",
        "\n",
        "plt.plot(t,pred, '--')\n",
        "plt.plot(t,df_y_tensor_np, '-')\n",
        "plt.legend(['Prediction', 'ground-truth'])\n",
        "plt.xlabel('time / seconds')\n",
        "plt.ylabel('Delta Temperature/delta time')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_y38GoxFDeJ"
      },
      "outputs": [],
      "source": [
        "# Import a slice of the datase (based on drive-id) for further analysis\n",
        "ds = TeslaDatasetDiff(device = device, ID = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08d4xtKcGONJ"
      },
      "outputs": [],
      "source": [
        "#Forward Euler method with fixed initial conditions but with updated \n",
        "#Temperature from the prediction of the model at previous iteration\n",
        "#with generated temporally equidistant time steps\n",
        "\n",
        "# ground-truth time\n",
        "t=ds.t\n",
        "max_t = t.max()\n",
        "\n",
        "# Ground-truth temperature\n",
        "true_temp = ds.x[:,4].numpy()\n",
        "\n",
        "# Predicted temperature using model prediction and forward euler method\n",
        "pred_temp = np.zeros((ds.x.shape[0]))\n",
        "pred_temp = true_temp.copy()\n",
        "\n",
        "# Fixed initial conditions for all environmental conditions\n",
        "input = ds.x[0].detach().clone()\n",
        "\n",
        "# temporally equdistant time steps\n",
        "tt = np.linspace(0,max_t,ds.x.shape[0])\n",
        "step_size=tt[2]-tt[1]\n",
        "\n",
        "#ODE\n",
        "for i in range(0, ds.x.shape[0] - 1):\n",
        "      input[4] = torch.tensor(pred_temp[i]).detach().clone()\n",
        "      pred = model(input.to(device))\n",
        "      pred = pred.detach().cpu().numpy()/normalize\n",
        "      pred_temp[i + 1] = pred_temp[i] + pred*step_size\n",
        "\n",
        "\n",
        "#MAE\n",
        "mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
        "print('MAE:', mae)\n",
        "\n",
        "#MSE\n",
        "mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
        "print('MSE:', mse)\n",
        "\n",
        "#Relative error\n",
        "rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
        "print('Relative error (%):', rel_error*100)\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(tt, pred_temp, '-', label='ODE approximation')\n",
        "plt.plot(t, true_temp, '--', label='Exact')\n",
        "plt.title('Approximate and True Solution (temporally equidistant step size)')\n",
        "plt.xlabel('t (seconds)')\n",
        "plt.ylabel('Temperature')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx9KVaQyGSYb"
      },
      "outputs": [],
      "source": [
        "#Forward Euler method with fixed initial conditions but with updated \n",
        "#Temperature from the prediction of the model at previous iteration\n",
        "#with true step sizes\n",
        "\n",
        "# ground-truth time\n",
        "t=ds.t\n",
        "max_t = t.max()\n",
        "t=t.numpy()\n",
        "\n",
        "# Ground-truth temperature\n",
        "true_temp = ds.x[:,4].numpy()\n",
        "\n",
        "# Predicted temperature using model prediction and forward euler method\n",
        "#pred_temp = np.zeros((ds.x.shape[0]))\n",
        "pred_temp[0] = true_temp[0].copy()\n",
        "\n",
        "# Fixed initial conditions for all environmental conditions\n",
        "input = ds.x[0].detach().clone()\n",
        "\n",
        "# temporally equdistant time steps\n",
        "tt = np.linspace(0,max_t,ds.x.shape[0])\n",
        "step_size=tt[2]-tt[1]\n",
        "\n",
        "# ODE\n",
        "for i in range(0, ds.x.shape[0] - 1):\n",
        "      #input = df_xx_tensor[0]\n",
        "      input[4] = torch.tensor(pred_temp[i]).detach().clone()\n",
        "      pred = model(input.to(device))\n",
        "      pred = pred.detach().cpu().numpy()/normalize\n",
        "      pred_temp[i + 1] = pred_temp[i] + pred*(t[i+1]-t[i])\n",
        "      \n",
        "#MAE \n",
        "mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
        "print('MAE:', mae)\n",
        "\n",
        "#MSE\n",
        "mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
        "print('MSE:', mse)\n",
        "\n",
        "# Relative error\n",
        "rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
        "print('Relative error (%):', rel_error*100)\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(t, pred_temp, '-', label='ODE approximation')\n",
        "plt.plot(t, true_temp, '--', label='Exact')\n",
        "plt.title('Approximate and True Solution (true step size)')\n",
        "plt.xlabel('t (seconds)')\n",
        "plt.ylabel('Temperature')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFmgP4Qz6Gll"
      },
      "outputs": [],
      "source": [
        "#Forward Euler method with updated environmental conditions from the dataset at each iteration\n",
        "#But with updated temperature from the prediction of the model at previous iteration\n",
        "#with true step sizes\n",
        "\n",
        "# ground-truth time\n",
        "t=ds.t\n",
        "max_t = t.max()\n",
        "t=t.numpy()\n",
        "\n",
        "# Ground-truth temperature\n",
        "true_temp = ds.x[:,4].numpy()\n",
        "\n",
        "# Predicted temperature using model prediction and forward euler method\n",
        "pred_temp = np.zeros((ds.x.shape[0]))\n",
        "pred_temp[0] = true_temp[0].copy()\n",
        "\n",
        "\n",
        "for i in range(0, ds.x.shape[0] - 1):\n",
        "      input = ds.x[i].detach().clone()\n",
        "      input[4] = torch.tensor(pred_temp[i]).detach().clone()\n",
        "      pred = model(input.to(device))\n",
        "      pred = pred.detach().cpu().numpy()/normalize\n",
        "      pred_temp[i + 1] = pred_temp[i] + pred*(t[i+1]-t[i])\n",
        "\n",
        "#MAE \n",
        "mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
        "print('MAE:', mae)\n",
        "\n",
        "#MSE\n",
        "mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
        "print('MSE:', mse)\n",
        "\n",
        "# Relative error\n",
        "rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
        "print('Relative error (%):', rel_error*100)\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(t, pred_temp, '-', label='ODE approximation')\n",
        "plt.plot(t, true_temp, '--', label='Exact')\n",
        "plt.title('Approximate and True Solution (true step size)')\n",
        "plt.xlabel('t (seconds)')\n",
        "plt.ylabel('Temperature')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2ppJIkXGVM7"
      },
      "outputs": [],
      "source": [
        "plt.plot(tt, '-', label='my step size')\n",
        "plt.plot(t, '--', label='true step-size')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yuf54BmGW-P"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.diff(t.reshape(-1)))\n",
        "plt.plot(np.diff(tt.reshape(-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK2F9VaIkRUj"
      },
      "outputs": [],
      "source": [
        "# Checking if vectorised version of the loss works\n",
        "\n",
        "true_temp = ds.x[:,4].numpy()\n",
        "pred_temp = true_temp.copy()\n",
        "\n",
        "prediction = model(ds.x.to(device)) \n",
        "\n",
        "deltaTemp = prediction.reshape(-1)*ds.dt.reshape(-1)/normalize\n",
        "\n",
        "temp0 = pred_temp + deltaTemp.detach().cpu().numpy()\n",
        "pred_temp[1:] = temp0[:-1]\n",
        "\n",
        "#MAE\n",
        "mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
        "print('MAE:', mae)\n",
        "\n",
        "#MSE\n",
        "mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
        "print('MSE:', mse)\n",
        "\n",
        "#Relative error\n",
        "rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
        "print('Relative error (%):', rel_error*100)\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(t, pred_temp, '-', label='ODE approximation')\n",
        "plt.plot(t, true_temp, '--', label='Exact')\n",
        "plt.title('Approximate and True Solution (true step size)')\n",
        "plt.xlabel('t (seconds)')\n",
        "plt.ylabel('Temperature')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Vectorised time stability of 1D_Heat_Eqn_Diff_Operator v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
