{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cSPnqZisanby"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"FrEIA\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a1eVVkYZu6Qu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.pyplot import figure\n",
        "from torch.utils.data import DataLoader\n",
        "import plain_inn_swap\n",
        "from tesladata import TeslaDataset\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb\n",
        "import pprint\n",
        "import math\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpY1sHVuanbz"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "IYGpi3qGanb2",
        "outputId": "e4d0998b-9a8c-4a46-e7c1-ece41ec9b786"
      },
      "outputs": [],
      "source": [
        "wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'Loss',\n",
        "    'goal': 'minimize'  \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'lambd_predict_back': {\n",
        "                # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'lambd_latent': {\n",
        "                # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'lambd_rev': {\n",
        "        # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(1),\n",
        "        'max': math.log(1024),\n",
        "        },\n",
        "    'epochs': {\n",
        "          'value': 1\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4KwIDXpanb5",
        "outputId": "3af564cd-26ff-46eb-9379-313aed56f164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'Loss'},\n",
            " 'parameters': {'epochs': {'value': 1},\n",
            "                'lambd_latent': {'distribution': 'q_log_uniform',\n",
            "                                 'max': 6.931471805599453,\n",
            "                                 'min': 0.0,\n",
            "                                 'q': 1},\n",
            "                'lambd_predict_back': {'distribution': 'q_log_uniform',\n",
            "                                       'max': 6.931471805599453,\n",
            "                                       'min': 0.0,\n",
            "                                       'q': 1},\n",
            "                'lambd_rev': {'distribution': 'q_log_uniform',\n",
            "                              'max': 6.931471805599453,\n",
            "                              'min': 0.0,\n",
            "                              'q': 1}}}\n",
            "Create sweep with ID: 7uoav28h\n",
            "Sweep URL: https://wandb.ai/jeyhun/INN%20optimization/sweeps/7uoav28h\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(sweep_config)\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"INN optimization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXK_PVgZanb7"
      },
      "source": [
        "### Training\n",
        "The following cell basically trains an Invertible Neural Network as of (Ardizzone, 2018) without padding: `[y,z] <=> x` with `x` = parameters, `y` = temperature readings and `z` our latent variable (iid. Gaussian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-LMS92itanb8"
      },
      "outputs": [],
      "source": [
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        batch_size = 2048\n",
        "        lr = 1e-3\n",
        "        #device = \"cuda:0\"\n",
        "        # Use cuda if it is available, else use the cpu\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        num_features = 100\n",
        "        num_blocks = 5\n",
        "\n",
        "        ds = TeslaDataset()\n",
        "        train_dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "        # get one sample of our dataset to infer its input and output dimension\n",
        "        x,y = ds.__getitem__(0)\n",
        "        dim_inp = x.shape[0]\n",
        "        dim_outp = 1\n",
        "         \n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        \n",
        "        #print('config.batch_size',config.batch_size)\n",
        "        my_inn = plain_inn_swap.INN(ndim_tot = dim_inp, ndim_y = dim_outp, ndim_x = dim_inp, ndim_z=dim_inp-dim_outp, \n",
        "            device = device,\n",
        "             lambd_predict_back = config.lambd_predict_back, lambd_latent = config.lambd_latent, lambd_rev = config.lambd_rev,\n",
        "             feature = num_features, num_blocks = num_blocks, batch_size = batch_size, lr = lr)\n",
        "\n",
        "        #begin = time.time()\n",
        "        my_inn.train(config.epochs, train_loader=train_dataloader, val_loader=train_dataloader, log_writer = ['wb', wandb])\n",
        "        #end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "palda30hanb9"
      },
      "outputs": [],
      "source": [
        "#print(\"time adaptive:\", end - begin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruD2gSAoanb_",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, train, count=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAoCMPX8ancB"
      },
      "source": [
        "### Analysis of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRCziZscCyHD"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(train_dataloader))\n",
        "\n",
        "# Make a prediction\n",
        "pred,_ = my_inn.model(x)\n",
        "pred = pred.detach().cpu().numpy()[:,0] # take temperature components, the other three elements are z\n",
        "\n",
        "y = y.cpu().numpy()\n",
        "#print(np.concatenate([df_y_tensor_np, pred],axis = 1))\n",
        "print('relative l2 norm: ', np.linalg.norm(y-pred) / np.linalg.norm(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDEZrI1-GW9k"
      },
      "outputs": [],
      "source": [
        "figure(figsize=(10, 8), dpi= 1440)\n",
        "\n",
        "plt.plot(pred, '--')\n",
        "plt.plot(y, '-')\n",
        "plt.legend(['Prediction', 'ground-truth'])\n",
        "plt.ylabel('Temperature / Â°C')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of 1D_Heat_Equation_INN-WANDB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
