{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XqFaBeDXyHq",
    "outputId": "640f796d-576e-4588-f1af-8f7c8e3394fe"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, ones, stack, load\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import time\n",
    "from tesladatano import TeslaDatasetNo\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Import PINNFramework etc.\n",
    "# https://github.com/ComputationalRadiationPhysics/NeuralSolvers.git\n",
    "# sys.path.append(\"...\")# PINNFramework etc.\n",
    "# sys.path.append(\"/home/hoffmnic/Code/NeuralSolvers\")\n",
    "sys.path.append(\"NeuralSolvers\")  \n",
    "import PINNFramework as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWHGXtmGxoEU"
   },
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEqKEcG8YMpg",
    "outputId": "a3107294-aca3-4cc8-aac5-34b5dbe9619b"
   },
   "outputs": [],
   "source": [
    "# Use cuda if it is available, else use the cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZXZ9Td7bX8x",
    "outputId": "4a0593e9-dc39-4fa8-fc9e-528b35158288"
   },
   "outputs": [],
   "source": [
    "# login wandb (optional)\n",
    "wandb.login()\n",
    "\n",
    "# Initialize WandB (optional)\n",
    "wandb.init(name='NO_reg_v7', \n",
    "           project='Neural_Operator_project',\n",
    "           notes='squared sum of gradients', \n",
    "           #tags=['...'],\n",
    "           #entity='...'\n",
    "           )\n",
    "\n",
    "\n",
    "# WandB Configurations (optional)\n",
    "wandb.config.normalize = 1000  \n",
    "wandb.config.batch_size= 4096   \n",
    "wandb.config.lr = 1e-4\n",
    "wandb.config.alpha = 100000\n",
    "\n",
    "\n",
    "\n",
    "# Create instance of the dataset\n",
    "ds = TeslaDatasetNo(diff = \"fwd_diff\", device = device, data ='train', normalize = wandb.config.normalize, rel_time = True)\n",
    "ds_test = TeslaDatasetNo(device = device, ID = -1, data = \"test\",normalize = wandb.config.normalize, rel_time = True)\n",
    "\n",
    "\n",
    "wandb.config.input_size = 6\n",
    "wandb.config.output_size = 1\n",
    "wandb.config.hidden_size = 100\n",
    "wandb.config.num_hidden = 4\n",
    "wandb.config.lb = ds.lb\n",
    "wandb.config.ub = ds.ub\n",
    "\n",
    "# trainloader\n",
    "train_loader = DataLoader(ds, batch_size=wandb.config.batch_size,shuffle=True)\n",
    "validloader = DataLoader(ds_test, batch_size=wandb.config.batch_size,shuffle=True)\n",
    "\n",
    "model = pf.models.MLP(input_size=wandb.config.input_size,\n",
    "                      output_size=wandb.config.output_size, \n",
    "                      hidden_size=wandb.config.hidden_size, \n",
    "                      num_hidden=wandb.config.num_hidden, \n",
    "                      lb=wandb.config.lb, \n",
    "                      ub=wandb.config.ub,\n",
    "                      #activation = torch.relu\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "# model = pf.models.MLP(input_size=6,\n",
    "#                       output_size=1, \n",
    "#                       hidden_size=100, \n",
    "#                       num_hidden=4, \n",
    "#                       lb=ds.lb, \n",
    "#                       ub=ds.ub,\n",
    "#                       #activation = torch.relu\n",
    "#                       )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=wandb.config.lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Log the network weight histograms (optional)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x, u):\n",
    "\n",
    "    grads = ones(u.shape, device=u.device) # move to the same device as prediction\n",
    "    grad_u = grad(u, x, create_graph=True, grad_outputs=grads )[0]\n",
    "   \n",
    "    # calculate first order derivatives\n",
    "    #u_t = grad_u[:, 4]\n",
    "    #u_t = u_t.reshape(-1, 1)\n",
    "    \n",
    "    #u_t = torch.sum(grad_u, 1).reshape(-1, 1)\n",
    "    \n",
    "    return grad_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk8L53ZG1YTF"
   },
   "source": [
    "## Function for saving a checkpoint during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXZeiNIRoK2K"
   },
   "outputs": [],
   "source": [
    "def write_checkpoint(checkpoint_path, epoch, min_mlp_loss, optimizer):\n",
    "    checkpoint = {}\n",
    "    checkpoint[\"epoch\"] = epoch\n",
    "    checkpoint[\"minimum_pinn_loss\"] = min_mlp_loss\n",
    "    checkpoint[\"optimizer\"] = optimizer.state_dict()\n",
    "    checkpoint[\"mlp_model\"] = model.state_dict()\n",
    "    torch.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjP8nSCE1gs7"
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p01JZkSBvB4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "min_mlp_loss = np.inf\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "x_data_plot=[]\n",
    "y_data_all_plot=[]\n",
    "y_data_1_plot=[]\n",
    "y_data_2_plot=[]\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "begin = time.time()\n",
    "for epoch in range(epochs):\n",
    "# with trange(epochs, unit=\"epochs\") as pbar:\n",
    "#     for epoch in pbar:\n",
    "        # Set current and total loss value\n",
    "        current_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        total_loss1 = 0.0\n",
    "        total_loss2 = 0.0\n",
    "\n",
    "        model.train()   # Optional when not using Model Specific layer\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            #print(i)\n",
    "            x_batch, y_batch = data\n",
    "            #print('data', x_batch.shape)\n",
    "            if wandb.config.batch_size == 1:\n",
    "                x_batch=torch.squeeze(x_batch)\n",
    "                y_batch=torch.squeeze(y_batch)\n",
    "              #delta_t=torch.squeeze(delta_t)\n",
    "\n",
    "            # Ground-truth temperature\n",
    "            true_temp = x_batch[:,4].detach().clone()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x_batch.requires_grad=True #new\n",
    "            pred = model(x_batch.to(device))\n",
    "            \n",
    "            u_deriv = derivative(x_batch,pred) #new\n",
    "            loss1 = criterion(pred,y_batch.to(device))\n",
    "            \n",
    "            #target2 = torch.zeros_like(u_t) #new\n",
    "            #loss2 = criterion(target2.to(device),u_t.to(device))*wandb.config.alpha #new\n",
    "            loss2 = torch.mean(u_deriv**2) * wandb.config.alpha #new new\n",
    "            loss = loss1 + loss2 #new\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            total_loss1 += loss1.item()\n",
    "            total_loss2 += loss2.item()\n",
    "\n",
    "            if i % 50 == 49:\n",
    "#                 print('Loss after mini-batch %5d: %.8f' %\n",
    "#                      (i + 1, current_loss / 50))\n",
    "                current_loss = 0.0\n",
    "\n",
    "        train_loss = total_loss/(i+1)\n",
    "        loss1 = total_loss1/(i+1) #new\n",
    "        loss2 = total_loss2/(i+1) #new\n",
    "        #print(\"Epoch \", epoch, \"Total Loss \", Loss)\n",
    "        #pbar.set_postfix(loss=Loss)\n",
    "        x_data_plot.append(epoch)\n",
    "        y_data_all_plot.append(train_loss)      \n",
    "        y_data_1_plot.append(loss1)\n",
    "        y_data_2_plot.append(loss2)\n",
    "        \n",
    "            ######## new\n",
    "        valid_loss = 0.0\n",
    "        model.eval()     # Optional when not using Model Specific layer\n",
    "        for j, data in enumerate(validloader,0):\n",
    "            x_batch, y_batch = data\n",
    "            # Forward Pass\n",
    "            target = model(x_batch.to(device))\n",
    "            # Find the Loss\n",
    "            loss = criterion(target,y_batch.to(device))\n",
    "            # Calculate Loss\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "        print(f'Epoch {epoch} \\t Training Loss: {\\\n",
    "        train_loss:.5f} \\t Loss 1: {loss1:.5f} \\t Loss 2: {loss2:.5f} \\t Validation Loss: {valid_loss / (j+1):.5f}')    \n",
    "\n",
    "\n",
    "        # uncomment for saving the best model and checkpoints during training\n",
    "        # save best model\n",
    "        if min_valid_loss > valid_loss:\n",
    "            print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "            min_valid_loss = valid_loss\n",
    "\n",
    "            # Saving State Dict    \n",
    "            model_name_path = Path('nomodel/best_model_{}_{}.pt'.format(wandb.run.id, wandb.run.name))\n",
    "            torch.save(model.state_dict(), model_name_path)\n",
    "\n",
    "        # writing checkpoint\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            checkpoint_path = Path('nomodel/checkpoint_{}_{}_{}.pt'.format(wandb.run.id, wandb.run.name, epoch))\n",
    "            write_checkpoint(checkpoint_path, epoch, min_valid_loss, optimizer)\n",
    "\n",
    "        # Log the loss and accuracy values at the end of each epoch\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Total Loss\": train_loss,\n",
    "            \"Loss1 (temperature)\": loss1,\n",
    "            \"Loss2 (regulariser)\": loss2,\n",
    "            \"Validation Loss\": valid_loss\n",
    "            })\n",
    "end = time.time()\n",
    "print(\"time:\", end - begin)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G9EHlOOxzfQ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make the plot of Total Loss vs epochs\n",
    "dpi = 360\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "\n",
    "plt.plot(x_data_plot,y_data_all_plot)\n",
    "plt.title('Total training loss vs epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Make the plot of the supervised loss\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "plt.plot(x_data_plot,y_data_1_plot)\n",
    "plt.title('Supervised loss vs epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss1')\n",
    "plt.show()\n",
    "\n",
    "# Make the plot of time stability loss\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "plt.plot(x_data_plot,y_data_2_plot)\n",
    "plt.title('Regulariser loss vs epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3p9a0my8wjSI"
   },
   "source": [
    "## Postprocessing -- Load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loVO9lty_1mH",
    "outputId": "489988c2-b3ea-4aeb-b8b7-c5791c73c5b4"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "PATH = 'nomodel/best_model_{}_{}.pt'.format(wandb.run.id, wandb.run.name)\n",
    "\n",
    "## Neural Operator without relative time trained on central differences\n",
    "#PATH = '/content/drive/MyDrive/NeuralSolvers-heat-eqn/examples/Research project/nomodel/norl/cdiff/best_model_icxc395f_NO_run.pt'\n",
    "\n",
    "## Neural Operator with relative time trained on central differences\n",
    "#PATH = \"/content/drive/MyDrive/nomodel/nomodel/rel_time/ctrl/best_model_3ef5thtw_NO_run.pt\" #rl time ctrl\n",
    "\n",
    "## Neural Operator with relative time trained on forward differences\n",
    "#PATH = \"/content/drive/MyDrive/nomodel/nomodel/rel_time/fwd/best_model_3cutaabz_NO_run.pt\"  \n",
    "\n",
    "# PATH ='nomodel/best_model_2yi86wor_NO_reg_v4.pt'\n",
    "\n",
    "#PATH = 'nomodel/best_model_745m0jcl_NO_reg_v3.pt'\n",
    "\n",
    "#PATH = 'nomodel/best_model_2zbvr34o_NO_reg_v2.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo8cip9mwFBF"
   },
   "source": [
    "## Performance of the model on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2CKaap0Aauy"
   },
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "normalize = wandb.config.normalize\n",
    "pred = model(ds.x.float().to(device)) #GPU\n",
    "pred = pred.detach().cpu().numpy()/normalize\n",
    "\n",
    "# ground-truth\n",
    "gt = ds.y.cpu().numpy()/normalize\n",
    "\n",
    "# Some statistics on the model performance on all of dataset\n",
    "mae = np.sum(np.abs(pred - gt).mean(axis=None))\n",
    "print('MAE:', mae)\n",
    "\n",
    "mse = ((gt - pred)**2).mean(axis=None)\n",
    "print('MSE:', mse)\n",
    "\n",
    "rel_error = np.linalg.norm(pred - gt) / np.linalg.norm(gt)\n",
    "print('Relative error (%):', rel_error*100)\n",
    "\n",
    "figure(figsize=(10, 8), dpi= 360)\n",
    "\n",
    "plt.plot(pred, '--')\n",
    "plt.plot(gt, '-')\n",
    "plt.legend(['Prediction', 'Ground-truth'])\n",
    "plt.title('Prediction accuracy on training data')\n",
    "plt.xlabel('t-idx')\n",
    "plt.ylabel('ΔTemp/Δt (°C/s)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# figure(figsize=(10, 8), dpi= 360)\n",
    "# #time\n",
    "# t=ds.t\n",
    "# plt.plot(t,pred, '--')\n",
    "# plt.plot(t,gt, '-')\n",
    "# plt.title('Prediction accuracy on training data')\n",
    "# plt.legend(['Prediction', 'Ground-truth'])\n",
    "# plt.xlabel('time (seconds)')\n",
    "# plt.ylabel('ΔTemp/Δt (°C/s)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRwCCUarwUVp"
   },
   "source": [
    "## Function for evaluating the performance on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtDt8BXiDYrZ"
   },
   "outputs": [],
   "source": [
    "def evaluate(idd,rel_time,diff):\n",
    "  print('ID = ', idd)\n",
    "  # import test data\n",
    "  ds_test = TeslaDatasetNo(device = device, ID = idd, data = \"test\",rel_time = rl, diff = \"central_diff\")\n",
    "\n",
    "  # Prediction accuracy of the Neural Operator\n",
    "  print('Prediction accuracy of the Neural Operator (NO)')\n",
    "  begin = time.time()\n",
    "  pred_der = model(ds_test.x.to(device))\n",
    "  pred_der = pred_der.detach().cpu().numpy()/normalize\n",
    "  end = time.time()\n",
    "  true_der = ds_test.y.cpu().numpy()\n",
    "  print(\"time:\", end - begin)\n",
    "  \n",
    "  # relative time\n",
    "  t=ds_test.t\n",
    "\n",
    "  #MAE\n",
    "  mae = np.sum(np.abs(pred_der- true_der).mean(axis=None))\n",
    "  print('MAE:', mae)\n",
    "\n",
    "  #MSE\n",
    "  mse = ((true_der - pred_der)**2).mean(axis=None)\n",
    "  print('MSE:', mse)\n",
    "\n",
    "  #Relative error\n",
    "  rel_error = np.linalg.norm(pred_der - true_der) / np.linalg.norm(true_der)\n",
    "  print('Relative error (%):', rel_error*100)\n",
    "  plt.figure(figsize = (12, 8))\n",
    "  plt.plot(t, pred_der, '-', label='Prediction')\n",
    "  plt.plot(t, true_der, '--', label='Ground-truth')\n",
    "  plt.title('Prediction accuracy of Neural Operator vs ground-truth for drive-ID = {}'.format(idd))\n",
    "  plt.xlabel('t (seconds)')\n",
    "  plt.ylabel('ΔTemp/Δt (°C/s)')\n",
    "  plt.grid()\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "  \n",
    "  print('########################################################')\n",
    "  \n",
    "  #3)Forward Euler method with fixed initial env. conditions but with updated \n",
    "  #Temperature (and rel time) from the prediction of the model at previous iteration\n",
    "  #with generated temporally equidistant time steps\n",
    "\n",
    "  print('Forwad Euler method with fixed initial env conditions')\n",
    "  rel_t = ds_test.rel_t\n",
    "\n",
    "  # ground-truth time\n",
    "  t=ds_test.t\n",
    "  max_t = t.max()\n",
    "  t=t.cpu().numpy()\n",
    "\n",
    "  # Ground-truth temperature\n",
    "  true_temp = ds_test.x[:,4].cpu().numpy()\n",
    "\n",
    "  # Predicted temperature using model prediction and forward euler method\n",
    "  pred_temp = np.zeros((ds_test.x.shape[0]))\n",
    "  pred_temp = true_temp.copy()\n",
    "\n",
    "  # Fixed initial conditions for all environmental conditions\n",
    "  input = ds_test.x[0].detach().clone()\n",
    "\n",
    "  # temporally equdistant time steps\n",
    "  tt = np.linspace(0,max_t,ds_test.x.shape[0])\n",
    "  step_size=tt[2]-tt[1]\n",
    "\n",
    "  #ODE\n",
    "  begin = time.time()\n",
    "\n",
    "  for i in range(0, ds_test.x.shape[0] - 1):\n",
    "      input[4] = torch.tensor(pred_temp[i]).detach().clone()\n",
    "      if rel_time == True:\n",
    "        input[5] = torch.tensor(rel_t[i]).detach().clone()\n",
    "      pred = model(input.to(device))\n",
    "      pred = pred.detach().cpu().numpy()/normalize\n",
    "      pred_temp[i + 1] = pred_temp[i] + pred*step_size\n",
    "  end = time.time()\n",
    "\n",
    "  print(\"time:\", end - begin)\n",
    "\n",
    "  #MAE\n",
    "  mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
    "  print('MAE:', mae)\n",
    "\n",
    "  #MSE\n",
    "  mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
    "  print('MSE:', mse)\n",
    "\n",
    "  #Relative error\n",
    "  rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
    "  print('Relative error (%):', rel_error*100)\n",
    "\n",
    "  plt.figure(figsize = (12, 8))\n",
    "  plt.plot(tt, pred_temp, '-', label='Prediction')\n",
    "  plt.plot(t, true_temp, '--', label='Ground-truth')\n",
    "  plt.title('Prediction vs ground-truth for drive-ID = {} (temporally equidistant step size)'.format(idd))\n",
    "  plt.xlabel('t (seconds)')\n",
    "  plt.ylabel('Temperature (°C)')\n",
    "  plt.grid()\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "  #4)Forward Euler method with updated environmental conditions from the dataset at each iteration\n",
    "  #But with updated temperature from the prediction of the model at previous iteration\n",
    "  #with true step sizes\n",
    "  print('Forwad Euler method with updated env conditions from the dataset at each iteration with true step sizes')\n",
    "  \n",
    "  # time\n",
    "  t=ds_test.t\n",
    "  t=t.numpy()\n",
    "  \n",
    "  # max time\n",
    "  max_t = t.max()\n",
    "\n",
    "  # Ground-truth temperature\n",
    "  true_temp = ds_test.x[:,4].cpu().numpy()\n",
    "\n",
    "  # Predicted temperature using model prediction and forward euler method\n",
    "  pred_temp = np.zeros((ds_test.x.shape[0]))\n",
    "  pred_temp[0] = true_temp[0].copy()\n",
    "\n",
    "  begin = time.time()\n",
    "  for i in range(0, ds_test.x.shape[0] - 1):\n",
    "        input = ds_test.x[i].detach().clone()\n",
    "        input[4] = torch.tensor(pred_temp[i]).detach().clone()\n",
    "        pred = model(input.to(device))\n",
    "        pred = pred.detach().cpu().numpy()/normalize\n",
    "        pred_temp[i + 1] = pred_temp[i] + pred*(t[i+1]-t[i])\n",
    "  end = time.time()\n",
    "\n",
    "\n",
    "  print(\"time:\", end - begin)\n",
    "  #MAE \n",
    "  mae = np.sum(np.abs(pred_temp- true_temp).mean(axis=None))\n",
    "  print('MAE:', mae)\n",
    "\n",
    "  #MSE\n",
    "  mse = ((true_temp - pred_temp)**2).mean(axis=None)\n",
    "  print('MSE:', mse)\n",
    "\n",
    "  # Relative error\n",
    "  rel_error = np.linalg.norm(pred_temp - true_temp) / np.linalg.norm(true_temp)\n",
    "  print('Relative error (%):', rel_error*100)\n",
    "\n",
    "  plt.figure(figsize = (12, 8))\n",
    "  plt.plot(t, pred_temp, '-', label='Prediction')\n",
    "  plt.plot(t, true_temp, '--', label='Ground-truth')\n",
    "  #plt.title('Approximate (with updated env conditions) and True Solution (true step size)'.format(idd))\n",
    "  plt.title('Prediction (with updated env. conditions) vs ground-truth for drive-ID = {} (true step size)'.format(idd))\n",
    "  plt.xlabel('t (seconds)')\n",
    "  plt.ylabel('Temperature (°C)')\n",
    "  plt.grid()\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "  # #5 time\n",
    "  # plt.figure(figsize = (12, 8))\n",
    "  # plt.plot(tt, '-', label='equidistant step size')\n",
    "  # plt.plot(t, '--', label='true stepsize')\n",
    "  # plt.title('Plot of equidistant test time vs true time')\n",
    "  # plt.legend(loc='lower right')\n",
    "\n",
    "  # #6\n",
    "  # plt.figure(figsize = (12, 8))\n",
    "  # plt.plot(np.diff(tt.reshape(-1)),'-', label='equidistant step size')\n",
    "  # plt.plot(np.diff(t.reshape(-1)),  '--', label='true step-size')\n",
    "  # plt.title('Plot of equidistant test time step size vs true time step size')\n",
    "  # plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4vMaQ0BweNo"
   },
   "source": [
    "## Performance of the model on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJRrMxsGvpod",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "rl = True\n",
    "diff = \"fwd_diff\"\n",
    "\n",
    "evaluate(idd=16,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoDCZ_BsvxUb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=39,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg6zRFgxv1X_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=47,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B95IHUJJv2P0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=52,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ddde_sWv5fq",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=72,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQ_m_fnov64d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=81,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcBZ7lrWv8Yl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "evaluate(idd=88,rel_time=rl,diff=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRe99_ONvLcs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralOperator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
