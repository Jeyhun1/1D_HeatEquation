{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1eVVkYZu6Qu",
    "outputId": "cf8a1c45-eb23-48c7-ecc0-54c5718b7edc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "from pyDOE import lhs\n",
    "from torch import Tensor, ones, stack, load\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import time\n",
    "from tesladatamlppower import TeslaDatasetMlpPower\n",
    "\n",
    "# Import PINNFramework etc.\n",
    "# https://github.com/ComputationalRadiationPhysics/NeuralSolvers.git\n",
    "sys.path.append(\"NeuralSolvers\")  \n",
    "import PINNFramework as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JS6Gfy1O_8k1"
   },
   "outputs": [],
   "source": [
    "# Use cuda if it is available, else use the cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = TeslaDatasetMlpPower(device = device, ID = -1, data = \"test\")\n",
    "ds_test.df0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEnkP4D3o_AW"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31GlZeC8CStC"
   },
   "outputs": [],
   "source": [
    "# login wandb (optional)\n",
    "wandb.login()\n",
    "\n",
    "# Initialize WandB (optional)\n",
    "wandb.init(name='mlp_power4-reg', \n",
    "           project='MLP_project',\n",
    "           notes='df_x = df0[[\"battery_temperature\",\"acc_fwd_diff\", \"battery_level\", \"outside_temp\"]]\\\n",
    "           df_y = df0[[\"power\"]]*normalize', \n",
    "           #tags=['...'],\n",
    "           #entity='...'\n",
    "           )\n",
    "\n",
    "\n",
    "# WandB Configurations (optional)\n",
    "wandb.config.normalize=0.01      \n",
    "wandb.config.batch_size=2048       \n",
    "wandb.config.lr = 1e-4\n",
    "\n",
    "# Create instance of the dataset\n",
    "ds = TeslaDatasetMlpPower(device = device, data = \"train\",normalize = wandb.config.normalize)\n",
    "ds_test = TeslaDatasetMlpPower(device = device, ID = -1, data = \"test\",normalize = wandb.config.normalize )\n",
    "\n",
    "\n",
    "# trainloader\n",
    "trainloader = DataLoader(ds, batch_size=wandb.config.batch_size,shuffle=True)\n",
    "validloader = DataLoader(ds_test, batch_size=wandb.config.batch_size,shuffle=True)\n",
    "\n",
    "# MLP model\n",
    "\n",
    "model = pf.models.MLP(input_size=4,\n",
    "                      output_size=1, \n",
    "                      hidden_size=100, \n",
    "                      num_hidden=4, \n",
    "                      lb=ds.lb, \n",
    "                      ub=ds.ub)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=wandb.config.lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Log the network weight histograms (optional)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x, u):\n",
    "\n",
    "    grads = ones(u.shape, device=u.device) # move to the same device as prediction\n",
    "    grad_u = grad(u, x, create_graph=True, grad_outputs=grads )[0]\n",
    "   \n",
    "    # calculate first order derivatives\n",
    "    #u_t = grad_u[:, 4]\n",
    "    #u_t = u_t.reshape(-1, 1)\n",
    "    \n",
    "#     u_t = torch.sum(grad_u, 1).reshape(-1, 1)\n",
    "    \n",
    "    return grad_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-DyWrMdGkEJ"
   },
   "outputs": [],
   "source": [
    "# function for saving checkpoints during training\n",
    "def write_checkpoint(checkpoint_path, epoch, min_mlp_loss, optimizer):\n",
    "    checkpoint = {}\n",
    "    checkpoint[\"epoch\"] = epoch\n",
    "    checkpoint[\"minimum_mlp_loss\"] = min_mlp_loss\n",
    "    checkpoint[\"optimizer\"] = optimizer.state_dict()\n",
    "    checkpoint[\"mlp_model\"] = model.state_dict()\n",
    "    torch.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XlXPoNeo_Aa"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRz83KPIgUzo",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "wandb.config.alpha = 1\n",
    "min_mlp_loss = np.inf\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "x_data_plot=[]\n",
    "y_data_all_plot=[]\n",
    "y_data_1_plot=[]\n",
    "y_data_2_plot=[]\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "begin = time.time()\n",
    "for epoch in range(epochs):\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch}')\n",
    "\n",
    "    # Set current and total loss value\n",
    "    current_loss = 0.0\n",
    "    total_train_loss = 0.0\n",
    "    total_train_loss1 = 0.0\n",
    "    total_train_loss2 = 0.0\n",
    "\n",
    "    model.train() \n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        #print(i)\n",
    "        x_batch, y_batch = data     \n",
    "        optimizer.zero_grad()\n",
    "        x_batch.requires_grad=True #new\n",
    "        target = model(x_batch.to(device))\n",
    "        u_deriv = derivative(x_batch,target) #new\n",
    "        #print('u_t shape', u_t.shape)\n",
    "        #print('target shape', target.shape  \n",
    "        loss1 = criterion(target,y_batch.to(device))\n",
    "        \n",
    "#         target2 = torch.zeros_like(u_t)\n",
    "#         loss2 = criterion(target2.to(device),u_t.to(device))\n",
    "        loss2 = torch.mean(u_deriv**2) * wandb.config.alpha #new new\n",
    "        loss = loss1 + loss2 #new\n",
    "        #print('loss shape', loss)\n",
    "        \n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_loss1 += loss1.item()\n",
    "        total_train_loss2 += loss2.item()\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            print('Loss after mini-batch %5d: %.8f' %\n",
    "                  (i + 1, current_loss / 50))\n",
    "            current_loss = 0.0\n",
    "            \n",
    "    train_loss = total_train_loss/(i+1)\n",
    "    loss1 = total_train_loss1/(i+1)\n",
    "    loss2 = total_train_loss2/(i+1)\n",
    "    #print(\"Epoch \", epoch, \"Total train Loss \", train_loss)\n",
    "    \n",
    "    x_data_plot.append(epoch)\n",
    "    y_data_all_plot.append(train_loss)\n",
    "    y_data_1_plot.append(loss1)\n",
    "    y_data_2_plot.append(loss2)\n",
    "    \n",
    "    ######## new\n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for j, data in enumerate(validloader,0):\n",
    "        x_batch, y_batch = data\n",
    "        # Forward Pass\n",
    "        target = model(x_batch.to(device))\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,y_batch.to(device))\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "#     print(f'Epoch {epoch} \\t Training Loss: {\\\n",
    "#     train_loss / len(trainloader)} \\t Validation Loss: {\\\n",
    "#     valid_loss / len(validloader)}')\n",
    "    \n",
    "#     print(f'Epoch {epoch} \\t Training Loss: {\\\n",
    "#     train_loss} \\t Loss 1: {loss1} \\t Loss 2: {loss2} \\t Validation Loss: {\\\n",
    "#     valid_loss / (j+1)}')\n",
    "    \n",
    "    print(f'Epoch {epoch} \\t Training Loss: {\\\n",
    "        train_loss:.5f} \\t Loss 1: {loss1:.5f} \\t Loss 2: {loss2:.5f} \\t Validation Loss: {valid_loss / (j+1):.5f}')    \n",
    "\n",
    "        \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        \n",
    "        # Saving State Dict\n",
    "        model_name_path = Path('mlpmodel/best_model_{}_{}.pt'.format(wandb.run.id, wandb.run.name))\n",
    "        torch.save(model.state_dict(), model_name_path)\n",
    "        \n",
    "#         # Saving State Dict\n",
    "#         torch.save(model.state_dict(), 'saved_model.pth')\n",
    "\n",
    "    # writing checkpoint\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        checkpoint_path = Path('mlpmodel/checkpoint_{}_{}_{}.pt'.format(wandb.run.id, wandb.run.name, epoch))\n",
    "        write_checkpoint(checkpoint_path, epoch, min_valid_loss, optimizer)\n",
    "\n",
    "\n",
    "# ##########old\n",
    "#     # writing checkpoint\n",
    "#     if (epoch + 1) % 200 == 0:\n",
    "#         checkpoint_path = Path('/mlpmodel/checkpoint_{}_{}_{}.pt'.format(wandb.run.id, wandb.run.name, epoch))\n",
    "#         write_checkpoint(checkpoint_path, epoch, min_mlp_loss, optimizer)\n",
    "        \n",
    "#     ########  new  \n",
    "        \n",
    "#     # uncomment for saving/tracking the best model and checkpoints\n",
    "#     # save best model\n",
    "#     if min_mlp_loss > Loss:\n",
    "#         print(f'Loss Decreased({min_mlp_loss:.6f}--->{Loss:.6f}) \\t Saving The Model')\n",
    "#         min_mlp_loss = Loss\n",
    "#         # Saving State Dict\n",
    "#         model_name_path = Path('/mlpmodel/best_model_{}_{}.pt'.format(wandb.run.id, wandb.run.name))\n",
    "#         torch.save(model.state_dict(), model_name_path)\n",
    "\n",
    "#     # writing checkpoint\n",
    "#     if (epoch + 1) % 200 == 0:\n",
    "#         checkpoint_path = Path('/mlpmodel/checkpoint_{}_{}_{}.pt'.format(wandb.run.id, wandb.run.name, epoch))\n",
    "#         write_checkpoint(checkpoint_path, epoch, min_mlp_loss, optimizer)\n",
    "# #########old\n",
    "\n",
    "    # Log the loss and accuracy values at the end of each epoch\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch,\n",
    "        \"Total Loss\": train_loss,\n",
    "        \"Loss1 (power)\": loss1,\n",
    "        \"Loss2 (regulariser)\": loss2,\n",
    "        \"Validation Loss\": valid_loss\n",
    "        })\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time:\", end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "9LIA6mcWbEjA",
    "outputId": "8e64ecc6-922f-48ca-ce21-d8eaf7d9e806",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make the plot of Total Loss vs epochs\n",
    "dpi = 360\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "\n",
    "plt.plot(x_data_plot,y_data_all_plot)\n",
    "plt.title('Training loss vs epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Make the plot of the supervised loss\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "plt.plot(x_data_plot,y_data_1_plot)\n",
    "plt.title('Training loss vs epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss1')\n",
    "plt.show()\n",
    "\n",
    "# Make the plot of time stability loss\n",
    "figure(figsize=(10, 8), dpi = dpi)\n",
    "plt.plot(x_data_plot,y_data_2_plot)\n",
    "plt.title('Training loss vs epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvHH7yyifZUL"
   },
   "source": [
    "## Postprocessing\n",
    "\n",
    "1) Load the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6CO7j3tKJ_O",
    "outputId": "b80ad404-95da-4b8d-c822-a0f9f00cf83c"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "PATH = 'mlpmodel/best_model_{}_{}.pt'.format(wandb.run.id, wandb.run.name)\n",
    "#PATH = 'mlpmodel/best_model_2wwc65h3_mlp_power2-reg.pt' # mlp with regulariser alpha=1\n",
    "#PATH ='/models/best_model_3a0z7dct_mlp_run.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "#model.load_state_dict(torch.load(PATH, map_location=torch.device('cpu'))) # if there is no gpu available\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "#checkpoint = torch.load('mlpmodel/checkpoint_29l1u779_mlp_power_1999.pt')\n",
    "#model.load_state_dict(checkpoint[\"mlp_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w7zK4hXo_Ai"
   },
   "source": [
    "2. Performance on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "D34Tded-SF9j",
    "outputId": "d7f67894-e89c-41c8-dc1c-3341f6ad0f50"
   },
   "outputs": [],
   "source": [
    "# Make a prediction on trained data\n",
    "normalize = wandb.config.normalize\n",
    "pred = model(ds.x.float().to(device)) #GPU\n",
    "pred = pred.detach().cpu().numpy()/normalize\n",
    "\n",
    "# ground-truth temperature\n",
    "gt = ds.y.numpy()/normalize\n",
    "\n",
    "# Some statistics on the model performance on training dataset\n",
    "mae = np.sum(np.abs(pred - gt).mean(axis=None))\n",
    "print('MAE:', mae)\n",
    "\n",
    "mse = ((gt - pred)**2).mean(axis=None)\n",
    "print('MSE:', mse)\n",
    "\n",
    "rel_error = np.linalg.norm(pred - gt) / np.linalg.norm(gt)\n",
    "print('Relative error (%):', rel_error*100)\n",
    "\n",
    "# Plot of the prediction vs ground-truth\n",
    "figure(figsize=(10, 8), dpi= 360)\n",
    "plt.plot(pred, '--')\n",
    "plt.plot(gt, '-')\n",
    "plt.title('Prediction vs ground-truth for the training dataset')\n",
    "plt.legend(['Prediction', 'ground-truth'])\n",
    "plt.xlabel('t-idx')\n",
    "plt.ylabel('Power (kWh)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02Ecn62zo_Ak"
   },
   "source": [
    "## Function for evaluating the model on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7KbCoerWLWb"
   },
   "outputs": [],
   "source": [
    "# Function for evaluating the model's performance on selected test data\n",
    "def predict(id):\n",
    "    print('ID = ', id)\n",
    "    # Test dataset\n",
    "    ds_test = TeslaDatasetMlpPower(device = device, ID = id, data = \"test\")\n",
    "\n",
    "    # time\n",
    "    t = ds_test.t\n",
    "\n",
    "    # prediction\n",
    "    pred = model(ds_test.x.float().to(device)) #GPU\n",
    "    pred = pred.detach().cpu().numpy()/normalize\n",
    "\n",
    "    # ground-truth\n",
    "    gt = ds_test.y.numpy()\n",
    "\n",
    "    # Some statistics on the model performance on test dataset\n",
    "    mae = np.sum(np.abs(pred - gt).mean(axis=None))\n",
    "    print('MAE:', mae)\n",
    "\n",
    "    mse = ((gt - pred)**2).mean(axis=None)\n",
    "    print('MSE:', mse)\n",
    "\n",
    "    rel_error = np.linalg.norm(pred - gt) / np.linalg.norm(gt)\n",
    "    print('Relative error (%):', rel_error*100)\n",
    "\n",
    "    # # \n",
    "    # figure(figsize=(10, 8), dpi= 360)\n",
    "    # plt.plot(pred, '--')\n",
    "    # plt.plot(gt, '-')\n",
    "    # plt.title('Prediction vs ground-truth for drive-id = {}'.format(id))\n",
    "    # plt.legend(['Prediction', 'ground-truth'])\n",
    "    # plt.xlabel('t-idx')\n",
    "    # plt.ylabel('Temperature (°C)')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Plot of the prediction vs ground-truth\n",
    "    figure(figsize=(10, 8), dpi= 360)\n",
    "    plt.plot(t,pred, '--')\n",
    "    plt.plot(t,gt, '-')\n",
    "    plt.title('Prediction vs ground-truth for drive-id = {}'.format(id))\n",
    "    plt.legend(['Prediction', 'ground-truth'])\n",
    "    plt.xlabel('t (seconds)')\n",
    "    plt.ylabel('Power (kW)')\n",
    "    plt.show()\n",
    "    return mae,mse,rel_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl-o2eMmo_Am"
   },
   "source": [
    "3. Performance oof the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "id": "OgW1Y7yZWW8I",
    "outputId": "5beea948-fd86-49a7-9ad5-34a199e5359f"
   },
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "\n",
    "mae16,mse16,rel_error16 = predict(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "qv4aObZmdOe6",
    "outputId": "9b0a7825-1d01-4ed0-b465-70a145c825e5"
   },
   "outputs": [],
   "source": [
    "mae39,mse39,rel_error39 = predict(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "Mf8DPwXKdOJ0",
    "outputId": "dbe9816e-6abd-410e-a242-1b707f0836ba"
   },
   "outputs": [],
   "source": [
    "mae47,mse47,rel_error47 = predict(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "EPAHDiVDdN5F",
    "outputId": "75446c26-6a26-49f5-c390-caa3cf2d3d03"
   },
   "outputs": [],
   "source": [
    "mae52,mse52,rel_error52 = predict(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "v5bxiyeUdNhe",
    "outputId": "a3cdc489-f163-457e-e56e-b65fedc19f63"
   },
   "outputs": [],
   "source": [
    "mae72,mse72,rel_error72 = predict(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "g9kCL6rcdUJh",
    "outputId": "5f63ca27-bbdf-4d15-b82a-2168f590cab7"
   },
   "outputs": [],
   "source": [
    "mae81,mse81,rel_error81 = predict(81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "NYZMNjQfdVEr",
    "outputId": "f094e821-86a6-4a0f-afc5-89873c2fbd78"
   },
   "outputs": [],
   "source": [
    "mae88,mse88,rel_error88 = predict(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test values = [16,39,47,52,72,81,88]\n",
    "mae_avg = (mae16+mae39+mae47+mae52+mae72+mae81+mae88)/7\n",
    "mse_avg = (mse16+mse39+mse47+mse52+mse72+mse81+mse88)/7\n",
    "rel_err_avg = (rel_err16+rel_err39+rel_err47+rel_err52+rel_err72+rel_err81+rel_err88)/7\n",
    "\n",
    "print(mae_avg)\n",
    "print(mse_avg)\n",
    "print(rel_err_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
